<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key attr.name="score" attr.type="double" for="edge" id="d23" />
  <key attr.name="type" attr.type="string" for="edge" id="d22" />
  <key attr.name="edited" attr.type="double" for="node" id="d21" />
  <key attr.name="upvote_ratio" attr.type="double" for="node" id="d20" />
  <key attr.name="is_video" attr.type="boolean" for="node" id="d19" />
  <key attr.name="edited" attr.type="boolean" for="node" id="d18" />
  <key attr.name="view_count" attr.type="long" for="node" id="d17" />
  <key attr.name="title" attr.type="string" for="node" id="d16" />
  <key attr.name="averageWordLength" attr.type="long" for="node" id="d15" />
  <key attr.name="corpus" attr.type="string" for="node" id="d14" />
  <key attr.name="sentiment" attr.type="string" for="node" id="d13" />
  <key attr.name="sentiment_score" attr.type="double" for="node" id="d12" />
  <key attr.name="readingLevel" attr.type="double" for="node" id="d11" />
  <key attr.name="quotedTextPerLength" attr.type="double" for="node" id="d10" />
  <key attr.name="averageWordLength" attr.type="double" for="node" id="d9" />
  <key attr.name="length" attr.type="long" for="node" id="d8" />
  <key attr.name="body" attr.type="string" for="node" id="d7" />
  <key attr.name="timestamp" attr.type="double" for="node" id="d6" />
  <key attr.name="score" attr.type="long" for="node" id="d5" />
  <key attr.name="author" attr.type="string" for="node" id="d4" />
  <key attr.name="id" attr.type="string" for="node" id="d3" />
  <key attr.name="parent_id" attr.type="string" for="node" id="d2" />
  <key attr.name="id_0" attr.type="string" for="node" id="d1" />
  <key attr.name="name" attr.type="string" for="node" id="d0" />
  <graph edgedefault="undirected">
    <node id="c0">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i0l65</data>
      <data key="d3">e6fvrvt</data>
      <data key="d4">-smiley--</data>
      <data key="d5">4</data>
      <data key="d6">1537660449.0</data>
      <data key="d7">Making a flowchart really helps a lot.</data>
      <data key="d8">38</data>
      <data key="d9">5.167</data>
      <data key="d10">0.0</data>
      <data key="d11">6.0</data>
      <data key="d12">0.4391</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</data>
    </node>
    <node id="c1">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fvrvt</data>
      <data key="d3">e6hbbyu</data>
      <data key="d4">bastywright</data>
      <data key="d5">1</data>
      <data key="d6">1537720384.0</data>
      <data key="d7">that's how i formulate my algorithms.

&amp;#x200B;</data>
      <data key="d8">47</data>
      <data key="d9">4.571</data>
      <data key="d10">0.0</data>
      <data key="d11">6.0</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c2">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4auegy</data>
      <data key="d4">sagaciux</data>
      <data key="d5">12</data>
      <data key="d6">1534466256.0</data>
      <data key="d7">I think your problem as currently stated is too open ended. Since your goal is to build a specific mathematical model, you're going to need a precise definition of what you want to achieve. Right now, the phrase "create the simplest model possible in which the evolution of the laws of nature arises from the natural selection of structures" is too ambiguous for me to unpack: what laws of nature are you looking to express? What structures are you selecting from? How do you define the process of evolution/natural selection? How would you know if your model was simpler or more complex?

The problem may become more clear if it is separated into smaller parts. I think philosophy can be open-ended and contradictory, but a model needs precise definitions. At minimum, a model needs rules and an initial state. Before trying to figure out these things, I would want to know: what do I want my model to demonstrate? Given a particular state, what should the next state look like? If the model should be simple, then I would want to include only the most relevant behaviors and states. What information does my model at minimum to function, and how much of it?</data>
      <data key="d8">1159</data>
      <data key="d9">7.75</data>
      <data key="d10">0.1104</data>
      <data key="d11">8.2</data>
      <data key="d12">0.0535</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 7), (25, 1), (26, 2), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 2), (47, 1), (48, 4), (49, 4), (50, 1), (51, 3), (52, 1), (53, 3), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1)]</data>
    </node>
    <node id="c3">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4auegy</data>
      <data key="d3">e4aznhr</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534470573.0</data>
      <data key="d7">The most of problems you mention (if not all) I tried to address or at least mention in the [section 0 of the article](https://kiwi0fruit.github.io/ultimate-question/#s0). And in particular in the [0.1 subsection](https://kiwi0fruit.github.io/ultimate-question/#s0_1). I'm aware that I'm still far from understanding...

&gt; what do I want my model to demonstrate?

It should be the model of open ended evolution (artificial life) (OEE). OEE means that individuals in the model with natural selection don't stop on some fixed level of complexity but keep evolving (like life kept evolving from unicellular life to homo sapiens). But at the same time the model should be simple enough to be (like) self-justifying from philosophical reasoning (that was addressed in the mentioned section 0.1).

&gt; Given a particular state, what should the next state look like?

If I'm to know the answer to this question then I've already had understood the model workings and I simply need to write them down in some language. That's clearly not the case now as I still lack understanding of how it should work in details.

As about "separating into smaller parts"... I have problems with that.

The name of the article is not mentioned here but it's "The Ultimate Question of Life, the Universe, and Everything". And there is a reason for it. Well enough justified (from philosophical point of view) model of open ended evolution would be a very good candidate to answer The Question. And I have no hope that such a question can be solved by splitting to smaller parts. I also can tell that all that I know about this problem suggests that it cannot be split to smaller components. But it's only my intuition so it's not an argument...
</data>
      <data key="d8">1719</data>
      <data key="d9">8.644</data>
      <data key="d10">0.0524</data>
      <data key="d11">8.2</data>
      <data key="d12">0.0547</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 3), (7, 1), (8, 2), (9, 1), (10, 2), (11, 2), (12, 2), (13, 1), (14, 6), (15, 1), (16, 1), (17, 1), (18, 6), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 2), (32, 2), (33, 2), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 2), (44, 1), (45, 2), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 4), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 2), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 2), (90, 2), (91, 1), (92, 1), (93, 3), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 3), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1)]</data>
    </node>
    <node id="c4">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4apf0r</data>
      <data key="d4">WeirdEidolon</data>
      <data key="d5">5</data>
      <data key="d6">1534462083.0</data>
      <data key="d7">NEAT might check a lot of the boxes you're looking for (I haven't browsed through your link yet)

https://en.m.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies</data>
      <data key="d8">169</data>
      <data key="d9">7.789</data>
      <data key="d10">0.0</data>
      <data key="d11">10.7</data>
      <data key="d12">0.5766</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c5">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4apf0r</data>
      <data key="d3">e4apf4w</data>
      <data key="d4">HelperBot_</data>
      <data key="d5">1</data>
      <data key="d6">1534462086.0</data>
      <data key="d7">Non-Mobile link: https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies
***
^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^204972</data>
      <data key="d8">222</data>
      <data key="d9">7.125</data>
      <data key="d10">0.0</data>
      <data key="d11">7.6</data>
      <data key="d12">0.0795</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c6">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4apf0r</data>
      <data key="d3">e4apf88</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1534462088.0</data>
      <data key="d7">**Neuroevolution of augmenting topologies**

NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm (GA) for the generation of evolving artificial neural networks (a neuroevolution technique) developed by Ken Stanley in 2002 while at The University of Texas at Austin. It alters both the weighting parameters and structures of networks, attempting to find a balance between the fitness of evolved solutions and their diversity. It is based on applying three key techniques: tracking genes with history markers to allow crossover among topologies, applying speciation (the evolution of species) to preserve innovations, and developing topologies incrementally from simple initial structures ("complexifying").

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1150</data>
      <data key="d9">10.315</data>
      <data key="d10">0.0122</data>
      <data key="d11">17.8</data>
      <data key="d12">0.0468</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1)]</data>
    </node>
    <node id="c7">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4akr6z</data>
      <data key="d4">Rococoon</data>
      <data key="d5">3</data>
      <data key="d6">1534458001.0</data>
      <data key="d7">When do you want to start working on it? I think it is super interesting and I would like to help you think about it, however I am super busy right now... I do think that I might be able to help though given my background. </data>
      <data key="d8">223</data>
      <data key="d9">5.273</data>
      <data key="d10">0.0</data>
      <data key="d11">4.5</data>
      <data key="d12">0.4731</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 3), (17, 1), (18, 1), (19, 1), (20, 1)]</data>
    </node>
    <node id="c8">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4akr6z</data>
      <data key="d3">e4amw9i</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534459909.0</data>
      <data key="d7">Actually I worked on it till summer of 2016. The article by link is a compilation of what I was able to figue out (mostly guesses and questions with details) - I've recently added final bits to the 2016 article and started to search for help once again - I feel like I've reached my limit or burnt out.

If you feel like you have thoughts or anything useful please do not hesitate to [comment here](https://github.com/kiwi0fruit/ultimate-question/issues/2) or even make a pull request to [the repo](https://github.com/kiwi0fruit/ultimate-question) (or communicate any other way you like).

I'm also going to be busy from now on but "It does not matter how slowly you go as long as you do not stop" :)
</data>
      <data key="d8">701</data>
      <data key="d9">6.386</data>
      <data key="d10">0.0913</data>
      <data key="d11">9.6</data>
      <data key="d12">0.4997</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)]</data>
    </node>
    <node id="c9">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4akr6z</data>
      <data key="d3">e4eahki</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534598699.0</data>
      <data key="d7">You might be interested in the **UPD** section I added to the main post. There is a short description of the assumptions that make the task look feasible. They are the core of the research idea.</data>
      <data key="d8">194</data>
      <data key="d9">5.067</data>
      <data key="d10">0.0</data>
      <data key="d11">4.4</data>
      <data key="d12">0.134</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]</data>
    </node>
    <node id="c10">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4akyzn</data>
      <data key="d4">noam_compsci</data>
      <data key="d5">2</data>
      <data key="d6">1534458202.0</data>
      <data key="d7">Page not found on the kiwi link</data>
      <data key="d8">31</data>
      <data key="d9">3.571</data>
      <data key="d10">0.0</data>
      <data key="d11">0.1</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c11">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4akyzn</data>
      <data key="d3">e4alo5d</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">2</data>
      <data key="d6">1534458839.0</data>
      <data key="d7">thanks! fixed.</data>
      <data key="d8">14</data>
      <data key="d9">5.5</data>
      <data key="d10">0.0</data>
      <data key="d11">-3.1</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1)]</data>
    </node>
    <node id="c12">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4al1uq</data>
      <data key="d4">Anonymous</data>
      <data key="d5">2</data>
      <data key="d6">1534458274.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c13">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4al1uq</data>
      <data key="d3">e4alv3q</data>
      <data key="d4">Anonymous</data>
      <data key="d5">-2</data>
      <data key="d6">1534459012.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c14">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4cbzu0</data>
      <data key="d4">Anonymous</data>
      <data key="d5">2</data>
      <data key="d6">1534521766.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c15">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4cbzu0</data>
      <data key="d3">e4ccl57</data>
      <data key="d4">Anonymous</data>
      <data key="d5">1</data>
      <data key="d6">1534522994.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c16">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4celt3</data>
      <data key="d4">Meguli</data>
      <data key="d5">2</data>
      <data key="d6">1534527325.0</data>
      <data key="d7">Chaitin might have material that can inspire you. </data>
      <data key="d8">50</data>
      <data key="d9">5.125</data>
      <data key="d10">0.0</data>
      <data key="d11">6.4</data>
      <data key="d12">0.5719</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]</data>
    </node>
    <node id="c17">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4celt3</data>
      <data key="d3">e4cfh25</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534529147.0</data>
      <data key="d7">Thanks. Looks like a big area to search through...

Random thought: I hope that the desired model of the natural selection would not resemble Chaitin's constant: as we can reason about it to some extent and have constraints that allow it. But we cannot have it's digits...</data>
      <data key="d8">272</data>
      <data key="d9">5.262</data>
      <data key="d10">0.0</data>
      <data key="d11">5.9</data>
      <data key="d12">0.4036</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1)]</data>
    </node>
    <node id="c18">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4digjl</data>
      <data key="d4">zergling_Lester</data>
      <data key="d5">2</data>
      <data key="d6">1534568090.0</data>
      <data key="d7">1. Much cleverer people tried that before, what makes you think that you can do better? Ignorance.

2. Go pirate and read https://en.wikipedia.org/wiki/Gödel,_Escher,_Bach, this will get you up to speed with the 1970s state of the art of that stuff and make you realize how much you don't know in the process. Also, it's so damn enjoyable, to be honest with you fam. Anyways, it'd provide a perfect starting point into more serious inquiries.</data>
      <data key="d8">442</data>
      <data key="d9">5.836</data>
      <data key="d10">0.0</data>
      <data key="d11">5.5</data>
      <data key="d12">0.2138</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 3), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2)]</data>
    </node>
    <node id="c19">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4digjl</data>
      <data key="d3">e4digt8</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1534568096.0</data>
      <data key="d7">**Gödel, Escher, Bach**

Gödel, Escher, Bach: An Eternal Golden Braid, also known as GEB, is a 1979 book by Douglas Hofstadter. 

By exploring common themes in the lives and works of logician Kurt Gödel, artist M. C. Escher, and composer Johann Sebastian Bach, the book expounds concepts fundamental to mathematics, symmetry, and intelligence. Through illustration and analysis, the book discusses how self-reference and formal rules allow systems to acquire meaning despite being made of "meaningless" elements. It also discusses what it means to communicate, how knowledge can be represented and stored, the methods and limitations of symbolic representation, and even the fundamental notion of "meaning" itself.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1141</data>
      <data key="d9">9.83</data>
      <data key="d10">0.0175</data>
      <data key="d11">15.5</data>
      <data key="d12">0.0397</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 2), (13, 3), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1)]</data>
    </node>
    <node id="c20">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4digjl</data>
      <data key="d3">e4e903v</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534596438.0</data>
      <data key="d7">1 ) Smartness is drastically not enough to find that answer. You need to be lucky to pick the right direction. Another necessary components are metaphysical considerations and desire for mathematical presicion.

I'm aware that from this on the task seems to tough for me...

And luck is that main factor. Do you know someone who tried to solve this task using metaphysical considerations attempted to bring some math and bet on natural selection as a mechanism that gives novelty?

If yes then I would be very glad to read what they wrote. If no then your first point is rather useless.

2) As about Hofstadter I tried to dig into his idea of strange loop. I felt like this crazy thing may be useful in that crazy task. But I wasn't able to think about it non-contradictory. May be I really should read the book :) Even if it would be just for fun in the end.</data>
      <data key="d8">859</data>
      <data key="d9">6.009</data>
      <data key="d10">0.0</data>
      <data key="d11">6.0</data>
      <data key="d12">0.2287</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 5), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 3), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]</data>
    </node>
    <node id="c21">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e4i9yyk</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534783212.0</data>
      <data key="d7">Comments from other sources:</data>
      <data key="d8">28</data>
      <data key="d15">6</data>
      <data key="d10">0.0</data>
      <data key="d11">3.7</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c22">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4i9z3i</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534783221.0</data>
      <data key="d7">&gt; Apart from various other concerns one comment: Evolution comes with an increase in complexity, whereas the physical laws evolve from (possibly) a complex unified theory at large energies etc. to arguably simpler effective theories (particles, distinct forces)  
&gt; ([Bort](https://physics.stackexchange.com/users/86132/bort))
</data>
      <data key="d8">327</data>
      <data key="d9">7.079</data>
      <data key="d10">0.0</data>
      <data key="d11">16.6</data>
      <data key="d12">0.3502</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]</data>
    </node>
    <node id="c23">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4ia93g</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534783853.0</data>
      <data key="d7">&gt; If I recall correctly, you can construct any logical outcome from a NOR and an AND operation. It then depends if you think that "it" comes from "bit". If so, there you go; if not, then you need a substrate for your logical tools to operate upon. Loop quantum gravity's spin networks, maybe.  
&gt; ([u/OliverSparrow](https://www.reddit.com/r/oee/comments/97q529/on_natural_selection_of_the_laws_of_nature/e4a8p00/))</data>
      <data key="d8">414</data>
      <data key="d9">7.128</data>
      <data key="d10">0.0169</data>
      <data key="d11">10.9</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c24">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4iaahk</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534783945.0</data>
      <data key="d7">&gt; So... I'm going to be blunt in expressing my opinion; you're being *way* too ambitious by trying to map this all out at such a high level before starting any actual work. You need to break this up into much smaller components, "solve" them, learn from your solutions, and try to figure out a way to combine those components into something larger.
&gt; 
&gt; If you just want to be philosophical and wax poetic about reality and write about your ideas, then that's one thing and keep doing what you enjoy. But if you want results, you need to scale back most of your expectations dramatically.  
&gt; ([u/WildZontar](https://www.reddit.com/r/evolution/comments/97s3ma/on_natural_selection_of_the_laws_of_nature/e4atqnn/))
</data>
      <data key="d8">714</data>
      <data key="d9">6.869</data>
      <data key="d10">0.0084</data>
      <data key="d11">14.7</data>
      <data key="d12">0.2124</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 3), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1)]</data>
    </node>
    <node id="c25">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4iabit</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534784007.0</data>
      <data key="d7">&gt; I don’t comprehend where you’re going with this. I just want to comment that your unit of natural selection should probably be more on the replicator level, not individual level.
&gt; 
&gt; Good luck!  
&gt; ([u/SirPolymorph](https://www.reddit.com/r/evolution/comments/97s3ma/on_natural_selection_of_the_laws_of_nature/e4b3p8b/))</data>
      <data key="d8">323</data>
      <data key="d9">7.472</data>
      <data key="d10">0.0</data>
      <data key="d11">18.0</data>
      <data key="d12">0.289</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]</data>
    </node>
    <node id="c26">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4iaeaa</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534784181.0</data>
      <data key="d7">&gt; Provocative but the laws of nature are not living organisms that seek to produce offspring. They are not subject to natural selection, they are just a fixed variable of the environment.  
&gt; ([u/Vanna_man](https://www.reddit.com/r/evolution/comments/97s3ma/on_natural_selection_of_the_laws_of_nature/e4hdhog/))</data>
      <data key="d8">311</data>
      <data key="d9">9.429</data>
      <data key="d10">0.0</data>
      <data key="d11">17.8</data>
      <data key="d12">-0.0918</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]</data>
    </node>
    <node id="c27">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e4iaqod</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534784960.0</data>
      <data key="d7">About [Section 4.1](https://kiwi0fruit.github.io/ultimate-question/#s4_1):

&gt; Your constraint 4 sounds very strange, if the purpose is to mimic natural selection. As I understand your Q, the complexity of the graph is a representation of the complexity of the "organism" (am I mistaken?). At the same time, you define 'reproduction' as the duplication of vertices, which to me sounds like an bipedal organism growing a third leg, if the graph is supposed to model the "complexity" of the "organism". How is the population size represented in the proposed model?  
&gt; ([fileunderwater](http://biology.stackexchange.com/users/3624/fileunderwater))</data>
      <data key="d8">644</data>
      <data key="d9">8.864</data>
      <data key="d10">0.045</data>
      <data key="d11">14.7</data>
      <data key="d12">0.0474</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1)]</data>
    </node>
    <node id="c28">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e6d591z</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538126.0</data>
      <data key="d7">&gt; Why do you think evolution can explain anything that preceded life? I feel that claim needs proper justification.  
([u/sanalphatau](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6bo1j8/))
</data>
      <data key="d8">242</data>
      <data key="d9">10.5</data>
      <data key="d10">0.0</data>
      <data key="d11">21.2</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1)]</data>
    </node>
    <node id="c29">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e6d5je4</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538593.0</data>
      <data key="d7">&gt; Do you want to evolve the actual laws of nature, like quantum mechanics?
&gt;
&gt; If not, you can invent a near-trivial system which evolves into an arbitrary state that you can call a "law of nature".  
([u/sorrge](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6czx3j/))</data>
      <data key="d8">319</data>
      <data key="d9">8.219</data>
      <data key="d10">0.0439</data>
      <data key="d11">16.2</data>
      <data key="d12">0.2107</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]</data>
    </node>
    <node id="c30">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9yyk</data>
      <data key="d3">e6h5ffp</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537708961.0</data>
      <data key="d7">&gt; Your research interest sounds interesting. I am somewhat familiar with artificial life, artificial intelligence and computer science but I had trouble understanding you. This may be because your post lacks proper structure and definitions. I could not distinguish between hypothesis and things which are based on other peoples research. Also, I advice you to not expect not everyone is familiar with every concept (e.g. I have never heard of Peirce's concept of Tychism before). That's why there are usually "related works" chapters in scientific works.  
([u/Cbeed](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6efmzb/))</data>
      <data key="d8">675</data>
      <data key="d9">7.847</data>
      <data key="d10">0.0207</data>
      <data key="d11">12.8</data>
      <data key="d12">0.0412</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1)]</data>
    </node>
    <node id="c31">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e6d5y09</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539284.0</data>
      <data key="d7">&gt; [The Origins of Order: Self-Organization and Selection in Evolution](https://www.amazon.com/Origins-Order-Self-Organization-Selection-Evolution/dp/0195079515).  
&gt;
&gt; I'm not aware of too many articles, but you could try [this one](https://www.sccs.swarthmore.edu/users/08/bblonder/phys120/docs/kauffman.pdf) co-authored by
Kaufmann a few years before the book was published.  
&gt; (u/[deleted])</data>
      <data key="d8">394</data>
      <data key="d9">9.222</data>
      <data key="d10">0.0</data>
      <data key="d11">20.7</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]</data>
    </node>
    <node id="c32">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d5y09</data>
      <data key="d3">e6d5yux</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539324.0</data>
      <data key="d7">After few years of research (2014-2016 mostly) I think about all **books** on the topic with a **great** scepsis. May be you know if there is an article on the topic? But still thank you!

**UPD**

Shame on me: I've forgot that such books in most cases have assosiated article(s) - for example books by Lee Smolin about time have a nice short article on the same topic: "Temporal naturalism".</data>
      <data key="d8">392</data>
      <data key="d9">5.382</data>
      <data key="d10">0.051</data>
      <data key="d11">6.5</data>
      <data key="d12">0.2103</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1)]</data>
    </node>
    <node id="c33">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97s8dl</data>
      <data key="d3">e6d63xi</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539574.0</data>
      <data key="d7">&gt;Hello, the title of this post caught my eye. I knew it would be some sort of ultimate question
&gt;about everything.
&gt;
&gt;I love how ambitious you are - trying to define the problem and solve it in one post on
&gt;reddit). Perhaps you’re underestimating the complexity of both processes.
&gt;
&gt;This topic, or problem, you’re talking about is so complex that it’s extremely hard to define it
&gt;in words that would describe its true nature. It’s interesting how people can still understand
&gt;what you’re talking about. It seems to me you’re looking for a not just a theory, but a
&gt;mathematical model of everything. It is important to note that this question deals with
&gt;consciousness because the nature of universe consists of objective nature (quantitative)
&gt;and subjective nature (qualitative).
&gt;
&gt;Let’s start by defining the problem correctly...
&gt;
&gt;Some people who have commented claim that your original question is too ambiguous to
&gt;be the definition of the problem being solved by a computational model. You mention
&gt;“evolution of laws of nature” and “natural selection of structure” and it doesn’t seem clear to
&gt;me what exactly you’re talking about.
&gt;
&gt;You seem to be trying to define current state of the world, universe, or everything. With this
&gt;information you could predict how it originated and how exactly it will change in the future.
&gt;This is the “simple” model you’re looking for.
&gt;
&gt;I think a better way of phrasing this problem is to be less ambiguous and more precise with
&gt;what you’re talking about. If you want a simple answer, ask a simple question.
&gt;
&gt;How - exactly - does everything operate, based on the current state of everything?
&gt;
&gt;Despite the lack of specificity, would you agree that this a more well-defined problem? To
&gt;me, using the word “everything” is easier and more useful than trying to define everything
&gt;because we all can agree on what we’re referring to when we say “everything”: the universe.
&gt;The universe is an example of a complex system. A complex system is any system featuring
&gt;a large number of interacting components (agents, processes, etc.) whose aggregate
&gt;activity is nonlinear (not derivable from the summations of the activity of individual
&gt;components) and typically exhibits hierarchical self-organization under selective pressures
&gt;Saying the laws of nature and structure leads one to think these systems are separate when
&gt;they are in fact both part of one complex system we can refer to as “everything”.
&gt;Understanding exactly what everything means requires an unimaginable amount of power.
&gt;Everything includes every single thing in existence and everything at once - everything that
&gt;has ever existed and everything that will exist. Everything is an objective thing with
&gt;quantifiable features like the laws of physics that is only observed through subjective things
&gt;like human beings and other biological organisms. It is important to note that the definition
&gt;of “everything” is different from person to person, however everyone can agree that the
&gt;word makes sense to represent everything in their world (or perception).
&gt;
&gt;So, you might ask, if everything is so hard to define, what would be computed to predict the
&gt;future?
&gt;
&gt;Well, some things just don’t need to be defined by all of its physical attributes to be used for
&gt;some purpose. Usually, complex systems are defined by emergent properties that come
&gt;about because of interactions among the parts. A classic traffic roundabout is a good
&gt;example, with cars moving in and out with such effective organization. How can people
&gt;predict the flow of traffic to drive safely to their destination? This seems obvious if you have
&gt;experience driving on a populated roadway. These drivers don’t know everything about this
&gt;roundabout (how it was built, the names of the drivers in the other cars), but they know
&gt;how they function. This only requires part of an understanding of a roundabout. Another
&gt;example the phenomenon of life as studied in biology - it is an emergent property of
&gt;chemistry, and psychological phenomena emerge from the neurobiological phenomena of
&gt;living things.
&gt;
&gt;From Wikipedia, “Emergence Theory” - Whenever there is a multitude of individuals
&gt;interacting, an order emerges from disorder; a pattern, a decision, a structure, or a change
&gt;in direction occurs.
&gt;
&gt;(I’m only quoting Wikipedia because it’s an example of an emergent property of human
&gt;communication and organization.)
&gt;
&gt;I think you would be interested in researching complexity theory as well as computational
&gt;complexity theory.
&gt;
&gt;“Complexity theory is the study of complex and chaotic systems and how order, pattern,
&gt;and structure can arise from them.”
&gt;
&gt;“Computational complexity theory is a branch of the theory of computation in theoretical
&gt;computer science that focuses on classifying computational problems according to their
&gt;inherent difficulty, and relating the resulting complexity classes to each other.[1] A
&gt;computational problem is understood to be a task that is in principle amenable to being
&gt;solved by mechanical application of mathematical steps, such as an algorithm, which is
&gt;equivalent to stating that the problem may be solved by a computer.
&gt;
&gt;A problem is regarded as inherently difficult if its solution requires significant resources,
&gt;whatever the algorithm used.”
&gt;
&gt;Something I’ve derived from studying complexity theory: An interesting relationship
&gt;between objective nature and subjective organisms is that as the environment becomes
&gt;increasingly complex, so does the organism.
&gt;
&gt;Also, research the hard problem of consciousness.
&gt;
&gt;:)  
&gt;(u/[Deleted])
</data>
      <data key="d8">5596</data>
      <data key="d9">11.913</data>
      <data key="d10">0.0</data>
      <data key="d11">12.2</data>
      <data key="d12">0.0569</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 3), (6, 2), (7, 1), (8, 6), (9, 1), (10, 1), (11, 5), (12, 2), (13, 3), (14, 1), (15, 4), (16, 1), (17, 8), (18, 1), (19, 3), (20, 1), (21, 1), (22, 2), (23, 5), (24, 1), (25, 1), (26, 7), (27, 2), (28, 2), (29, 6), (30, 1), (31, 3), (32, 2), (33, 1), (34, 4), (35, 15), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 3), (42, 1), (43, 1), (44, 1), (45, 1), (46, 2), (47, 3), (48, 2), (49, 2), (50, 2), (51, 1), (52, 1), (53, 1), (54, 2), (55, 2), (56, 2), (57, 5), (58, 1), (59, 1), (60, 3), (61, 1), (62, 5), (63, 3), (64, 2), (65, 1), (66, 2), (67, 3), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 2), (80, 3), (81, 2), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 3), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1), (94, 4), (95, 4), (96, 1), (97, 1), (98, 2), (99, 2), (100, 1), (101, 1), (102, 1), (103, 2), (104, 1), (105, 1), (106, 1), (107, 2), (108, 2), (109, 1), (110, 1), (111, 1), (112, 1), (113, 3), (114, 1), (115, 1), (116, 3), (117, 1), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 2), (124, 9), (125, 1), (126, 1), (127, 1), (128, 3), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 2), (140, 1), (141, 1), (142, 1), (143, 1), (144, 2), (145, 1), (146, 1), (147, 2), (148, 1), (149, 3), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 6), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 2), (180, 3), (181, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 3), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 2), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 3), (210, 1), (211, 2), (212, 1), (213, 1), (214, 1), (215, 1), (216, 2), (217, 1), (218, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 3), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 2), (240, 2), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 3), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 2), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 2), (263, 1), (264, 2), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 2), (273, 1), (274, 2), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 2), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 2), (293, 1), (294, 1), (295, 1), (296, 1), (297, 2), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1), (314, 2), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 1), (321, 1), (322, 1), (323, 1), (324, 1), (325, 4), (326, 1), (327, 1), (328, 1), (329, 1), (330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (349, 1), (350, 1), (351, 1), (352, 1), (353, 1), (354, 1), (355, 1), (356, 1), (357, 1), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 1), (364, 1), (365, 1), (366, 1), (367, 1), (368, 1), (369, 1), (370, 1), (371, 1), (372, 1), (373, 1), (374, 1), (375, 1), (376, 1), (377, 1), (378, 1), (379, 1), (380, 1), (381, 1), (382, 1), (383, 1), (384, 1), (385, 1), (386, 1), (387, 1), (388, 1), (389, 1), (390, 1), (391, 1), (392, 1)]</data>
    </node>
    <node id="c34">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d63xi</data>
      <data key="d3">e6d6410</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537539578.0</data>
      <data key="d7">**Streetlight effect**

The streetlight effect, or the drunkard's search principle, is a type of observational bias that occurs when people only search for something where it is easiest to look. Both names refer to a well-known joke:



A policeman sees a drunk man searching for something under a streetlight and asks what the drunk has lost. He says he lost his keys and they both look under the streetlight together. After a few minutes the policeman asks if he is sure he lost them here, and the drunk replies, no, and that he lost them in the park.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">980</data>
      <data key="d9">9.825</data>
      <data key="d10">0.0</data>
      <data key="d11">12.3</data>
      <data key="d12">-0.1641</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 2), (18, 3), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 3), (28, 1), (29, 1), (30, 1), (31, 3), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 2), (45, 1), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1)]</data>
    </node>
    <node id="c35">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d63xi</data>
      <data key="d3">e6d64en</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539597.0</data>
      <data key="d7">Assuming the length of your post I suggest it was written before I added the **UPD** to the main post. In there I put the key points of the research program (as the talk with u/sagaciux shown I scattered and buried them across the article so they are not obvious). Please see them if not already.

The two assumptions/intuitions mentioned are the reason I desided to try to solve this problem.

As were said [here](https://physics.stackexchange.com/questions/229404/intuitions-for-the-simplest-model-in-which-the-evolution-of-the-laws-of-nature-a):

&gt; Apart from various other concerns one comment: Evolution comes with an increase in complexity, whereas the physical laws evolve from (possibly) a complex unified theory at large energies etc. to arguably simpler effective theories (particles, distinct forces)

If I thought that the theory of everything would be a complex one I would never tried to find it. And so the main idea from latest **UPD** takes place:

&gt; Both these intuitions give hope that the model to build would be simple and obvious in retrospect like postulates of natural selection are simple and obvious in retrospect. So there is a hope that it's feasible task.

I might be biased with [Streetlight effect](https://en.wikipedia.org/wiki/Streetlight_effect) but it still seems attractive and promising to me to search for the answer in this simple form.</data>
      <data key="d8">1375</data>
      <data key="d9">8.043</data>
      <data key="d10">0.0</data>
      <data key="d11">10.5</data>
      <data key="d12">0.2279</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 2), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 3), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 3), (74, 1), (75, 1), (76, 3), (77, 1), (78, 1), (79, 1), (80, 1), (81, 2), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 2), (88, 1), (89, 1), (90, 1), (91, 1), (92, 3), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1)]</data>
    </node>
    <node id="c36">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4aznhr</data>
      <data key="d3">e4b5cpc</data>
      <data key="d4">sagaciux</data>
      <data key="d5">4</data>
      <data key="d6">1534475336.0</data>
      <data key="d7">Reading through section 0, I still feel there is too much ambiguity to approach the problems in section 0.1. For example, what is an individual? You postulate that natural selection begins with individuals and their environment, then later you describe natural selection as the change of the model's structure over time. I'm not entirely sure how you define structure, but I'm going to guess that it's the state of the model at a given time - a bunch of numbers, presumably. As time advances, you apply some rules and get a new state/structure. How can you identify individuals within this state/structure? Are there multiple individuals, or just one? How are individuals created/destroyed? I understand you're not sure about this either, but I think before you can even begin to answer your later questions, you need to solve the smaller problem of how to define individuals and their environment. Presumably, both are separate entities, yet they exist in a common state/structure.

I think it's impossible to answer a big general question without breaking it down into easier to manage parts. It's a bit like asking, "what is love?" There are multiple and even contradicting answers to such a question because it is too vague, and so we have to ask, what kind of assumptions can we make before answering? I may have an intuition about love which guides my answer towards a certain direction, but I can't just appeal just to intuition to generate and communicate my answer. If I want others to understand what my answer, or even my question, is, I need to precisely explain what I mean, and why I choose to make certain assumptions.

In your article, you assume for example, that a) the complexity of the universe is a result of evolution, and b) evolution is a product of natural selection, heredity, and variation. I'm not saying your assumptions are right or wrong, but you have to admit that if they are true, there must be individuals who can undergo evolution in your universe. Thus, "what is an individual?" is not merely speculative for your model - it is a mandatory question that is required for your model to work. On the other hand, if you change your assumptions and say that the state/structure as a whole can undergo "evolution" (how would you even define evolution in this case?), then you don't need a definition of individuals at all! And what if there's some mechanism other than evolution which can increase the complexity of the universe? These are some of the questions which come to my mind when reading your ideas.</data>
      <data key="d8">2539</data>
      <data key="d9">9.874</data>
      <data key="d10">0.0185</data>
      <data key="d11">9.4</data>
      <data key="d12">0.1436</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 3), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 3), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 4), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 6), (34, 1), (35, 2), (36, 3), (37, 2), (38, 3), (39, 1), (40, 1), (41, 2), (42, 3), (43, 3), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 2), (55, 1), (56, 1), (57, 1), (58, 3), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 6), (67, 2), (68, 2), (69, 3), (70, 2), (71, 2), (72, 3), (73, 1), (74, 2), (75, 1), (76, 2), (77, 5), (78, 1), (79, 1), (80, 1), (81, 8), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 3), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 3), (109, 1), (110, 1), (111, 2), (112, 1), (113, 1), (114, 1), (115, 1), (116, 2), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 3), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 3), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 2), (141, 1), (142, 1), (143, 4), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 2), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 2), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1)]</data>
    </node>
    <node id="c37">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4alo5d</data>
      <data key="d3">e4am7vz</data>
      <data key="d4">noam_compsci</data>
      <data key="d5">1</data>
      <data key="d6">1534459324.0</data>
      <data key="d7">Thanks! Looking forward to reading. </data>
      <data key="d8">36</data>
      <data key="d9">5.8</data>
      <data key="d10">0.0</data>
      <data key="d11">7.6</data>
      <data key="d12">0.2463</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c38">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4alv3q</data>
      <data key="d3">e4asmt5</data>
      <data key="d4">daermonn</data>
      <data key="d5">5</data>
      <data key="d6">1534464782.0</data>
      <data key="d7">Hey! I think some of my readings in recent years are relevant to what you're trying to do. It's a really fascinating space. 


Generally, agency is a thermodynamic engine that consumes resources to produce work that's invested in the agent's future productive capabilities, with the side-effect of entropy production. From the perspective of the universe, entropy production hastens time and renders the universe a simpler computational object, so entropy-maximizing paths - including abiogenesis - are more likely to be realized. There's deep math in information theory, thermodynamics, and (quantum) physics that I don't understand well enough yet, but that's the overall picture.


Here are some links to authors/concept that might be valuable to you:

* [Causal Entropic Forces - Wisner-Freer &amp; Gross](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.110.168702): a formal model of agency roughly along the lines sketched above, where an agent produces/disperses entropy to maximize future freedom of action

* [Friston's free energy model of agency](https://en.wikipedia.org/wiki/Free_energy_principle): another formal model of agency from a neuroscientific perspective, with a focus on free energy in the system

* [Empowerment: An agent-centric model of control](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.8746&amp;rep=rep1&amp;type=pdf) - Klyubin et al.: another model of agency, with a focus on the throughput velocity of information through an agent's sensor-actuator circuit 

* [Jeremy England's work](http://www.englandlab.com/) on the entropic gradient that incentivizes abiogenesis


Some other folks writing in the space that I'm much less familiar with:

* Ilya Prigogine, of course, who won the Nobel for his work on the nature of time, irreversibility in thermodynamic systems, far-from-equilibrium dynamics, and dissipative structures

* Alfred Lotka, a 20thC physicist who wrote extensively on the relationship between evolution and physics

* [Rod Swenson](http://philosophyofscience.org/), who is apparently regarded as a bit of a crackpot, but whose ideas seem very interesting

* Chaisson's [Energy Rate Density as a Complexity Metric &amp; Evolutionary Driver](http://www.paulchefurka.ca/Thermo%20Reading%20List/Chaisson%202010%3B%20Energy%20Rate%20Density%20as%20a%20Measure%20of%20Complexity.pdf) is another work in this space I'm not terribly familiar with

* Philosophers like Bataille, Deleuze &amp; Guattari, contemporary accelerationists, etc have interesting ideas around this from the perspective of continental philosophy, which is just as hard to parse as the math but along a different dimension


Check out also, e.g., the [quantum source of spacetime](http://www.nature.com/news/the-quantum-source-of-space-time-1.18797), which casts space as quantum entanglement networks and time as the breaking of entanglement, which is apparently a big improvement in the complexity of the math we use to represent spacetime, and which provides a path forward for quantum gravity as the density of entanglements. This is important because entropy is in some sense a measure of entanglement or causal relationships; think about entropy as information-theoretic uncertainty within a causal model of epistemology for an intuition pump here.


It sounds like you're less interested in, e.g., specific models of agency,


At the end of the day, I don't really know. I wish I could be more helpful. Most generally, there's some super-deep, super-important underlying unity between thermodynamics, information theory, physics and cosmology, evolutionary processes, machine learning and optimization, linear algebra and topology, markets and efficiency, etc etc etc, but I don't have the mathematical maturity of conceptual clarity to really explicate it. 


Godspeed, let me know what you find!</data>
      <data key="d8">3826</data>
      <data key="d9">10.931</data>
      <data key="d10">0.0</data>
      <data key="d11">16.0</data>
      <data key="d12">0.2442</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 3), (5, 1), (6, 1), (7, 4), (8, 1), (9, 2), (10, 1), (11, 2), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 3), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 5), (29, 1), (30, 2), (31, 1), (32, 1), (33, 3), (34, 1), (35, 1), (36, 3), (37, 2), (38, 1), (39, 1), (40, 1), (41, 2), (42, 3), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 5), (54, 2), (55, 2), (56, 2), (57, 2), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 4), (64, 3), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 2), (82, 1), (83, 1), (84, 1), (85, 6), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 3), (93, 2), (94, 2), (95, 2), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 2), (121, 1), (122, 1), (123, 3), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 2), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 2), (150, 1), (151, 2), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 2), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 2), (179, 1), (180, 2), (181, 1), (182, 1), (183, 4), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 2), (193, 1), (194, 1), (195, 2), (196, 2), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 2), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1)]</data>
    </node>
    <node id="c39">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4alv3q</data>
      <data key="d3">e4amfzv</data>
      <data key="d4">Anonymous</data>
      <data key="d5">2</data>
      <data key="d6">1534459517.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c40">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4ccl57</data>
      <data key="d3">e4ccl9v</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1534523002.0</data>
      <data key="d7">**Streetlight effect**

The streetlight effect is a type of observational bias that occurs when people only search for something where it is easiest to look.It is also called a drunkard's search, after the joke about a drunkard who is searching for something he has lost:



A policeman sees a drunk man searching for something under a streetlight and asks what the drunk has lost. He says he lost his keys and they both look under the streetlight together. After a few minutes the policeman asks if he is sure he lost them here, and the drunk replies, no, and that he lost them in the park. The policeman asks why he is searching here, and the drunk replies, "this is where the light is".The anecdote goes back at least to the 1920s,

and has been used metaphorically in the social sciences since at least 1964, when Abraham Kaplan referred to it as "the principle of the drunkard's search".

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1319</data>
      <data key="d9">10.353</data>
      <data key="d10">0.05</data>
      <data key="d11">11.1</data>
      <data key="d12">-0.1545</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 3), (22, 3), (23, 2), (24, 1), (25, 2), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 3), (32, 1), (33, 1), (34, 4), (35, 1), (36, 2), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 3), (43, 1), (44, 1), (45, 1), (46, 3), (47, 2), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1)]</data>
    </node>
    <node id="c41">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4ccl57</data>
      <data key="d3">e4cdzfr</data>
      <data key="d4">Anonymous</data>
      <data key="d5">1</data>
      <data key="d6">1534526005.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c42">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4cfh25</data>
      <data key="d3">e4cj3d5</data>
      <data key="d4">Meguli</data>
      <data key="d5">1</data>
      <data key="d6">1534535389.0</data>
      <data key="d7">I am not well-versed in this area but a model that strong may not be within the boundaries of halting problem. As I said, I am not that experienced and have no clue whether you can escape limitations of Chaitin's constant. Still, I think that's a good starting point for theoretical analysis.

In a lecture, I saw Chaitin's dislike for dynamical models approach to this problem and he was criticizing Turing for dabbling in PDEs for such problems. But that kind of numeric optimization might be your only bet. </data>
      <data key="d8">510</data>
      <data key="d9">6.149</data>
      <data key="d10">0.0</data>
      <data key="d11">9.1</data>
      <data key="d12">0.0184</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]</data>
    </node>
    <node id="c43">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4e903v</data>
      <data key="d3">e4fap4m</data>
      <data key="d4">sagaciux</data>
      <data key="d5">2</data>
      <data key="d6">1534649092.0</data>
      <data key="d7">I would suggest that smartness is more important than luck, because there are too many possibilities to stumble upon one by accident. One of Godel, Escher, Bach's arguments is how a self-referencing "strange loop" can be constructed from Godel's incompleteness theorem. What's interesting to me is how specific this construction is, and how long it takes. It's not an argument you could stumble upon, rather, it's something that was carefully thought out and constructed, piece by piece.

The fact that nobody has previously answered your question should be a sign that it is a very hard question. You may not know of anyone who has tried to bring math and natural selection into solving this problem, but if there are thousands of smart people who have thought about it, what are the chances nobody has tried this combination? I mean, I've thought about it in the past as well, which is why I'm interested in engaging you. As for metaphysical ideas, without knowing a solution, how do you know your metaphysical intuitions are leading in the right direction?</data>
      <data key="d8">1059</data>
      <data key="d9">6.976</data>
      <data key="d10">0.0123</data>
      <data key="d11">10.8</data>
      <data key="d12">0.2419</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 4), (39, 1), (40, 2), (41, 3), (42, 3), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 2), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 2)]</data>
    </node>
    <node id="c44">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4i9z3i</data>
      <data key="d3">e6d5bn9</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538240.0</data>
      <data key="d7">Yes, you got the main difference right. Apart from that, effective theories describe a smaller part of the reality than the unified theories. So there is no surprise that they are simpler. The assumption of the simpler state in the past and evolution that creates complexity is the attempt to answer the "Why these laws question". I cannot forsee any other ways of answering it.

And also this question fits well with Lee Smolin assumption of cosmological natural selection.

Thank you for the comment. It's a good question about the viability of the research problem.</data>
      <data key="d8">568</data>
      <data key="d9">6.389</data>
      <data key="d10">0.0423</data>
      <data key="d11">6.8</data>
      <data key="d12">0.2803</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1)]</data>
    </node>
    <node id="c45">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iaahk</data>
      <data key="d3">e4iaarn</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534783962.0</data>
      <data key="d7">The name of the article is not mentioned here but it's "The Ultimate Question of Life, the Universe, and Everything". And there is a reason for it. Well enough justified (from philosophical point of view) model of open ended evolution would be a very good candidate to answer The Question. And I have no hope that such a question can be solved by splitting to smaller parts. I also can tell that all that I know about this problem suggests that it cannot be split to smaller components. But it's only my intuition so it's not an argument...

But you've got the point that breaking into smaller components can be useful - it would provide intuitions and habits of how to deal with that small parts. With these intuitions and habits the task would be easier. But this aside: I do not see how this can be slit up. Not a single idea. As I said [**here**](https://www.reddit.com/r/compsci/comments/97s8dl/on_natural_selection_of_the_laws_of_nature/e4c4ghi) the hardest part is to formulate what are the individuals in the model and how they work (they are weakly constrained by expectations of open-endedness and some occam's-razor-like metaphysics). How to split that?</data>
      <data key="d8">1164</data>
      <data key="d9">8.077</data>
      <data key="d10">0.0515</data>
      <data key="d11">7.8</data>
      <data key="d12">0.1557</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 3), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 6), (47, 1), (48, 3), (49, 1), (50, 1), (51, 3), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1)]</data>
    </node>
    <node id="c46">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iaeaa</data>
      <data key="d3">e4iaefr</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534784191.0</data>
      <data key="d7">For this I assume that the fixed laws of nature can be the properties of the universe that may be one of the individuals-universes from Lee Smolin's [Cosmological natural selection](https://en.wikipedia.org/wiki/Lee_Smolin#Cosmological_natural_selection).

It's unknown why laws of nature are this way not the other. I cannot come with idea better than the proposed research task described in the main post.</data>
      <data key="d8">407</data>
      <data key="d9">7.773</data>
      <data key="d10">0.0</data>
      <data key="d11">12.0</data>
      <data key="d12">0.2004</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 2), (9, 1), (10, 1), (11, 2), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c47">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iaqod</data>
      <data key="d3">e4iarpt</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534785025.0</data>
      <data key="d7">Presumably, there are many "layers" on which populations exist. The vertices themself are
the atomic individuals that are characterised by their edges. All the vertices are the basic population. But the goal of the model is to get the individuals at higher levels: as patterns in the graph (there may be even cycles of patterns changing to each other, like wave). The interesting individuals are patterns (subgraphs that persist in the changing graph during time). And there expected layers on layers.</data>
      <data key="d8">501</data>
      <data key="d9">7.66</data>
      <data key="d10">0.014</data>
      <data key="d11">8.6</data>
      <data key="d12">0.1272</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 3), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 3), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1)]</data>
    </node>
    <node id="c48">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d591z</data>
      <data key="d3">e6d5cgx</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538277.0</data>
      <data key="d7">Strictly speaking it's a a bit justified hope that natural selection can explain... everything :) It is connected to the idea of self-justifying models of universe (see more details in [section 7.1](https://kiwi0fruit.github.io/ultimate-question/#s7_1)).

Though as the pool of ideas I came with is still not self-justifying enough but my intuition suggests that the closest to self-justifying I can imagine are set of postulates from [section 7.2](https://kiwi0fruit.github.io/ultimate-question/#s7_1) (they are in Update 2 in this Reddit post).

I don't know better candidates for explaining open-ended universe that have a balance of random and predetermined. So I bet on natural selection as it's a description of a such balanced process. **Actually the whole [section 7](https://kiwi0fruit.github.io/ultimate-question/#s7) is my attemt to justify the claim together with noting it's obvious problems**.

To that I can add that I'm sure that any explanation of novelty generation in the universe would require either absolute random (like in independent random events in postulates of probability theory) or infinite past/actual infinity as a carpet to sweep under (to sweep the moment when novel information/event came to existence - like the result of the die toss in probability theory). But what framework to use together with random? I guess there are some theories of "emergence" out there but natural selection is a more obvious choice.
</data>
      <data key="d8">1448</data>
      <data key="d9">8.918</data>
      <data key="d10">0.0069</data>
      <data key="d11">13.1</data>
      <data key="d12">0.1668</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 3), (11, 1), (12, 1), (13, 2), (14, 3), (15, 3), (16, 3), (17, 1), (18, 6), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 3), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 3), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1), (94, 2), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1)]</data>
    </node>
    <node id="c49">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d5je4</data>
      <data key="d3">e6d5k8r</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538634.0</data>
      <data key="d7">Not a this stage of the research definitely. Any stable laws (or better call them stable phenotype?) would be OK. But the model should be open-ended - that doesn't stop on fixed level of complexity and is capable to evolve to sentient artificial life (I doubt that all path to intelligence is within reach of our computational abilities but don't stopping and continuing should be possible).</data>
      <data key="d8">391</data>
      <data key="d9">5.981</data>
      <data key="d10">0.0</data>
      <data key="d11">9.6</data>
      <data key="d12">0.4885</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 2), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1)]</data>
    </node>
    <node id="c50">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5ffp</data>
      <data key="d3">e6h5foi</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537708971.0</data>
      <data key="d7">The first problem resolves quickly: this whole research is a hypothesis. So the possibility of distinguishing is not meant at all.

There is no need for cites for tychism as it's not really important to the picture. But if someone is qurious (s)he can google it (but I still need to fix this bug). As for other terms that matter and may be unfamiliar: I thoght there were either cites or hyperlinks...</data>
      <data key="d8">401</data>
      <data key="d9">5.145</data>
      <data key="d10">0.0</data>
      <data key="d11">6.5</data>
      <data key="d12">-0.1369</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1)]</data>
    </node>
    <node id="c51">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d64en</data>
      <data key="d3">e6d654w</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539633.0</data>
      <data key="d7">&gt;Yeah I wrote that before you updated the post. Now I see that you’re really looking
&gt;for a simple theory of everything and I understand what you mean. I briefly read your
&gt;article and I can see you’ve spent a lot of time and effort into the question you
&gt;originally asked. Sorry for trying to put words in your mouth.
&gt;
&gt;You’re trying to come up with a theory of how laws of physics evolve. Is this correct?  
&gt;(u/[Deleted])
</data>
      <data key="d8">426</data>
      <data key="d9">5.542</data>
      <data key="d10">0.0</data>
      <data key="d11">6.0</data>
      <data key="d12">0.0365</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]</data>
    </node>
    <node id="c52">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4b5cpc</data>
      <data key="d3">e4c2lom</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534506986.0</data>
      <data key="d7">&gt; And what if there's some mechanism other than evolution which can increase the complexity of the universe?

I would be curious to learn about such mechanism. I guess there can be imagined some. But I guess they would fall somewhere between natural selection postulates (plus something yet unknown that would allow to precisely define what is an individual) and between sentient god that created the universe this morning with me unshaven.

The more complex structures we introduce as axioms to generate open ended dynamic universe the more we would feel the need to answer "Why these particular structures?" question.

By the way, if we ever to create the general artificial intelligence then it could be possible to make an assumption that the Universe started with a such an AI precisely defined (plus something to drive process).

But still I feel like starting with something as simple as possible is much preferable.</data>
      <data key="d8">923</data>
      <data key="d9">7.52</data>
      <data key="d10">0.0358</data>
      <data key="d11">10.5</data>
      <data key="d12">0.3963</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 2), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 3), (32, 1), (33, 2), (34, 3), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 3), (42, 4), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1)]</data>
    </node>
    <node id="c53">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4b5cpc</data>
      <data key="d3">e4c4ghi</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534509287.0</data>
      <data key="d7">&gt; but I think before you can even begin to answer your later questions, you need to solve the smaller problem of how to define individuals and their environment

I guess I failed to say it properly. And it's a good point to note **but** the all metaphysical considerations, all guesses and other questions are there for only one purpose: to help find out what should be the individuals (environment should be other individuals presumably - again from simplicity considerations) so that their dynamic would lead to natural selection with open ended evolution that does not stop on fixed level of complexity.

I/we should answer this only question and then make a research if open ended evolution is the case in a formulated model (how to do it is another question).

So again. The most of the assumptions I made are for philosophical self-justification that take form of choosing the simplest structures. I guess I choose them also because it's easier to work with them :)

</data>
      <data key="d8">973</data>
      <data key="d9">7.259</data>
      <data key="d10">0.0</data>
      <data key="d11">16.0</data>
      <data key="d12">0.052</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 3), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 2), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (50, 1), (51, 1), (52, 3), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1)]</data>
    </node>
    <node id="c54">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4b5cpc</data>
      <data key="d3">e4ca5zp</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534518135.0</data>
      <data key="d7">The whole article is a description of the research program aimed to create an atrificial universe in which we can answer any questions like "why is the present is this way not another?" (it's a better formulated ancient question "Why is there something rather than nothing?"). And this universe formulation should be enough simple and self-justifying to be a candidate for model of the our real universe.

And there are two main intuitions-constraints for this universe: 1) the start from the simple enough state (the beggining of time), 2) the complexity capable of producing sentient beings (after enormous simulation time of cource) comes from natural selection. And natural selection postulates hold in the universe formulation.

Both these intuitions give hope that the model to build would be simple and obvious in retrospect like postulates of natural selection are simple and obvious in **retrospect**. So there is a hope that it's feasible task.

The "only" thing is left is to precisely define what are individuals and environment in the model (environment should be other individuals presumably - again from simplicity considerations) and how the process of their replication and death takes place. At the moment I'm not even sure if the individuals should be bult-in or to be emergent... (but I lean to the first option).

And sadly I have not moved far to this goal. I'm still in the situation of "I feel like the answer the this grand question can be obtained this particular way".</data>
      <data key="d8">1495</data>
      <data key="d9">8.746</data>
      <data key="d10">0.1177</data>
      <data key="d11">11.2</data>
      <data key="d12">0.1893</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 3), (17, 3), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 3), (28, 4), (29, 1), (30, 1), (31, 3), (32, 6), (33, 3), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 3), (48, 1), (49, 1), (50, 1), (51, 3), (52, 2), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 2), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 3), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1)]</data>
    </node>
    <node id="c55">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4asmt5</data>
      <data key="d3">e4aw6ql</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534467717.0</data>
      <data key="d7">Oh my macaroni! That would be a hard read through (when I get free time and motivation). Thanks a lot as it seems like there can be something very useful.

If not my metaphysical hopes I would have dropped this task long ago. And hopes are about that the desired model should be simple enough to imagine and create (even for me): start from the simplest state of finite and discrete space (presumably that consist of atomic agents that can influence/change each other), laws that govern change of the space are immanent to agents and not much more complex than natural selection postulates, and etc.</data>
      <data key="d8">599</data>
      <data key="d9">5.866</data>
      <data key="d10">0.0</data>
      <data key="d11">7.9</data>
      <data key="d12">0.3535</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1), (60, 4), (61, 1)]</data>
    </node>
    <node id="c56">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4fap4m</data>
      <data key="d3">e4ghpsu</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534707907.0</data>
      <data key="d7">That's definitely a hard problem. But I hope it has a non-complex non-obvious solution (see the **UPD** to he main post). All I did actually for solving the problem is that I came up with some intuitions in what direction the solution can be obtained. These intuitions might lead in the wrong direction. I'm aware of it. But taking into account metaphysical considerations about simplicity and justified complexity (that root to the "the world was created this morning with me unshaven"-like considerations) I can image only two solutions to the problem:

1. Minimal open-ended model with natural selection that has the beginning of time
2. Model with general artificial intelligence at the beginning of time (aka The God)

As we all know the natural selection is capable of producing sentient beings so it's simpler from Occam's razor to go with the first option not the second.

P.S.

The beginning of time metaphysically justified by anti-"intinite elephants"-like considerations.


</data>
      <data key="d8">986</data>
      <data key="d9">7.153</data>
      <data key="d10">0.072</data>
      <data key="d11">11.3</data>
      <data key="d12">0.2302</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 5), (49, 1), (50, 1), (51, 1), (52, 3), (53, 1), (54, 2), (55, 1), (56, 2), (57, 3), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1)]</data>
    </node>
    <node id="c57">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iaefr</data>
      <data key="d3">e6d5qsg</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537538939.0</data>
      <data key="d7">&gt; It is very possible that the structure that create what we call laws of nature have gone through some selection. If we observe something it is probably stable. Unstable structure collapse in stable one, this is also a description of biological evolution. 'Bird can fly' can be interpreted as law of nature, emerging from the structure of a bird (or its genetic code), which is collapsed from a less stable from and it's collapsing in more stable ones. The same way chemical law emerge from the structure of atoms which is stable form of matter. You can go down the abstraction all as deep as you want. The idea of evolution of law is for me well grounded. But computational model of it trivial, in the sense that is no different from simulating biological evolution. In computation evolution and selection is reduced to it's logical form that is the same no matter the context. You can use genetic algorithm to solve puzzle, play super mario or simulate cellular evolution but the model isn't changing a lot. All you change is the fitness function and the description of the replicator.
&gt;
&gt; In conclusion, i think evolution of nature law is an interesting ontological idea but uneventful computation model wise.  
&gt; ([u/TheTorla](https://www.reddit.com/r/evolution/comments/97s3ma/on_natural_selection_of_the_laws_of_nature/e4k70zr/))</data>
      <data key="d8">1336</data>
      <data key="d9">9.008</data>
      <data key="d10">0.0</data>
      <data key="d11">11.2</data>
      <data key="d12">0.117</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 4), (28, 2), (29, 1), (30, 1), (31, 2), (32, 5), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 4), (72, 1), (73, 4), (74, 1), (75, 4), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 2), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1)]</data>
    </node>
    <node id="c58">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iarpt</data>
      <data key="d3">e4iase3</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534785064.0</data>
      <data key="d7">&gt; To me, it is still unclear how individuals, individual traits and the population is represented in your model. It would probably be useful if you clearly defined how 'individual', 'individual properties' (which represent individual "complexity") and 'population' are represented in the model directly in your question, e.g. vertex = xxx, graph =yyy, edge = zzz.  
&gt; ([fileunderwater](http://biology.stackexchange.com/users/3624/fileunderwater))</data>
      <data key="d8">446</data>
      <data key="d9">8.279</data>
      <data key="d10">0.0247</data>
      <data key="d11">19.8</data>
      <data key="d12">0.2154</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1)]</data>
    </node>
    <node id="c59">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d5k8r</data>
      <data key="d3">e6h5iik</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537709097.0</data>
      <data key="d7">&gt; Your problem is right here - nobody has any good definition of open-endedness, and there is no convincing demonstration of any open-ended systems. So you set out solve a major open problem, that so far wasn't even clearly defined. No wonder you will find it difficult and will get no substantial help from the others.
&gt;
&gt; The "capable to evolve to sentient artificial life" property cannot even be approached now, there is not a single clue about the necessary requirements for that.
&gt;
&gt; Also, you seem to contradict yourself. Either there is a stable phenotype, or the endless increase of complexity. One excludes the other.  
([u/sorrge](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6du0w4/))</data>
      <data key="d8">748</data>
      <data key="d9">7.451</data>
      <data key="d10">0.0615</data>
      <data key="d11">11.4</data>
      <data key="d12">0.0075</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 3), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1)]</data>
    </node>
    <node id="c60">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6d654w</data>
      <data key="d3">e6d65dz</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537539645.0</data>
      <data key="d7">I hope that something that resemble the laws of physics emerge in the model. But that not the thing I'd like concentrate on. I'm more interested in seeing the emerging populations of individuals that are stable and have enough coherent behavior (like individuals in a pulation quiet alike in comparison with other species). And then seeing that populations change in time and become more and more complex.

As about laws of physics: they may be a properties of a particular individual universe if we are to remember the cosmological natural selection by Lee Smolin. (if we are under mentioned research assumptions of simplicity).

So the task is much more about special case of artificial life and open-ended evolution than about physical laws. But the desired model can still be a good candidate for a theory of everything. But it might (or would) be very hard to test it.

It also may be that there is a way that position invariant  laws on physics (that hold across the universe) can emerge from natural selection. It's an interesting way of research but I haven't thought of it much...</data>
      <data key="d8">1089</data>
      <data key="d9">7.728</data>
      <data key="d10">0.0</data>
      <data key="d11">8.7</data>
      <data key="d12">0.3266</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 3), (17, 1), (18, 1), (19, 4), (20, 1), (21, 2), (22, 2), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 7), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 3), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1)]</data>
    </node>
    <node id="c61">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4c2lom</data>
      <data key="d3">e4fb4fx</data>
      <data key="d4">sagaciux</data>
      <data key="d5">2</data>
      <data key="d6">1534649528.0</data>
      <data key="d7">Here's a trivial example of a system that "increases the complexity of the universe". Suppose I define a universe in which there exists only a mathematical machine that outputs the digits of pi. Over time, the universe fills up with the machine's output - successive digits of pi. This universe is getting more complex over time, because pi never repeats. But this is obviously not an interesting universe, let alone a model of our universe. It does not have self-conscious individuals, for example.

My point is, there are plenty of possible universes (infinite, even) that get more complex over time. You are going to need a more precise definition of the complexity that you are looking for. A general artificial intelligence is a good candidate for generating "comlexity" because it is self-referential and self-modifying - except this is a very hard problem that hasn't been solved yet. If such an AI is the foundation of the solution to your problem, that suggests your problem is even harder than the problem of general AI.</data>
      <data key="d8">1030</data>
      <data key="d9">8.078</data>
      <data key="d10">0.0495</data>
      <data key="d11">10.0</data>
      <data key="d12">-0.0825</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 2), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 3), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 6), (36, 2), (37, 2), (38, 2), (39, 1), (40, 3), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 3), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2)]</data>
    </node>
    <node id="c62">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4ca5zp</data>
      <data key="d3">e4fc3ou</data>
      <data key="d4">sagaciux</data>
      <data key="d5">2</data>
      <data key="d6">1534650540.0</data>
      <data key="d7">I feel the entire problem still comes down to defining your individuals and their environment. For example, is there physical distance in your model? What are your individuals trying to maximize (what is their goal)? Natural selection presumably means some of these individuals will die or otherwise fail to reproduce. What are the fitness criterion that govern this? How do your individuals decide what to do? Are they governed by a computer code? What actions does this code allow? If there is reproduction and variation, these codes would have to be combined in a way that doesn't break their functionality.

I imagine there are countless ways to define a model, most of which don't result in "complexity". If someone magically gave you a "solved" model that does what you want, it would be trivial to prove or disprove each of your intuitions and assumptions by comparing it with the solved model. But finding that model *is* the problem. As they say, the devil is in the details.

When I find myself stuck on a problem, it's usually a sign I need to take a break, rethink my goals, and learn about different approaches. Similarly, if I am having trouble communicating my ideas to someone, it is usually because I don't understand it clearly myself.</data>
      <data key="d8">1253</data>
      <data key="d9">7.791</data>
      <data key="d10">0.0144</data>
      <data key="d11">7.7</data>
      <data key="d12">-0.169</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 4), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 4), (44, 3), (45, 3), (46, 2), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 2), (55, 5), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 2)]</data>
    </node>
    <node id="c63">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4aw6ql</data>
      <data key="d3">e4b5zpd</data>
      <data key="d4">daermonn</data>
      <data key="d5">1</data>
      <data key="d6">1534475885.0</data>
      <data key="d7">Haha yeah, it's a lot, I sympathize as I never do the readings I should.


And yeah, sounds like you will be most interested in the underlying thermodynamics/information theory/statistical mechanics.</data>
      <data key="d8">199</data>
      <data key="d9">5.75</data>
      <data key="d10">0.0</data>
      <data key="d11">12.7</data>
      <data key="d12">0.7041</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c64">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4iase3</data>
      <data key="d3">e4iaspq</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534785086.0</data>
      <data key="d7">Current assumption: vertexes=individuals, edges=individual traits and the graph=population. But this is only at the "basic level". Patterns are also individuals but on the "next level".</data>
      <data key="d8">185</data>
      <data key="d15">6</data>
      <data key="d10">0.1243</data>
      <data key="d11">12.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c65">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5iik</data>
      <data key="d3">e6h5jhc</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537709140.0</data>
      <data key="d7">There's no contradiction: relatively stable on one time period may be chainging on another.</data>
      <data key="d8">91</data>
      <data key="d9">5.846</data>
      <data key="d10">0.0</data>
      <data key="d11">12.3</data>
      <data key="d12">-0.25</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]</data>
    </node>
    <node id="c66">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5iik</data>
      <data key="d3">e6h5ka9</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537709179.0</data>
      <data key="d7">And I'm fully aware that the problem is hard and help would be a rare accasion... C'est la vie.</data>
      <data key="d8">95</data>
      <data key="d9">3.8</data>
      <data key="d10">0.0</data>
      <data key="d11">2.3</data>
      <data key="d12">-0.0513</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c67">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4fc3ou</data>
      <data key="d3">e4gjz6s</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534711836.0</data>
      <data key="d7">It seems to me that I at least managed to communicate the problem :)

Yep, the devil is in details. Even using all metaphysical assumptions I've got it still isn't enough to figure out what would individuals look like. And randomly create models and test them is not an option. I still lack some pieces for the puzzle (assuming it's the right puzzle and it exists).

As about some of your questions:

* I would start from something like enchanced grapf like structure. So the distance is an emergent property. And the basic entity that form space is a link that means the possibility of action-impact
* Individuals don't have a goal but they have free-will that is simply a random choice from available actions-impacts to their neighbors (or to themselves even)
* I think that there should not be environment only individuals that are environment to each other. And the finness criteria comes from the Red Queen hypothesis.
* The most tricky part is that the individuals should somehow contain an algorithm that defines impacts on the neighborhood. So that algorithm changes neighbors' algorithms. Or even the algorithm changes itself also.
* **UPD** Or maybe there still should be some medium in which the algorithms with individuals emerge... 


By the way, I'm on a break from this problem since summer 2016. And I still hold frustration for it...
</data>
      <data key="d8">1351</data>
      <data key="d9">7.549</data>
      <data key="d10">0.0</data>
      <data key="d11">8.3</data>
      <data key="d12">-0.075</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 9), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 4), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 3), (31, 4), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 4), (48, 1), (49, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 2), (78, 1), (79, 1), (80, 1), (81, 1), (82, 3), (83, 2), (84, 1), (85, 3), (86, 1), (87, 1), (88, 2), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1)]</data>
    </node>
    <node id="c68">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5ka9</data>
      <data key="d3">e6h5mdb</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537709268.0</data>
      <data key="d7">&gt; Bon courage!
&gt;
&gt; I also tried to make such systems. I don't see in your text mentioning of key obstacles to OEE as I understand them. In the chapter "minimum model for OEE" you mix the description of the model and the requirements for it, the latter poorly defined. Concretely,
&gt;
&gt; * "there should be the evolution of such patterns" - the evolution and patterns are not formally defined
&gt; * "that lead to their complication" - complexity is not defined
&gt; * "incorporation the information about the graph structure or about other patterns" - information about ... and how it should be incorporated is not defined
&gt; * "evolution is led by competition for “staying alive” of such patterns with each other" - life, death is not described
&gt;
&gt; So your description is, on one hand, too specific without justification, e.g. it is never said why is the concept of life and death required, or what does it even mean. On the other hand, it is too vague, in critical parts about complexity and evolution, all non-trivial concepts. As for OEE itself, it's all lumped up into the last point, "it should be the case of OEE". Any artificial system observed so far either stops at a fixed level of complexity, or generates "empty" complexity (random noise). How to define the useful/substantial/interesting complexity should be the real subject of chapter 4. Then you can start working on a model that will show the generation of such complexity.
&gt;
&gt; Moreover, there is a question of how to demonstrate that the complexity grows indefinitely. There is always a doubt of whether the complexity growth will stop if you simulate the model longer. I think nobody even mentioned this in the research articles so far, even though this is a major and obvious problem with the whole field.  
([u/sorrge](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6g7w9d/))</data>
      <data key="d8">1887</data>
      <data key="d9">8.87</data>
      <data key="d10">0.1595</data>
      <data key="d11">12.6</data>
      <data key="d12">-0.008</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 4), (13, 1), (14, 1), (15, 1), (16, 4), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 3), (25, 2), (26, 1), (27, 2), (28, 2), (29, 4), (30, 1), (31, 6), (32, 1), (33, 1), (34, 1), (35, 1), (36, 4), (37, 1), (38, 1), (39, 2), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 3), (68, 1), (69, 1), (70, 1), (71, 1), (72, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 1), (101, 2), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 2), (128, 1), (129, 1), (130, 1), (131, 1)]</data>
    </node>
    <node id="c69">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4gjz6s</data>
      <data key="d3">e4hokg0</data>
      <data key="d4">sagaciux</data>
      <data key="d5">2</data>
      <data key="d6">1534753819.0</data>
      <data key="d7">Perhaps you could start by building a simple model that demonstrates limited evolution. For example, you might include:

- __Individuals__ containing __algorithm(s)__ and __properties__
- A __genotype__ or __algorithm__ containing a __code__ governs how individuals behave, which also defines a __population__ of individuals sharing the same genotype/algorithm
- The universe's __rules__, which dictate how individuals are added, removed, or otherwise altered
- The universe's structure: some kind of graph or grid on which individuals have a location

A very simple model that contains some of these elements is John Conway's "Game of Life". There are individuals (cells) that live on a grid (a kind of graph), and they have one property: whether they are alive or dead. The universe's rules are: for every timestep, depending on the number of adjacent live cells, a cell either remains dead, becomes alive, stays alive, or becomes dead. This model exhibits very complex behavior with the right starting conditions - in fact, it has been demonstrated to be Turing complete. 

However, this model is missing the genotype or algorithm governing each individual's behavior, and thus lacks natural selection. Here's a way you might extend this model. First, each individual needs some properties that can be manipulated. For example, each cell might have a property - a number - called "energy". Second, each cell needs an algorithm and actions it can choose. For example, this algorithm might be written in a code which executes one instruction per timestep, looping back to the beginning when completed. The instructions might be WAIT, which does nothing, and GROW, which spends energy to bring a (random) adjacent cell to life. Finally, the universe's rules need to have interesting tradeoffs, so that it's not too easy or too hard for individuals to survive. For example, each cell might lose a certain amount of energy per timestep to stay alive. Each cell might also receive a certain amount of energy per timestep which depends on the number of adjacent live and dead cells. By tweaking these rules, you could make a universe in which cells have to spend energy strategically to stay alive.

Even though the model I've outlined so far lacks evolution, you can already demonstrate some interesting things. For example, you could generate random genotypes, put an initial population of that genotype in an empty universe, and see which genotypes produce the most individuals or the highest energy individuals after a certain number of timesteps. You could pit different genotypes against each other by populating them in the same universe. You could repeat these experiments on universes with varying rules, and see how those rules affect the resulting complexity of the model.

The Red Queen hypothesis isn't a fitness criterion - it simply states that individuals can become more complex by competing against each other. You need to actually define a way to measure the fitness of an individual. For example, individuals might compete by growth, in which case you are looking for a population that outnumbers the rest. To express this fitness criterion, your universe might have a rule which kills x individuals every n timesteps. Or, individuals might compete by amassing the most energy. To express this, you might have a rule killing off individuals with less than y energy.

The final missing piece for evolution is reproduction. You need rules for how genotypes can be altered within the universe. The simplest would be asexual variation - when a new cell is born, simply randomize the code that is copied. Sexual reproduction would require more complex rules for how genotypes are passed from cell to cell.

A few notes on the genotype/algorithm: first, in my outline I said each instruction takes one timestep to complete. I chose this because it gives instructions a cost, namely time, which makes shorter, simpler genomes more competitive against longer genomes. Second, if you want complex behavior to emerge out of your genomes, you'll probably want the code to be Turing complete, which means it must include branching and recursion. I haven't really thought about what code would be minimally Turing complete, but as a quick sketch, you could expand the code above to include:

- Branching: IF{a certain neighbor cell is alive/dead}, do {one action}, else do {another action}
- Recursion: GO_BACK{a certain number of instructions}

All of this would be quite interesting to build, but of course doesn't guarantee that the resulting universes would be worth studying. For example, I suspect many universes would end up in a fixed or repeating state. On the other hand, you might build a universe that gets more complex for a while, but then simply stops. In fact, even the universe we live in might have a finite limit on complexity! It is simply impossible to know - unless you can run your model for an infinite amount of time, which is also impossible (see the halting problem). As for building a universe that ends up like ours, well, personally I'm not very optimistic. Either this perfect model of our universe would have the same rules as ours, in which case we can just look at our real universe to discover them, or the model has (drastically) different rules, in which case it would be a very interesting philosophical object, but of what relevance to our universe? I can only say to you, good luck.</data>
      <data key="d8">5425</data>
      <data key="d9">11.827</data>
      <data key="d10">0.0037</data>
      <data key="d11">11.6</data>
      <data key="d12">0.081</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 6), (3, 1), (4, 1), (5, 7), (6, 2), (7, 1), (8, 13), (9, 8), (10, 2), (11, 1), (12, 12), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 1), (24, 1), (25, 1), (26, 13), (27, 3), (28, 1), (29, 16), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 4), (37, 1), (38, 2), (39, 9), (40, 2), (41, 1), (42, 4), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 3), (52, 3), (53, 1), (54, 2), (55, 1), (56, 2), (57, 1), (58, 2), (59, 9), (60, 1), (61, 2), (62, 5), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 2), (74, 1), (75, 4), (76, 5), (77, 1), (78, 1), (79, 1), (80, 6), (81, 1), (82, 1), (83, 3), (84, 2), (85, 2), (86, 4), (87, 1), (88, 3), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 3), (101, 2), (102, 3), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 5), (111, 1), (112, 5), (113, 1), (114, 1), (115, 1), (116, 1), (117, 8), (118, 1), (119, 5), (120, 1), (121, 1), (122, 2), (123, 1), (124, 1), (125, 1), (126, 1), (127, 2), (128, 2), (129, 4), (130, 1), (131, 2), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 2), (138, 2), (139, 1), (140, 3), (141, 2), (142, 1), (143, 1), (144, 1), (145, 1), (146, 3), (147, 1), (148, 1), (149, 1), (150, 2), (151, 1), (152, 1), (153, 7), (154, 1), (155, 3), (156, 1), (157, 1), (158, 7), (159, 2), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 3), (166, 1), (167, 1), (168, 1), (169, 2), (170, 1), (171, 1), (172, 1), (173, 1), (174, 4), (175, 1), (176, 1), (177, 1), (178, 2), (179, 2), (180, 1), (181, 1), (182, 2), (183, 1), (184, 1), (185, 1), (186, 2), (187, 1), (188, 1), (189, 1), (190, 1), (191, 2), (192, 1), (193, 2), (194, 3), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 3), (201, 2), (202, 1), (203, 1), (204, 1), (205, 1), (206, 2), (207, 2), (208, 3), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 4), (219, 1), (220, 1), (221, 1), (222, 2), (223, 4), (224, 1), (225, 1), (226, 1), (227, 3), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 8), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 2), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 2), (283, 2), (284, 2), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 2), (317, 1), (318, 1), (319, 1), (320, 1), (321, 1), (322, 1), (323, 1), (324, 1), (325, 1), (326, 1), (327, 1), (328, 2), (329, 1), (330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1)]</data>
    </node>
    <node id="c70">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5mdb</data>
      <data key="d3">e6h5mqt</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537709285.0</data>
      <data key="d7">&gt; your description is, on one hand, too specific without justification

All the justification I have is based on intuitive philosophical concept (lol) of self-justification that is discussed in [chapter 7](https://kiwi0fruit.github.io/ultimate-question/#s7). It's not yet properly defined and understood (as said in [ch.7.3](https://kiwi0fruit.github.io/ultimate-question/#s7_3)).

All the specifics are in the model constraints to satisfy self-justification as I see it (but there are still not enough constraints to have a well defined model). There too many possible ways to build open-ended model so these extra constraints narrow an area of possible modela. So:

* self-justification uses open-ended natural selection as a solution to "where novelty in simple models comes from?" question,
* open ended artificial life (OEAL) uses self-justification to narrow space of possible models,
* it may be expected that extra constraints would make it harder to build an OEAL but I have a hunch that two task would help each other instead (if not then the whole idea of using natural selection in [chapter 7.1](https://kiwi0fruit.github.io/ultimate-question/#s7_1) is wrong and then all the research direction is wrong, and then I have neither ideas how nor hope to solve that major philosophical problem).

&gt; How to define the useful/substantial/interesting complexity should be the real subject of chapter 4

Yep, this is another problem that would inevitable rise. But because of the sel-justification requirements (and problems with it too) I didn't get to the problem of "what is complexity?" yet.</data>
      <data key="d8">1599</data>
      <data key="d9">9.343</data>
      <data key="d10">0.0394</data>
      <data key="d11">14.5</data>
      <data key="d12">0.0521</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 2), (14, 1), (15, 4), (16, 1), (17, 2), (18, 1), (19, 1), (20, 4), (21, 5), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 4), (28, 1), (29, 2), (30, 1), (31, 2), (32, 1), (33, 1), (34, 2), (35, 2), (36, 3), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 3), (83, 1), (84, 1), (85, 3), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 2), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1)]</data>
    </node>
    <node id="c71">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4hokg0</data>
      <data key="d3">e4itpf7</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534809331.0</data>
      <data key="d7">As I always say the great role in my assumptions play intuitions of simplicity resembling Occam's razor.

And I also try to apply it to the question "What should the individual be?". And in case we try to define individuals in some particular way the question "Why individuals are this way not the other?". Answering these questions is important for justifying creation of a toy-model of universe (so that it's a universe that has The Beginning of Time not just a model that has a it's cause of existence in the form of people).

And the answer to this question should be satisfactory (that's what I called 'self-justifying' later).

For example if we build a model and define the individuals the first question is "how many individuals should we set?". From simplicity assumptions it should be one or two. Others would appear via reproduction mechanism. One is preferable but the final choice depends on dynamics we can get from one or two that depends on other properties of the model (that are yet to be defined). And if start from single individual then the next time step presumably should have two individuals. And that may give some hints about the **rules** to define.

Another possible way of justifying the individuals design is "gauging away" as Lee Smolin called it. It's like specifying [equivalence class](https://en.wikipedia.org/wiki/Equivalence_class) on a set (so the "real" structure is the structure of the equivalence class not the particular implementation) or like [Electric potential](https://en.wikipedia.org/wiki/Electric_potential) that is defined up to a constant (so the class of solutions that differ on a constant is effectively the same tool). Random thought about the model to build: different ways of defining algorithms (that are like DNA for the individuals) may be the particular implementations and the real thing is the model after "gauging away".

But I feel like going the way of "gauging away" is too tough for me... I'm not good at creating complex things aver and over again. If go this way there should be created many flawed models that would lead to my disappointment and eventually decrease motivation to zero :) So would like to leverage metaphysical considerations as much as possible.

I hope that the justification via simplicity considerations not only the extra burden to keep in mind but also a help. Because if metaphysical simplicity considerations are right hypothesis about the beginning of time then we should build a model using these considerations. But it they are wrong then I give up to build a model that may be of any complexity (and Universe itself then should be unknowable or unexplainable - with this I also give up).

&gt; I mean, I've thought about it in the past as well, which is why I'm interested in engaging you.

By the way, did you use some philosophical or common-sense considerations when you thought about? If yes then what considerations it were?

&gt; You need to actually define a way to measure the fitness of an individual.

But why? Fitness criteria as it's in bioliogy is a tool for studying the process of natural selection. It's not an objective thing that exist.

Or you simply mean the answer to the question "what death means in the model?" (and how it works). That's a good question. At the moment I cannot choose from simplicity considerations if there should be explicit death criteria in the model or it should be emerging property (like if the "genotype" is absent in the simulation at particular time then the genotype is extinct).

&gt; **algorithm(s)** and **properties**

From simplicity considerations it is desirable the algorithms actually also be the properties. That is, the properties of individuals is how they affect and change other individuals (that is should be encoded in the algorithm). But that's a hard idea to think of. When thinking about it sometimes strange loop come to mind. Sometimes that the atoms of the universe should be something more simple than individuals and the individuals emerge from these atoms...

&gt; In fact, even the universe we live in might have a finite limit on complexity!

I think that our universe is capable of containing general intelligence (artificial or not). I think the ability to reach this is good constraint, but a vague one :)

&gt; As for building a universe that ends up like ours

As stated by other commenters:

&gt; the laws of nature are not living organisms that seek to produce offspring. They are not subject to natural selection, they are just a fixed variable of the environment.

And we observe them this way. For this I assume that the fixed laws of nature can be the properties of the universe that may be one of the individuals-universes from Lee Smolin's [Cosmological natural selection](https://en.wikipedia.org/wiki/Lee_Smolin#Cosmological_natural_selection).

It's unknown why laws of nature are this way not the other. I cannot come with idea better than the proposed research task described in the main post.

&gt; but of what relevance to our universe?

My only hope for relevance to our universe is that we can judge about possible properties of the possible universes and even about their probabilities.
</data>
      <data key="d8">5169</data>
      <data key="d9">12.311</data>
      <data key="d10">0.0377</data>
      <data key="d11">10.3</data>
      <data key="d12">0.1626</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 6), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 4), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 1), (24, 1), (25, 2), (26, 9), (27, 3), (28, 2), (29, 2), (30, 8), (31, 1), (32, 4), (33, 1), (34, 5), (35, 1), (36, 12), (37, 3), (38, 18), (39, 3), (40, 8), (41, 1), (42, 8), (43, 1), (44, 1), (45, 2), (46, 2), (47, 1), (48, 1), (49, 3), (50, 1), (51, 3), (52, 1), (53, 2), (54, 1), (55, 7), (56, 1), (57, 3), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 5), (67, 3), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 3), (75, 1), (76, 1), (77, 4), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 6), (84, 3), (85, 1), (86, 3), (87, 3), (88, 1), (89, 1), (90, 3), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 2), (98, 1), (99, 1), (100, 2), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 6), (114, 3), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 2), (121, 2), (122, 3), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 7), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 3), (138, 1), (139, 1), (140, 1), (141, 2), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 2), (148, 1), (149, 1), (150, 1), (151, 2), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 2), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 2), (167, 1), (168, 3), (169, 1), (170, 1), (171, 1), (172, 1), (173, 2), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 2), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 2), (197, 1), (198, 3), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 2), (211, 1), (212, 2), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 2), (237, 1), (238, 1), (239, 1), (240, 1), (241, 2), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 2), (251, 1), (252, 3), (253, 1), (254, 1), (255, 2), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1), (277, 1), (278, 2), (279, 3), (280, 1), (281, 3), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 2), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1)]</data>
    </node>
    <node id="c72">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h5mqt</data>
      <data key="d3">e6i7fhl</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537758683.0</data>
      <data key="d7">&gt; Your self-justification argument is flawed. As I understood it, you say that natural selection created sentient life, therefore we can replace god/AGI with NS in the theory of everything. Then you propose a particular model containing NS as the basis of theory of everything.
&gt;
&gt; The problem is that NS alone is insufficient to create sentient life. Take any existing alife system with NS and see for yourself: there is no chance of sentient life to appear there. It is very likely that your proposed system will not solve the problem either. But then it cannot be self-justifying.  
([u/sorrge](https://www.reddit.com/r/alife/comments/9hdqzp/artificial_life_with_openended_evolution_for_the/e6i54dg/))</data>
      <data key="d8">704</data>
      <data key="d9">7.851</data>
      <data key="d10">0.0</data>
      <data key="d11">11.1</data>
      <data key="d12">-0.0118</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 3), (18, 3), (19, 2), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]</data>
    </node>
    <node id="c73">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4itpf7</data>
      <data key="d3">e4j23r1</data>
      <data key="d4">sagaciux</data>
      <data key="d5">2</data>
      <data key="d6">1534816503.0</data>
      <data key="d7">I don't think you can avoid philosophical or common-sense ideas if you are trying to design a universe from nothing. In my outline of "Game of Life" there are already assumptions about the existence of individuals, a grid that defines neighbors, the existence of time stepping forward... every assumption is some kind of philosophical or common-sense idea humans have about the universe. What's the point of arguing about the right assumptions, when the proof is in the model? As an analogy, you don't show that humans can fly by having a philosophical debate, you show it by building an airplane. Besides, assumptions can be wrong. Common sense says the sun goes around the Earth, but astronomy shows it makes more sense for the Earth to go around the sun.

When you are designing a model universe, things like fitness criteria and the laws of nature no longer have any intrinsic meaning, except as you define them. For example: in the real universe, death is a name we have for some chemical reactions stopping and others starting. But in a model you can explicitly define death - give it a numerical property and specific conditions which cause it. Or you can choose to leave it out. You keep talking about removing things and getting to the simplest or most minimal model - but even the smallest model has to define *something*. So the choice of what to define is the problem.

I'm not sure what else I can say to help you. I've described the way I would build a model and explore what is possible. Either you can start building models to verify your ideas, or you can keep speculating forever.</data>
      <data key="d8">1598</data>
      <data key="d9">7.92</data>
      <data key="d10">0.0081</data>
      <data key="d11">7.7</data>
      <data key="d12">-0.1618</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 4), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 2), (19, 2), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 3), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 3), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 2), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 4), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 5), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 2), (109, 2), (110, 3), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1)]</data>
    </node>
    <node id="c74">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6i7fhl</data>
      <data key="d3">e6i7hvz</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537758735.0</data>
      <data key="d7">I didn't get how your arguments are connected to self-justifying... But NS postulates are not enough to build an open-ended evolution model.

To be correct: I do not propose a particular model. There's no well defined model at the  moment.  What I propose is that such a model if built would be a good candidate for a theory of everything that doesn't rise question "why this particular theory not the other?"

But to build such model something should be added to NS postulates. Something can be guessed (as in Update 2 part) but it's not enough... And how can something unknown and unobvious be self-justifying? 

And are list in Update 2 (ch.7.2) self-justifying? So the worst problem is notion of self-justifying: unless I formalise it somehow I would be stuck...</data>
      <data key="d8">766</data>
      <data key="d9">7.41</data>
      <data key="d10">0.0548</data>
      <data key="d11">7.2</data>
      <data key="d12">-0.0841</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 1), (24, 2), (25, 2), (26, 1), (27, 1), (28, 2), (29, 2), (30, 2), (31, 1), (32, 1), (33, 2), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1)]</data>
    </node>
    <node id="c75">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6i7fhl</data>
      <data key="d3">e6i827r</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1537759174.0</data>
      <data key="d7">Unfortunately there are too many parts of the model to build that are still "to be formalized". And at least notion of self-justification should be formalized. Or the whole idea of research direction would be questionable. </data>
      <data key="d8">223</data>
      <data key="d9">6.5</data>
      <data key="d10">0.0762</data>
      <data key="d11">8.0</data>
      <data key="d12">-0.212</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]</data>
    </node>
    <node id="c76">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e4j23r1</data>
      <data key="d3">e4jtusi</data>
      <data key="d4">kiwi0fruit</data>
      <data key="d5">1</data>
      <data key="d6">1534848984.0</data>
      <data key="d7">Thank you for thoughtful and useful conversation! Yep, both speculations and model are stuck at the moment. So the better option is to start again doing not waiting for a miracle or a savior.</data>
      <data key="d8">191</data>
      <data key="d9">5.133</data>
      <data key="d10">0.0</data>
      <data key="d11">6.5</data>
      <data key="d12">0.2953</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]</data>
    </node>
    <node id="c77">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hyvs3</data>
      <data key="d3">e6fma9u</data>
      <data key="d4">NowImAllSet</data>
      <data key="d5">8</data>
      <data key="d6">1537650025.0</data>
      <data key="d7">Well I'll be damned. I did a senior project on exactly this. Take a look at [this node package](https://github.com/ageitgey/node-unfluff). It is by no means perfect, but I found it to do the best job. Worked pretty well for most sites. And the algorithm itself is actually pretty straightforward, no machine learning involved. It's well written and easy to understand.</data>
      <data key="d8">368</data>
      <data key="d9">5.824</data>
      <data key="d10">0.0</data>
      <data key="d11">5.4</data>
      <data key="d12">0.3147</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1)]</data>
    </node>
    <node id="c78">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fma9u</data>
      <data key="d3">e6fmirk</data>
      <data key="d4">GhostFoxGod</data>
      <data key="d5">-2</data>
      <data key="d6">1537650354.0</data>
      <data key="d7">Can you please explain the working in brief? It would be really helpful. Just basci overview how you approached it</data>
      <data key="d8">114</data>
      <data key="d9">4.895</data>
      <data key="d10">0.0</data>
      <data key="d11">3.5</data>
      <data key="d12">0.3968</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c79">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hyvs3</data>
      <data key="d3">e6fis6l</data>
      <data key="d4">rgb786684</data>
      <data key="d5">6</data>
      <data key="d6">1537644292.0</data>
      <data key="d7">There won’t be consistency across sites in terms of tagging so you’ll have trouble building something that works well on most websites. The best way I can think of getting a system that works in the general case is to use ML or NLP to classify text as good or bad.</data>
      <data key="d8">264</data>
      <data key="d9">4.417</data>
      <data key="d10">0.0</data>
      <data key="d11">9.7</data>
      <data key="d12">0.1699</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1)]</data>
    </node>
    <node id="c80">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fis6l</data>
      <data key="d3">e6frwom</data>
      <data key="d4">ProgramTheWorld</data>
      <data key="d5">0</data>
      <data key="d6">1537656606.0</data>
      <data key="d7">There are predetermined sets of rules that can recognize the main content of an article. Those are mainly used in mobile to create a “readable version” of a webpage. It works most of the time  which I would say “good enough”.</data>
      <data key="d8">225</data>
      <data key="d9">4.892</data>
      <data key="d10">0.0</data>
      <data key="d11">6.3</data>
      <data key="d12">0.0911</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c81">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hyvs3</data>
      <data key="d3">e6fi7tr</data>
      <data key="d4">crimson117</data>
      <data key="d5">2</data>
      <data key="d6">1537643192.0</data>
      <data key="d7">If there are any tags isolating those social media links/words, you can adjust your scraper to ignore them.</data>
      <data key="d8">107</data>
      <data key="d9">4.579</data>
      <data key="d10">0.0</data>
      <data key="d11">8.0</data>
      <data key="d12">-0.3612</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]</data>
    </node>
    <node id="c82">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fi7tr</data>
      <data key="d3">e6fi93e</data>
      <data key="d4">GhostFoxGod</data>
      <data key="d5">-1</data>
      <data key="d6">1537643265.0</data>
      <data key="d7">But I need to do this for different sites. Some sites contain ads. So I will need to isolate them too. </data>
      <data key="d8">103</data>
      <data key="d9">4.647</data>
      <data key="d10">0.0</data>
      <data key="d11">1.3</data>
      <data key="d12">-0.0674</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]</data>
    </node>
    <node id="c83">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fmirk</data>
      <data key="d3">e6fmquz</data>
      <data key="d4">NowImAllSet</data>
      <data key="d5">10</data>
      <data key="d6">1537650658.0</data>
      <data key="d7">I did not write this library, I did a senior project where I needed to extract webpage content and analyzed a bunch of different third party solutions. It's been a while since I looked at the code, so I can't recall enough of the details to give any sort of overview. Basic gist that I remember is that it has a series of predefined words and tags that it uses to filter out what is likely content and what is likely not.

But, ya know...it's on GitHub. It's open source. The code is well written and documented. Go read it if you want details... </data>
      <data key="d8">547</data>
      <data key="d9">5.851</data>
      <data key="d10">0.0</data>
      <data key="d11">4.8</data>
      <data key="d12">0.1096</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 3), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]</data>
    </node>
    <node id="c84">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fi93e</data>
      <data key="d3">e6k1ieb</data>
      <data key="d4">crimson117</data>
      <data key="d5">1</data>
      <data key="d6">1537835503.0</data>
      <data key="d7">You are basically trying to write a [web scraper](https://en.wikipedia.org/wiki/Web_scraping).

This is not an easy task. There is no magic wand to make it work for all sites.

Someone else suggested using news sites' RSS feeds instead of scaping their main page. This is a great idea for a general purpose news aggregator. Would that work for you?</data>
      <data key="d8">348</data>
      <data key="d9">5.936</data>
      <data key="d10">0.0</data>
      <data key="d11">4.6</data>
      <data key="d12">-0.0018</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c85">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k1ieb</data>
      <data key="d3">e6k1irk</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537835511.0</data>
      <data key="d7">**Web scraping**

Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1003</data>
      <data key="d9">10.584</data>
      <data key="d10">0.0</data>
      <data key="d11">14.4</data>
      <data key="d12">-0.0226</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 4), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 3), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)]</data>
    </node>
    <node id="c86">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a1kvr</data>
      <data key="d4">clownshoesrock</data>
      <data key="d5">335</data>
      <data key="d6">1537419108.0</data>
      <data key="d7">It's almost too intuitive for me to explain..

But think of the counter-consequences.

If a computer could simulate itself faster than it could run, then you could run a faster simulator inside the simulator, and in turn have an ever increasing speedup.

Anyway, the simulator has to do things like fetch memory, but fetching the memory in simulator always takes as long as doing all the prep work in the simulator, then doing a memory fetch in hardware equivalent to what is being simulated..  So basically every thing you do has to be done in hardware anyway, but with more overhead on everything
</data>
      <data key="d8">599</data>
      <data key="d9">6.817</data>
      <data key="d10">0.0</data>
      <data key="d11">11.3</data>
      <data key="d12">0.0475</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 3), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 3), (17, 2), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 2), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]</data>
    </node>
    <node id="c87">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6a3hx5</data>
      <data key="d4">loamfarer</data>
      <data key="d5">27</data>
      <data key="d6">1537420687.0</data>
      <data key="d7">Yeah, its a claim that relates more to engineering and practical realities / measurements. Computation theory describes a sequence of concrete ordered steps that could be instantaneous for all that is cared about. Under which a program that never halts will run forever, but if it halts it's result can be considered instantaneous as far as the model goes. Sometimes a step is given a unit of measurement, but its usually only put in terms of time to emphasis a point in a specific example.</data>
      <data key="d8">490</data>
      <data key="d9">6.219</data>
      <data key="d10">0.0</data>
      <data key="d11">11.5</data>
      <data key="d12">0.1794</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 4), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]</data>
    </node>
    <node id="c88">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6cnkll</data>
      <data key="d4">t_bptm</data>
      <data key="d5">5</data>
      <data key="d6">1537519026.0</data>
      <data key="d7">The phrase "must always" is too strong. The simulation will in general be slower, but there are situations where an optimizing simulation could exploit a lack of compression for programs which would gain enough time to precede the actual computers runtime. Though for these cases case you gain less for each level of depth (likely extremely) bringing it back to slower again with multiple depth simulation, so the logic of infinite depth'd speedup doesn't really apply. But if you are talking about in general, then sure.. I guess it depends on what level you are considering as faster, but I would hardly ever assume simulation means 1-&gt;1 mapping of instructions executed if there are optimizations to be made.

It's a very similar idea to the theory of compression as well, if you are simulating random instructions- sure, there is nothing that can help you. But if this isn't the case (which it probably isn't) you have a chance of executing faster for 1 layer of depth (and maybe 2 or more) if you have the right conditions and a good implementation. Just as you can run gzip once or twice on a file and see improvements..</data>
      <data key="d8">1126</data>
      <data key="d9">7.214</data>
      <data key="d10">0.0107</data>
      <data key="d11">11.7</data>
      <data key="d12">0.4119</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 3), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 3), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 2), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1)]</data>
    </node>
    <node id="c89">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6al5vq</data>
      <data key="d4">bloatedfrog</data>
      <data key="d5">18</data>
      <data key="d6">1537437561.0</data>
      <data key="d7">It’s like physics, a force can only return a force of equal or lesser strength. </data>
      <data key="d8">80</data>
      <data key="d9">4.2</data>
      <data key="d10">0.0</data>
      <data key="d11">5.6</data>
      <data key="d12">0.6908</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c90">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6ardux</data>
      <data key="d4">bo0mb0om</data>
      <data key="d5">3</data>
      <data key="d6">1537444019.0</data>
      <data key="d7">Yeah, the positive feedback analogy nails it. At best you can have equal performance.</data>
      <data key="d8">85</data>
      <data key="d9">4.929</data>
      <data key="d10">0.0</data>
      <data key="d11">4.8</data>
      <data key="d12">0.6686</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c91">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6aonk6</data>
      <data key="d4">ThePeskyWabbit</data>
      <data key="d5">1</data>
      <data key="d6">1537441077.0</data>
      <data key="d7">nested simulators that each run faster than the last. why are we even using super computers?!</data>
      <data key="d8">93</data>
      <data key="d9">4.688</data>
      <data key="d10">0.0</data>
      <data key="d11">5.2</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c92">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6a47fr</data>
      <data key="d4">SuperGameTheory</data>
      <data key="d5">-9</data>
      <data key="d6">1537421301.0</data>
      <data key="d7">I don’t know if the argument is/was at all valid, but one time I was high and realized this, then I took it one toke further and argued that we could never really realize or appreciate the actual underlying mechanics of reality (or the reality from which our reality springs) because we’d need tools/measurements/math that were native to the underlying reality for the models. In other words, our current instruments and math are derived from the physical world, and so they’d essentially be unequipped to deal with the reality that they themselves are made of. Or something like that. Also, something about how our brains are computers within the computers of physical reality, which are in the computers of their more basic reality...all the way down.

I was high.</data>
      <data key="d8">766</data>
      <data key="d9">7.057</data>
      <data key="d10">0.0</data>
      <data key="d11">11.7</data>
      <data key="d12">0.0694</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 3), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 5), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 3), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1)]</data>
    </node>
    <node id="c93">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6am7b7</data>
      <data key="d4">c3534l</data>
      <data key="d5">1</data>
      <data key="d6">1537438602.0</data>
      <data key="d7">But what about the case where the simulation speed is equal to the computer speed? If all the computer does is simulate itself or if its output is zero, the simulation speed and computing speed are equal.</data>
      <data key="d8">204</data>
      <data key="d9">6.6</data>
      <data key="d10">0.0</data>
      <data key="d11">9.3</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 3), (12, 1), (13, 1), (14, 1), (15, 1)]</data>
    </node>
    <node id="c94">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6a9sq2</data>
      <data key="d4">zck</data>
      <data key="d5">-21</data>
      <data key="d6">1537426440.0</data>
      <data key="d7">&gt; If a computer could simulate itself faster than it could run, then you could run a faster simulator inside the simulator, and in turn have an ever increasing speedup.

This isn't a proof of its impossibility, it's a proof we haven't figured out how to do it yet. I agree it's impossible, but I don't think the argument here holds up.</data>
      <data key="d8">335</data>
      <data key="d9">5.521</data>
      <data key="d10">0.0</data>
      <data key="d11">8.8</data>
      <data key="d12">0.1764</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 3), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 2), (29, 1), (30, 1)]</data>
    </node>
    <node id="c95">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6adm33</data>
      <data key="d4">hnerixh</data>
      <data key="d5">-16</data>
      <data key="d6">1537430159.0</data>
      <data key="d7">To be fair, a computer could simulate a faster clone of itself, but only if we simulate the reality around the simulation as well. For example we can simulate high frequency hardware circuits in software. Or you know, just go full matrix. Never go full matrix.</data>
      <data key="d8">260</data>
      <data key="d9">5.474</data>
      <data key="d10">0.0</data>
      <data key="d11">7.8</data>
      <data key="d12">0.1277</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1)]</data>
    </node>
    <node id="c96">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6anoiv</data>
      <data key="d4">wasimwesley</data>
      <data key="d5">-2</data>
      <data key="d6">1537440080.0</data>
      <data key="d7">But like, can a digital computer simulate a quantum computer? Or could some imaginary, immensely complex analog computer simulate a digital computer, that simulates a faster version of the original?

I'm imagining that guy [who built a calculator using minecraft blocks](https://www.tomshardware.com/news/Minecraft-Calculator-Graphing-MaxSGB-Scientific,15109.html)...pretty outlandish, but he did it!

And really, every computer is built out of basic blocks in one sense or another, right?</data>
      <data key="d8">489</data>
      <data key="d9">8.078</data>
      <data key="d10">0.0</data>
      <data key="d11">12.8</data>
      <data key="d12">0.0906</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]</data>
    </node>
    <node id="c97">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1kvr</data>
      <data key="d3">e6an120</data>
      <data key="d4">CowboyFromSmell</data>
      <data key="d5">-10</data>
      <data key="d6">1537439431.0</data>
      <data key="d7">&gt; If a computer could simulate itself faster than it could run, then you could run a faster simulator inside the simulator, and in turn have an ever increasing speedup.

Not only **can** this be done, it **has** been done. See [my answer](https://www.reddit.com/r/compsci/comments/9h8t0k/comment/e6ak6tl?st=JM9YIVT3&amp;sh=bc45597d).</data>
      <data key="d8">329</data>
      <data key="d9">7.629</data>
      <data key="d10">0.0</data>
      <data key="d11">9.9</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 3), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c98">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a1zo8</data>
      <data key="d4">TheMasterBaker01</data>
      <data key="d5">71</data>
      <data key="d6">1537419428.0</data>
      <data key="d7">You could really just think of this like, if a computer can only physically process 10 bits per second, then no simulation inside that machine could ever process faster than 10 bits per seconds just due to physical limitations on the hardware.</data>
      <data key="d8">243</data>
      <data key="d9">5.528</data>
      <data key="d10">0.0</data>
      <data key="d11">18.5</data>
      <data key="d12">0.1717</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c99">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a1zo8</data>
      <data key="d3">e6a7im5</data>
      <data key="d4">Sukrim</data>
      <data key="d5">-29</data>
      <data key="d6">1537424297.0</data>
      <data key="d7">Only if that simulation also always simulates all steps instead of having an optimizer stage and only simulating the outcome of the processing.

JIT compilers would be an example.</data>
      <data key="d8">179</data>
      <data key="d9">5.692</data>
      <data key="d10">0.0</data>
      <data key="d11">11.3</data>
      <data key="d12">0.1806</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]</data>
    </node>
    <node id="c100">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a3tv5</data>
      <data key="d4">hypermog</data>
      <data key="d5">156</data>
      <data key="d6">1537420972.0</data>
      <data key="d7">In this house we obey the laws of thermodynamics</data>
      <data key="d8">48</data>
      <data key="d9">4.444</data>
      <data key="d10">0.0</data>
      <data key="d11">4.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</data>
    </node>
    <node id="c101">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a3tv5</data>
      <data key="d3">e6af06o</data>
      <data key="d4">mulletlaw</data>
      <data key="d5">11</data>
      <data key="d6">1537431528.0</data>
      <data key="d7">It just keeps going *faster and faster.*</data>
      <data key="d8">40</data>
      <data key="d9">5.167</data>
      <data key="d10">0.0</data>
      <data key="d11">0.1</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</data>
    </node>
    <node id="c102">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a3tv5</data>
      <data key="d3">e6b01ja</data>
      <data key="d4">agumonkey</data>
      <data key="d5">1</data>
      <data key="d6">1537456848.0</data>
      <data key="d7">Still, since my early years in programming, one of my deepest desire was to study how to make interpretation layers run as close as possible as a single one.</data>
      <data key="d8">157</data>
      <data key="d9">5.25</data>
      <data key="d10">0.0</data>
      <data key="d11">12.2</data>
      <data key="d12">0.4019</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]</data>
    </node>
    <node id="c103">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a78sn</data>
      <data key="d4">nanodano</data>
      <data key="d5">39</data>
      <data key="d6">1537424045.0</data>
      <data key="d7">Could you pull a wagon and have the wagon go faster than you?</data>
      <data key="d8">61</data>
      <data key="d9">4.364</data>
      <data key="d10">0.0</data>
      <data key="d11">3.6</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1)]</data>
    </node>
    <node id="c104">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a78sn</data>
      <data key="d3">e6axgas</data>
      <data key="d4">daviegravee</data>
      <data key="d5">14</data>
      <data key="d6">1537452258.0</data>
      <data key="d7">No but I could start pulling a wagon downhill briefly before it gains monentum and crushes me to death which is pretty close</data>
      <data key="d8">124</data>
      <data key="d9">4.435</data>
      <data key="d10">0.0</data>
      <data key="d11">8.7</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c105">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a2gkg</data>
      <data key="d4">Dev__</data>
      <data key="d5">30</data>
      <data key="d6">1537419808.0</data>
      <data key="d7">You can use a light bulb to power a solar cell that powers a light bulb.

The second light bulb will never emit as much energy as the first.

Or you could go with a photocopier analogy - if you copy a copy of copy there will be a reduction in quality. There will always be a loss. As the other commentor suggested if there was some kind of improvement or increase within the system the consequences would be absurd. </data>
      <data key="d8">416</data>
      <data key="d9">5.964</data>
      <data key="d10">0.0</data>
      <data key="d11">7.1</data>
      <data key="d12">0.1137</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 3), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1)]</data>
    </node>
    <node id="c106">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a2gkg</data>
      <data key="d3">e6ahffh</data>
      <data key="d4">sheikhy_jake</data>
      <data key="d5">3</data>
      <data key="d6">1537433903.0</data>
      <data key="d7">I quite like the photocopier analogy. </data>
      <data key="d8">38</data>
      <data key="d9">5.167</data>
      <data key="d10">0.0</data>
      <data key="d11">10.4</data>
      <data key="d12">0.4201</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c107">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a2gkg</data>
      <data key="d3">e6bggvd</data>
      <data key="d4">MjrK</data>
      <data key="d5">2</data>
      <data key="d6">1537481789.0</data>
      <data key="d7">Both of these analogies are hand-waiving to the point of being completely misleading.

&amp;#x200B;</data>
      <data key="d8">95</data>
      <data key="d9">5.615</data>
      <data key="d10">0.0</data>
      <data key="d11">7.6</data>
      <data key="d12">-0.4576</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c108">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6ags43</data>
      <data key="d4">olliej</data>
      <data key="d5">15</data>
      <data key="d6">1537433275.0</data>
      <data key="d7">There are different reasons, such as the tautological/obviously not happening: if a system can simulate itself to run code faster than it could run the code itself, then you would just have the simulator run the simulator, recursively to get an huge performance win.

Another trivial way: take the fastest/shortest runtime instruction, and run it in the simulator. The fastest thing it can do is to just execute the instruction natively, which is obviously not faster than itself.

Now you might be thinking “the simulator could optimize the code before executing it”, but if it does that it could still just run the optimized code directly rather than going through the simulator.

Hence the absolute best case performance of a simulator is identical performance to running natively. To achieve that the simulator cannot do *anything* other than run the code directly, which means it’s no longer a simulator.

Therefore a simulator of any machine, running on top of a real version of the machine must be slower than the host machine itself.</data>
      <data key="d8">1041</data>
      <data key="d9">8.622</data>
      <data key="d10">0.0</data>
      <data key="d11">12.9</data>
      <data key="d12">0.2816</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 5), (2, 3), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 3), (11, 3), (12, 1), (13, 1), (14, 1), (15, 5), (16, 1), (17, 1), (18, 1), (19, 1), (20, 5), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 3), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]</data>
    </node>
    <node id="c109">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ags43</data>
      <data key="d3">e6bhj22</data>
      <data key="d4">singham</data>
      <data key="d5">1</data>
      <data key="d6">1537482709.0</data>
      <data key="d7">Is the idea of water blowing up in finite time related to this : 

https://math.stackexchange.com/questions/2283496/a-basic-understanding-of-the-navier-stokes-or-terry-taos-exploding-water-pro

&gt; Tao's idea is to set up initial data that successively moves energy from longer length scales to shorter length scales by constructing smaller, faster vortices. As in the NYT quote, it is a bit like a machine which constructs a small copy of itself and then dissipates, and then the copy creates an even smaller copy of itself and then dissipates, etc. This process then accelerates fast enough that, roughly speaking, after only a finite amount of time the machine already has no size. In the modified Navier-Stokes used in his recent paper, this construction actually goes through and leads to finite time blowup.

https://www.quantamagazine.org/terence-tao-proposes-fluid-new-path-in-navier-stokes-problem-20140224/</data>
      <data key="d8">914</data>
      <data key="d9">9.593</data>
      <data key="d10">0.0</data>
      <data key="d11">14.9</data>
      <data key="d12">0.144</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 3), (2, 2), (3, 1), (4, 2), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 2), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 4), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1)]</data>
    </node>
    <node id="c110">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a3ghy</data>
      <data key="d4">Dustin-</data>
      <data key="d5">9</data>
      <data key="d6">1537420653.0</data>
      <data key="d7">For a super simple example, a NOT gate (a switch who's output is opposite of its input) can be "simulated" by stringing 3 NOT gates together in a line, but it would take 3 times longer to run than a single one. </data>
      <data key="d8">211</data>
      <data key="d9">4.5</data>
      <data key="d10">0.0474</data>
      <data key="d11">17.3</data>
      <data key="d12">0.3506</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]</data>
    </node>
    <node id="c111">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a3ghy</data>
      <data key="d3">e6a6wyo</data>
      <data key="d4">ctchalk</data>
      <data key="d5">-5</data>
      <data key="d6">1537423734.0</data>
      <data key="d7">In your model, three NOT gates in a line can be simulated by one NOT gate, and in this case the simulator takes 1/3 as long as the three gates.</data>
      <data key="d8">143</data>
      <data key="d9">4.625</data>
      <data key="d10">0.0</data>
      <data key="d11">10.3</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1)]</data>
    </node>
    <node id="c112">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6a4omn</data>
      <data key="d4">Reddit1990</data>
      <data key="d5">2</data>
      <data key="d6">1537421723.0</data>
      <data key="d7">Its like running an emulator... Except the emulator has the same specs as your computer, so time needs to dilated for it to be able to run properly. I mean you only have one machine, you cant have two machines for the price of one. That would break the laws of conservation of information (pretty sure thats a thing, or it should be).</data>
      <data key="d8">334</data>
      <data key="d9">5.28</data>
      <data key="d10">0.0</data>
      <data key="d11">7.1</data>
      <data key="d12">0.1699</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c113">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a4omn</data>
      <data key="d3">e6an0qu</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">3</data>
      <data key="d6">1537439423.0</data>
      <data key="d7">&gt; That would break the laws of conservation of information

That would make physics a lot easier if it does end up being true, but our current understanding is that black holes destroy information - it's fundamentally what [Stephen Hawking spent his life working on exploring](https://en.wikipedia.org/wiki/Black_hole_information_paradox).</data>
      <data key="d8">339</data>
      <data key="d9">6.951</data>
      <data key="d10">0.0</data>
      <data key="d11">22.8</data>
      <data key="d12">-0.2248</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 2), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]</data>
    </node>
    <node id="c114">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6ahi9a</data>
      <data key="d4">ocean07</data>
      <data key="d5">1</data>
      <data key="d6">1537433981.0</data>
      <data key="d7">This is basically saying we can never truly simulate the universe if the universe is a simulation. </data>
      <data key="d8">99</data>
      <data key="d9">5.786</data>
      <data key="d10">0.0</data>
      <data key="d11">12.3</data>
      <data key="d12">-0.3412</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]</data>
    </node>
    <node id="c115">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahi9a</data>
      <data key="d3">e6aiu70</data>
      <data key="d4">mistahspecs</data>
      <data key="d5">1</data>
      <data key="d6">1537435277.0</data>
      <data key="d7">I don't think you should have the conditional there. It doesn't matter if the universe is a simulation or not, we cannot simulate the entire universe inside of the universe. </data>
      <data key="d8">174</data>
      <data key="d9">5.64</data>
      <data key="d10">0.0</data>
      <data key="d11">9.1</data>
      <data key="d12">-0.0095</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1)]</data>
    </node>
    <node id="c116">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahi9a</data>
      <data key="d3">e6aih3j</data>
      <data key="d4">olliej</data>
      <data key="d5">1</data>
      <data key="d6">1537434922.0</data>
      <data key="d7">Wording screwed up maybe?

we can’t simulate the entire universe from within the universe, being a simulation or not is irrelevant. Basically there is X amount of information/energy in the universe, so to simulate the entire universe you would need *at least* X information/energy, but you can’t do that because you’re already using all of X amount of stuff in the universe simply being the universe.
</data>
      <data key="d8">401</data>
      <data key="d9">7.043</data>
      <data key="d10">0.0</data>
      <data key="d11">11.9</data>
      <data key="d12">-0.247</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 2), (8, 2), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 3), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c117">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6btixm</data>
      <data key="d4">znegva</data>
      <data key="d5">0</data>
      <data key="d6">1537492536.0</data>
      <data key="d7">No, it's false. We can construct a computer made up of two subunits A and B. A and B can each execute the same programs, only B is faster than A. We can feed a program to the computer and instruct it to run on A. Meanwhile, B is idle. Now we can simulate this execution using a simulator program that runs on B. Since B is arbitrarily faster than A and simulating B's idleness requires no computation, we're faster than the original execution.

This is exactly what happens when recompiling a program so that it uses faster combinations of instructions.

The key here is to realize that a simulation consists in running a *model* of a machine. Depending on the complexity of the model, "running the model" may be somewhat slower or faster but it's different from replicating the original machine with infinite physical precision, if there were such thing.
</data>
      <data key="d8">856</data>
      <data key="d9">7.344</data>
      <data key="d10">0.021</data>
      <data key="d11">9.2</data>
      <data key="d12">0.018</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 5), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 2), (20, 3), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 3), (30, 3), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1)]</data>
    </node>
    <node id="c118">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6btixm</data>
      <data key="d3">e6cdjt5</data>
      <data key="d4">znegva</data>
      <data key="d5">1</data>
      <data key="d6">1537509287.0</data>
      <data key="d7">Could the downvoter(s) explain their source of dissatisfaction, please?</data>
      <data key="d8">71</data>
      <data key="d9">5.9</data>
      <data key="d10">0.0</data>
      <data key="d11">9.2</data>
      <data key="d12">-0.2263</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]</data>
    </node>
    <node id="c119">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9h8t0k</data>
      <data key="d3">e6ak6tl</data>
      <data key="d4">CowboyFromSmell</data>
      <data key="d5">-17</data>
      <data key="d6">1537436603.0</data>
      <data key="d7">No, definitely not a law.

[PyPy is a Python implementation](https://pypy.org/) in Python that can run faster than the C implementation of Python with less memory and better concurrency. So that’s a similar problem, if not the same problem - virtual machines are machines too. 

You can [read more about how PyPy works here](https://stackoverflow.com/a/2592094) but the gist is that they used higher level abstractions available in Python to make optimizations unavailable to C. 

This really isn’t unlike CPUs. Several Intel CPUs have included a decoder step where it converted regular x86 op codes to simpler RISC-based op codes. This enabled them to make optimization’s they couldn’t have otherwise. So in a sense it happens at a hardware level already.

They also keep runtime metrics about branches to make better predictions and do speculative execution. It’s by no means unreasonable to have a VM do a better job of predicting branches. It’s just a matter of running the optimizer at a level higher.

So yes, we have built virtual machines that can emulate themselves faster than the original. I see no reason why this absolutely can’t be true for non-virtual machines as well.

Edit: clarity

Edit:

Alright, everyone’s heavily downvoting me, so let’s set some bounds. If you read to the bottom I have an example of such a hardware simulator.

A simulator mimics the **behavior**. For a CPU, this means it implements the instruction set and each instruction returns the same result for each instruction. You could even argue that it needs to have the same clock speed, but you can’t ever argue that it has to have the same instruction throughput. Otherwise, it would be almost impossible to build simulators because they would usually have a lower throughput (be slower). 

Intel has successfully used clock speed as a measure of CPU performance ever since the Pentium 3. While clock speed has implications on overall performance, it’s far from the truth. 

Long ago, to achieve instruction throughput, CPU manufacturers started pipelining. Simplistically, this means that each instruction gets partially computed on each cycle. Suddenly, instead of processing one instruction at a time, there are lots of instructions in flight. On modern Intel CPUs, there can be as many as 168 in flight instructions at any given time.

So now the problem is keeping the pipeline full. If it stays full, all the hardware is busy. If a “bubble” forms, we’ve lost opportunity to optimally utilize the hardware. This is a very hard problem.

IF statements are one of the primary places bubbles would form. You don’t know which instruction to load until the IF condition is fully evaluated. This is where speculative execution comes in - you keep track of which branches are usually taken so that you can make better guesses. 

The problem is CPUs have a hardware budget - there are a finite amount of transistors they can use for keeping branch statistics, but a much larger number of branches to be taken (and scenarios under which branches execute, etc). 

A software-based simulator should have a much larger amount of memory available to keep branch statistics, so should have a larger capacity to make speculative execution decisions.

If I were to make such a simulator that executes code faster than the original, I’d do it very similar to what JIT compilers do (e.g. JVM, CLR, etc).

1. To start, don’t pass instructions directly through to the CPU. Instead, put instrumentation around branches to keep track of statistics. 
2. After about 10,000 iterations of a loop, “rewrite” the instructions that are passed through to the CPU such that the CPU makes much better speculation decisions.

In step 1, the simulator would be significantly slower than the original. In step 2, the hot code could be significantly faster than the original CPU would have executed it.

Again, this isn’t new. It’s what JIT compilers do. You can argue if they’re *effective*, but you can’t tell me they’re *impossible* (which is fundamentally what OP’s professor said).</data>
      <data key="d8">4047</data>
      <data key="d9">10.423</data>
      <data key="d10">0.0</data>
      <data key="d11">8.9</data>
      <data key="d12">0.0709</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 4), (3, 1), (4, 5), (5, 1), (6, 4), (7, 1), (8, 1), (9, 1), (10, 4), (11, 2), (12, 3), (13, 1), (14, 4), (15, 2), (16, 5), (17, 10), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 3), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 3), (31, 6), (32, 1), (33, 1), (34, 4), (35, 1), (36, 2), (37, 1), (38, 2), (39, 1), (40, 3), (41, 1), (42, 1), (43, 4), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 4), (53, 12), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 3), (63, 1), (64, 1), (65, 2), (66, 3), (67, 1), (68, 1), (69, 5), (70, 1), (71, 1), (72, 1), (73, 1), (74, 4), (75, 1), (76, 3), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 3), (84, 1), (85, 1), (86, 1), (87, 3), (88, 1), (89, 1), (90, 2), (91, 1), (92, 1), (93, 4), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 3), (111, 1), (112, 1), (113, 1), (114, 1), (115, 3), (116, 1), (117, 1), (118, 3), (119, 2), (120, 4), (121, 1), (122, 2), (123, 1), (124, 1), (125, 7), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 4), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 2), (139, 5), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 2), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 4), (167, 1), (168, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 3), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 2), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 2), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 2), (200, 1), (201, 2), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 2), (211, 2), (212, 1), (213, 3), (214, 1), (215, 2), (216, 2), (217, 1), (218, 2), (219, 1), (220, 1), (221, 3), (222, 3), (223, 1), (224, 1), (225, 2), (226, 1), (227, 1), (228, 1), (229, 2), (230, 2), (231, 1), (232, 1), (233, 1), (234, 1), (235, 2), (236, 2), (237, 1), (238, 1), (239, 1), (240, 3), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 1), (248, 1), (249, 2), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 2), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 2)]</data>
    </node>
    <node id="c120">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ak6tl</data>
      <data key="d3">e6awoki</data>
      <data key="d4">Putnam3145</data>
      <data key="d5">8</data>
      <data key="d6">1537450993.0</data>
      <data key="d7">Python is [not a virtual machine.](https://stackoverflow.com/questions/441824/java-virtual-machine-vs-python-interpreter-parlance)

&gt;It’s by no means unreasonable to have a VM do a better job of predicting branches. It’s just a matter of running the optimizer at a level higher.

This is not a simulation of the same computer, then.</data>
      <data key="d8">332</data>
      <data key="d9">7.694</data>
      <data key="d10">0.0</data>
      <data key="d11">9.9</data>
      <data key="d12">0.1399</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]</data>
    </node>
    <node id="c121">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a3hx5</data>
      <data key="d3">e6bd0r3</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">2</data>
      <data key="d6">1537478587.0</data>
      <data key="d7">Uhhhh. You are completely missing complexity theory? This would imply exponential speedup and a near collapse of complexity classes. If a speedup is  possible this would surely imply P=NP=EXPTIME=... wouldn't it?</data>
      <data key="d8">212</data>
      <data key="d9">6.034</data>
      <data key="d10">0.0</data>
      <data key="d11">10.8</data>
      <data key="d12">-0.1033</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1)]</data>
    </node>
    <node id="c122">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a3hx5</data>
      <data key="d3">e6ahz34</data>
      <data key="d4">sheikhy_jake</data>
      <data key="d5">1</data>
      <data key="d6">1537434441.0</data>
      <data key="d7">I'm not sure I followed. Do you mind saying that again in different words?

My understanding is that it's a theoretically impossible task for a computer to simulate itself performing a task faster than in can perform a task not just practically. Surely  compute_time(task A) &lt;= simulation_time(compute_time(A)). But you're saying that isnt the case?</data>
      <data key="d8">349</data>
      <data key="d9">6.535</data>
      <data key="d10">0.0</data>
      <data key="d11">9.8</data>
      <data key="d12">0.0399</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 3), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 3), (24, 1), (25, 1), (26, 1), (27, 1)]</data>
    </node>
    <node id="c123">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6cnkll</data>
      <data key="d3">e6csq2b</data>
      <data key="d4">clownshoesrock</data>
      <data key="d5">2</data>
      <data key="d6">1537523816.0</data>
      <data key="d7">That's an emulator rather than a simulator, but still a well considered point.</data>
      <data key="d8">78</data>
      <data key="d9">5.333</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.3919</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c124">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6al5vq</data>
      <data key="d3">e6bcv57</data>
      <data key="d4">SirClueless</data>
      <data key="d5">20</data>
      <data key="d6">1537478429.0</data>
      <data key="d7">Actually this is not true. If you set up a lever, you can return a greater force than you apply. For example, with a car Jack, the downward force of a single human can lift a car.

Force is not conserved, the things that are conserved are energy and momentum.</data>
      <data key="d8">259</data>
      <data key="d9">5.583</data>
      <data key="d10">0.0</data>
      <data key="d11">4.6</data>
      <data key="d12">0.0773</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c125">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6al5vq</data>
      <data key="d3">e6bg8mu</data>
      <data key="d4">MjrK</data>
      <data key="d5">6</data>
      <data key="d6">1537481589.0</data>
      <data key="d7">If you are referring to Newton's third law, then the statement is that, for every force, there is an equal and opposite reaction. Key point being, the reaction force is always exactly equal in magnitude - always. It's never lesser.

And no, this isn't a good analogy for simulation.</data>
      <data key="d8">282</data>
      <data key="d9">5.575</data>
      <data key="d10">0.0</data>
      <data key="d11">6.8</data>
      <data key="d12">-0.1396</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c126">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6al5vq</data>
      <data key="d3">e6aq2gq</data>
      <data key="d4">voidmechanic</data>
      <data key="d5">-61</data>
      <data key="d6">1537442554.0</data>
      <data key="d7">Unless it's you know... THE FORCE OF THE DARK SIDE BOOO WHAA HAHAHAHA

You've been dark sided. </data>
      <data key="d8">95</data>
      <data key="d9">4.471</data>
      <data key="d10">0.0</data>
      <data key="d11">4.2</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c127">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a47fr</data>
      <data key="d3">e6af9mo</data>
      <data key="d4">timshoaf</data>
      <data key="d5">9</data>
      <data key="d6">1537431787.0</data>
      <data key="d7">You might have been high as balls, but the underlying notion is interesting and I am disappointed to see you so thoroughly downvoted.

The idea that the physical reality has less constructs imposed than a simulated one is not at all an uninteresting statement. It is one I have spent more than a few hours pondering.

Presumably I could construct a simulation of a universe that had different laws of physics and the resulting time evolution of said system would always take on values of a state space that was a strict subset of that of the machine upon which it is being simulated.

Ostensibly one wonders whether, there is some physical analogy to the incompleteness theorems. 

Yes yes, I know the highly specific domain to which those apply with respect to formal systems containing the peano axioms, however, that isn't the question. The question is, by some analogous constructing, some godel numbering of the state space of the universe (should we find it discrete), whether the system itself must be either incomplete or inconsistent and, in a further but somewhat tangential question, whether the computational power of our universe, if simulated, is indeed equivalent or strictly less than that of the simulating universe. 

Are we complete, in the sense that we can with I finite time and resource, simulate anything in the simulating universe? Or are we incomplete, and restricted to a series of states that do not even begin to touch that of the simulating universe as if we were a little DFA being run by a Turing machine.

It's normally at this point I go down some rabit hole of how to cheat, exploit relativity to have time experienced by the machine faster? Issues with that set up abound in information retrieval... Etc etc..

But it's an interesting line of thought and at some point would be a fun bit of recreational math to actually try to formalize the notion, even if it shows it all to be bunk in the first few hours of construction.</data>
      <data key="d8">1960</data>
      <data key="d9">8.202</data>
      <data key="d10">0.0</data>
      <data key="d11">13.1</data>
      <data key="d12">0.067</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 3), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 2), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 3), (24, 10), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 2), (42, 1), (43, 1), (44, 2), (45, 1), (46, 3), (47, 3), (48, 1), (49, 1), (50, 2), (51, 2), (52, 1), (53, 1), (54, 1), (55, 5), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 3), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 2), (103, 3), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 2), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1)]</data>
    </node>
    <node id="c128">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a47fr</data>
      <data key="d3">e6assj0</data>
      <data key="d4">knot_hk</data>
      <data key="d5">0</data>
      <data key="d6">1537445700.0</data>
      <data key="d7">dude thats epic :D hope u shared with ur buds at the lunch table :D</data>
      <data key="d8">67</data>
      <data key="d9">3.786</data>
      <data key="d10">0.0</data>
      <data key="d11">3.2</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c129">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6am7b7</data>
      <data key="d3">e6amppf</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">23</data>
      <data key="d6">1537439120.0</data>
      <data key="d7">Fundamentally, the computer has to expend some amount of energy and time running that simulation - if the simulation were identical to the machine, how would that simulation exist? Where would it store its state? It doesn't need much state - a hypervisor can be written to use only tiny, tiny amounts of memory, and the amount of instructions it takes to rewrite or redirect the memory accesses is tiny... but it's all still there. Even if you bake it mostly into the hardware, as Intel has with the VT extensions.

You can get vanishingly close to the same performance as the host machine, but you can't ever get the same or greater performance. Luckily for us, a lot of the time that tiny bit of overhead is irrelevant to our end goals... but for the sake of this discussion it's **everything**.</data>
      <data key="d8">797</data>
      <data key="d9">7.146</data>
      <data key="d10">0.0</data>
      <data key="d11">8.9</data>
      <data key="d12">0.2144</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 3), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 3), (38, 1), (39, 2), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1)]</data>
    </node>
    <node id="c130">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a9sq2</data>
      <data key="d3">e6ab7wr</data>
      <data key="d4">trex-eaterofcadrs</data>
      <data key="d5">26</data>
      <data key="d6">1537427819.0</data>
      <data key="d7">Information is energy and so then you would bust the laws of thermodynamics if you could do this. </data>
      <data key="d8">98</data>
      <data key="d9">4.647</data>
      <data key="d10">0.0</data>
      <data key="d11">10.3</data>
      <data key="d12">0.2732</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]</data>
    </node>
    <node id="c131">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a9sq2</data>
      <data key="d3">e6abg3m</data>
      <data key="d4">Little_Milton</data>
      <data key="d5">-13</data>
      <data key="d6">1537428039.0</data>
      <data key="d7">Underrated post. What we have today would surely be seen as impossible black magic a hundred years ago, let alone 200-300. I’m sure we’ll find some new mind blowing way of making CPU’s in 20-30 years, or maybe a new way of computing all together.</data>
      <data key="d8">246</data>
      <data key="d9">4.581</data>
      <data key="d10">0.0</data>
      <data key="d11">9.7</data>
      <data key="d12">0.1815</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c132">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6adm33</data>
      <data key="d3">e6ah58u</data>
      <data key="d4">olliej</data>
      <data key="d5">5</data>
      <data key="d6">1537433632.0</data>
      <data key="d7">Yes but the resulting simulation is for a different machine. When talking about something like this it’s really important to note the initial conditions of the statement.

Otherwise you could, for example, simulate an arm variant that supported hardware multiply on a arm variant that didn’t. If your simulator implemented the multiply instructions directly inline, then it will run such code faster than the host could. (Basically if you hit an unsupported instruction on arm you take a fault and the OS is expected to do the work to produce the correct result)


Clearly that is not a reasonable/useful comparison :D</data>
      <data key="d8">618</data>
      <data key="d9">6.474</data>
      <data key="d10">0.0</data>
      <data key="d11">11.2</data>
      <data key="d12">0.2722</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 3), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]</data>
    </node>
    <node id="c133">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6anoiv</data>
      <data key="d3">e6aogcn</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">10</data>
      <data key="d6">1537440875.0</data>
      <data key="d7">&gt; But like, can a digital computer simulate a quantum computer? 

Yes. In fact, almost all of the quantum computing we've ever done in the history of computation has been done on conventional digital machines. (We have ran some quantum calculations, but on computers that are composed of tens or possibly small hundreds of qubits...)

But quantum computers aren't magic machines. They're faster at conventional machines at solving certain kinds of problems that require computing through massive search spaces (some cryptography algorithms, some physics simulations, etc)... but they're actually not a hell of a lot better than a conventional machine at anything else, and they're exceptionally complicated to build (hence why in 40 years we've barely scratched the surface of building the necessary hardware).

&gt; Or could some imaginary, immensely complex analog computer simulate a digital computer, that simulates a faster version of the original?

It will still never beat the host machine. This has nothing to do with computation specifically - you're trying to build a machine that defies the universe: a machine that generates information faster than that machine can generate information. It proves itself can't exist through simple contradiction.

If it could exist, it'd be better than a perpetual motion machine - you could use it to precompute what would happen next in the universe for every particle for all of the rest of history...</data>
      <data key="d8">1447</data>
      <data key="d9">8.587</data>
      <data key="d10">0.0</data>
      <data key="d11">12.4</data>
      <data key="d12">0.134</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 3), (3, 1), (4, 4), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 2), (13, 2), (14, 3), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 6), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 3), (47, 1), (48, 1), (49, 1), (50, 5), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 3), (65, 2), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 3), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1)]</data>
    </node>
    <node id="c134">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6anoiv</data>
      <data key="d3">e6b7k87</data>
      <data key="d4">barsoap</data>
      <data key="d5">-1</data>
      <data key="d6">1537472041.0</data>
      <data key="d7">Your computer, given enough memory and time, can compute any computable function. That's what being a (bounded) Turing machine means, it also means that you can simulate any other Turing machine.

Quantum computers are no more powerful, what makes them interesting is the possibility of exponential speedups, essentially by better physical data representation. I say "possibility" because noone has yet actually demonstrated it, and there's the possibility that any speedup you gain will be eaten by increasing quantum noise, making the whole idea impossible to exploit in practice. Butchering Einstein: "You cannot cheat God at dice".</data>
      <data key="d8">635</data>
      <data key="d9">6.5</data>
      <data key="d10">0.0646</data>
      <data key="d11">12.0</data>
      <data key="d12">0.2771</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1)]</data>
    </node>
    <node id="c135">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a7im5</data>
      <data key="d3">e6a8afs</data>
      <data key="d4">krimin_killr21</data>
      <data key="d5">34</data>
      <data key="d6">1537425014.0</data>
      <data key="d7">In order to simulate it's outcome, the computer must first know the outcome, which it could not possibly do fast than itself </data>
      <data key="d8">125</data>
      <data key="d9">5.05</data>
      <data key="d10">0.0</data>
      <data key="d11">10.7</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c136">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a7im5</data>
      <data key="d3">e6ai1t0</data>
      <data key="d4">olliej</data>
      <data key="d5">15</data>
      <data key="d6">1537434515.0</data>
      <data key="d7">Yes, but then I could run the jit on the same code and run it natively and it would still be faster than in the simulator.

Essentially if you have a jit (or recompiler) that can optimize the code for the simulator you can perform those same optimizations to run it natively. Basically what you’re doing when optimizing the code for the simulator is changing what code you are simulating.

Essentially for it to be a simulator it needs to ensure that every visible state change in the simulator matches the state changes in the machine being simulated. So even if you could (for example) recognize that a given operation was something like ‘add 0’, you could save the read/add/store but you would still need to update all the flags, and increment the pc multiple (separate) times.

Actually maybe this helps for the intuition:

Any instruction being simulated requires the simulator to increment the PC of the simulated machine, in addition to performing the operation itself. That means a best case average time to simulate an instruction is ‘average instruction time + time to increment Simualted PC’ - also necessarily you don’t have enough native state to hold the state of the simulated machine because if nothing else your simulator is already using the native PC state, so you have time cost of managing the state overflow.</data>
      <data key="d8">1330</data>
      <data key="d9">8.901</data>
      <data key="d10">0.0</data>
      <data key="d11">15.8</data>
      <data key="d12">0.4581</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 4), (2, 3), (3, 1), (4, 1), (5, 2), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1), (12, 2), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 6), (24, 3), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 3), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 5), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 3), (90, 1), (91, 4), (92, 1), (93, 1), (94, 1)]</data>
    </node>
    <node id="c137">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a7im5</data>
      <data key="d3">e6abcur</data>
      <data key="d4">khedoros</data>
      <data key="d5">7</data>
      <data key="d6">1537427953.0</data>
      <data key="d7">Ah, that's the solution! We just need to nest JIT optimization stages within each other! Have the optimizer optimize the optimizer optimizing the optimizer that optimizes the native code.

The problem here is that while there are workloads that could be optimized and run faster than native code, there are also workloads that would run slower than native code. </data>
      <data key="d8">362</data>
      <data key="d9">7.22</data>
      <data key="d10">0.0</data>
      <data key="d11">9.1</data>
      <data key="d12">0.4586</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 3), (5, 1), (6, 1), (7, 1), (8, 1), (9, 3), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 4), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 2), (28, 1), (29, 2), (30, 1)]</data>
    </node>
    <node id="c138">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6af06o</data>
      <data key="d3">e6aycxw</data>
      <data key="d4">technocapital</data>
      <data key="d5">1</data>
      <data key="d6">1537453814.0</data>
      <data key="d7">did somebody say... ａｃｃｅｌｅｒａｔｅ?</data>
      <data key="d8">31</data>
      <data key="d9">5.4</data>
      <data key="d10">0.0</data>
      <data key="d11">1.3</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1)]</data>
    </node>
    <node id="c139">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bggvd</data>
      <data key="d3">e6bh0qx</data>
      <data key="d4">Dev__</data>
      <data key="d5">3</data>
      <data key="d6">1537482269.0</data>
      <data key="d7">Care to elaborate or are you happy to leave a "you're wrong" comment.

</data>
      <data key="d8">71</data>
      <data key="d9">4.5</data>
      <data key="d10">0.1831</data>
      <data key="d11">6.0</data>
      <data key="d12">0.5574</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]</data>
    </node>
    <node id="c140">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a6wyo</data>
      <data key="d3">e6a9c93</data>
      <data key="d4">EldritchSundae</data>
      <data key="d5">9</data>
      <data key="d6">1537426009.0</data>
      <data key="d7">Right, but a NOT gate simulator that implements virtual NOT gates with 3 real gates cannot simulate that virtual NOT in less than 3 real gates' time by definition.

Or flip it around: imagine you have the world's fastest possible computer that can perform an OP infinitesimally fast.

If it were simulating itself, that simulation would be running as fast as possible (this is the world's fastest possible computer), with zero wasted cycles (the simulation is mimicking the world's fastest possible computer).

And still it could only simulate any given OP as fast as itself can run. By definition. It doesn't matter what OP is or how it's implemented, it kind of cancels out of the equation.

And we are far from the idealized perfect hardware that defies causality like this one, so in reality simulations are always gonna run slower.</data>
      <data key="d8">836</data>
      <data key="d9">7.326</data>
      <data key="d10">0.0</data>
      <data key="d11">12.5</data>
      <data key="d12">0.0051</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 2), (9, 2), (10, 1), (11, 1), (12, 5), (13, 1), (14, 2), (15, 2), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 4), (26, 3), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1)]</data>
    </node>
    <node id="c141">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a6wyo</data>
      <data key="d3">e6aglg8</data>
      <data key="d4">Kaon_Particle</data>
      <data key="d5">4</data>
      <data key="d6">1537433095.0</data>
      <data key="d7">The computer you're running the simulation on has 3 NOT gates though, if you remove those all you've done is built a better computer.  </data>
      <data key="d8">135</data>
      <data key="d9">4.696</data>
      <data key="d10">0.0</data>
      <data key="d11">11.5</data>
      <data key="d12">0.4404</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c142">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6an0qu</data>
      <data key="d3">e6anpq1</data>
      <data key="d4">Reddit1990</data>
      <data key="d5">5</data>
      <data key="d6">1537440113.0</data>
      <data key="d7">Destruction of information seems unlikely to me, even if Hawking's work suggests it. If it is true, then I have to assume spontaneous creation of information is also true.</data>
      <data key="d8">171</data>
      <data key="d9">6.043</data>
      <data key="d10">0.0</data>
      <data key="d11">8.9</data>
      <data key="d12">0.0999</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]</data>
    </node>
    <node id="c143">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6an0qu</data>
      <data key="d3">e6an101</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537439429.0</data>
      <data key="d7">**Black hole information paradox**

The black hole information paradox is a puzzle resulting from the combination of quantum mechanics and general relativity.  Calculations suggest that physical information could permanently disappear in a black hole, allowing many physical states to devolve into the same state. This is controversial because it violates a core precept of modern physics—that in principle the value of a wave function of a physical system at one point in time should determine its value at any other time. A fundamental postulate of the Copenhagen interpretation of quantum mechanics is that complete information about a system is encoded in its wave function up to when the wave function collapses.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1144</data>
      <data key="d9">10.977</data>
      <data key="d10">0.0</data>
      <data key="d11">16.4</data>
      <data key="d12">-0.0929</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 2), (2, 4), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 3), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 1), (34, 3), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 2), (50, 2), (51, 1), (52, 1), (53, 2), (54, 1), (55, 3), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1)]</data>
    </node>
    <node id="c144">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aiu70</data>
      <data key="d3">e6ayz38</data>
      <data key="d4">Oriumpor</data>
      <data key="d5">1</data>
      <data key="d6">1537454886.0</data>
      <data key="d7">you're missing the most import last piece: 'we cannot simulate the entire universe inside of the universe **at the same speed of the universe.**'

Now here's the part that'll blow your mind:

If you were in the \*inner\* simulated universe, you don't have any way of perceiving the timing reference differential, so your time is "normal" to you.  But the external universe is always going to be running at some multiplier to your own.

As the outer universe loses energy (heat death) even the most effective energy capture systems will run out of energy and so will the computer you're simulated on probably slowing down as it runs out.  But to you the world would have been going on all along at the same \*perceived\* rate, until the last \*tick\* of the simulator, which never comes.</data>
      <data key="d8">786</data>
      <data key="d9">7.046</data>
      <data key="d10">0.0089</data>
      <data key="d11">11.5</data>
      <data key="d12">0.1875</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 2), (8, 1), (9, 2), (10, 1), (11, 1), (12, 4), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 3), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1)]</data>
    </node>
    <node id="c145">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aih3j</data>
      <data key="d3">e6atue3</data>
      <data key="d4">richardathome</data>
      <data key="d5">0</data>
      <data key="d6">1537447036.0</data>
      <data key="d7">This is pretty much my reasoning as to there being no god(s). There's not enough space to contain everything and a being to know everything about that everything.</data>
      <data key="d8">162</data>
      <data key="d9">5.458</data>
      <data key="d10">0.0</data>
      <data key="d11">6.4</data>
      <data key="d12">0.125</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]</data>
    </node>
    <node id="c146">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aih3j</data>
      <data key="d3">e6az68o</data>
      <data key="d4">Oriumpor</data>
      <data key="d5">0</data>
      <data key="d6">1537455233.0</data>
      <data key="d7">you have gotta choose: precision or speed, you can be \*as precise\* as we can effectively measure in our current universe and simulate it slower than the current one, or you can lose the precision and create a neutered variant of our universe (meh, how do strong and weak gravitational forces interact?  meh, skip that part -- too much computation, just futz it with this constant...)  You can run the less precise one (likely) faster than the outer simulation, but it would be at most a subset of our universe.</data>
      <data key="d8">512</data>
      <data key="d9">6.381</data>
      <data key="d10">0.0</data>
      <data key="d11">12.5</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]</data>
    </node>
    <node id="c147">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6awoki</data>
      <data key="d3">e6bgopc</data>
      <data key="d4">CowboyFromSmell</data>
      <data key="d5">-2</data>
      <data key="d6">1537481980.0</data>
      <data key="d7">Read the comments on that StackOverflow answer. Almost every comment points out various aspects that the answer is flat out wrong. Furthermore, they provide no formal definition of a virtual machine nor link to any outside content.

Additionally, the answer says that a VM is analogous to a CPU where

&gt; An instruction executes deterministically based only on the current state of the virtual machine and does not depend on information elsewhere in the instruction stream at that point in time.

This isn’t even true for CPUs. Otherwise, how the hell did Spectre and Meltdown happen?

Here’s a [definition of a simulator:](https://www.google.com/search?q=simulator&amp;ie=UTF-8&amp;oe=UTF-8&amp;hl=en-us&amp;client=safari)

&gt; a machine with a similar set of controls designed to provide a realistic imitation of the operation of a vehicle, aircraft, or other complex system, used for training purposes.

In that sense, PyPy is certainly a simulation of Python in the same way that VirtualBox simulates Windows or Linux.

There is no inherent requirement that simulators make the same optimizations as the thing they’re simulating. That would be called a [Quine](https://www.google.com/search?client=safari&amp;hl=en-us&amp;ei=EqujW8ioFYqI8APhiZGYDA&amp;ins=false&amp;q=quine+program&amp;oq=quine&amp;gs_l=mobile-gws-wiz-serp.1.0.0i71l5.0.0..315661...0.0..0.0.0.......0.u_mxVGV43m4).

Simulators have the same interface, they aren’t required to have the same optimizations.

Edit: wording</data>
      <data key="d8">1447</data>
      <data key="d9">9.362</data>
      <data key="d10">0.0</data>
      <data key="d11">11.7</data>
      <data key="d12">-0.0388</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 2), (19, 7), (20, 2), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 4), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1)]</data>
    </node>
    <node id="c148">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bd0r3</data>
      <data key="d3">e6btc8s</data>
      <data key="d4">loamfarer</data>
      <data key="d5">2</data>
      <data key="d6">1537492383.0</data>
      <data key="d7">I'm giving a contrast between practical computation models and theoretic ones (automata.) So, computational classes, not complexity classes. When studying theoretical models of computation you aren't always sure how many state changes are necessary to pull off a particular program, its dependent on the alphabet you use and the finite state machine that is attached. This holds true for FSMs, PDAs, LBAs, PDA-IIs, and TMs. You can implement for yourself an "instruction set" then measure those concretely, but then you start moving into a physically constrained model, after all you can't just magically add numbers or do it ad-hoc on the side yourself outside the model. That needs to be described, but since those results are deterministic and finite they are just collapsed (ie. factored out) to be instantaneous and those details are instead reserved for implementation concerns. So what you measure at this stage is whether something can be computed, including cases where you can run a program that will never end but is always making progress (calculating sqrt(2) or something.)

When I say "sometimes units of measure are given" I refer to using Big O approximations as a pedagogical tool to detail language-class behavior. As opposed to solving Big O of a polynomial or dijkstra's algorithm, the example here might contrast regular and context-free language examples. None of the obtained numbers are necessarily absolute for the aforementioned hand waving. Instead you would measure them with relative bounds. It's also these models of computation that reveal a simulation will take more steps (notice steps not time) than the thing being simulated itself. Again, you really have to move off the mathematically purer models to express that formally. The best someone could do is give a step some time frame, but this given measure will be arbitrary as we know from a real computer it must be clocked to synchronize itself, because different operations and state transitions take different times. So we don't even have these details to measure in the theoretical models and adding them is an empty gesture except for pedagogical reasons.

Now with computational complexity classes, you are measuring problem classes in terms of their time and space (memory) constraints relative to different automata models. But the result that you can't simulate something faster comes from the underlying limitations of the computational models themselves.</data>
      <data key="d8">2452</data>
      <data key="d9">8.57</data>
      <data key="d10">0.0216</data>
      <data key="d11">12.9</data>
      <data key="d12">0.0682</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 2), (26, 3), (27, 3), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 6), (53, 1), (54, 1), (55, 6), (56, 1), (57, 1), (58, 1), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 1), (80, 1), (81, 3), (82, 1), (83, 1), (84, 5), (85, 2), (86, 1), (87, 2), (88, 1), (89, 2), (90, 3), (91, 1), (92, 1), (93, 1), (94, 1), (95, 3), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 3), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 2), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 2), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 2), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 2), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 2), (170, 1), (171, 2), (172, 1), (173, 2), (174, 2), (175, 1), (176, 2), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 2), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1)]</data>
    </node>
    <node id="c149">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahz34</data>
      <data key="d3">e6anc46</data>
      <data key="d4">umpc</data>
      <data key="d5">17</data>
      <data key="d6">1537439737.0</data>
      <data key="d7">Simplifying a bit, though they are saying in general that computers are bounded by physics whereas computation is bounded by mathematics.</data>
      <data key="d8">137</data>
      <data key="d9">6.389</data>
      <data key="d10">0.0</data>
      <data key="d11">13.8</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c150">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahz34</data>
      <data key="d3">e6ax1hb</data>
      <data key="d4">pilotInPyjamas</data>
      <data key="d5">1</data>
      <data key="d6">1537451571.0</data>
      <data key="d7">Imagine a computer simulating itself running a simple program,like count a value from 0 to 10^50, then print "finished". This would take an absurdly long time. Theoretically, the computer may perform some static analysis which decides that since we don't need to use the result of the variable, we can omit it from the simulation. So theoretically, the simulated computer may run faster that the program on the actual machine. In practice, this is probably not the case.</data>
      <data key="d8">470</data>
      <data key="d9">6.016</data>
      <data key="d10">0.0191</data>
      <data key="d11">9.4</data>
      <data key="d12">0.068</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 3), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]</data>
    </node>
    <node id="c151">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6csq2b</data>
      <data key="d3">e6d612d</data>
      <data key="d4">t_bptm</data>
      <data key="d5">2</data>
      <data key="d6">1537539434.0</data>
      <data key="d7">My mistake, thanks. </data>
      <data key="d8">20</data>
      <data key="d15">5</data>
      <data key="d10">0.0</data>
      <data key="d11">5.6</data>
      <data key="d12">0.128</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1)]</data>
    </node>
    <node id="c152">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aq2gq</data>
      <data key="d3">e6b3b29</data>
      <data key="d4">stringParameter</data>
      <data key="d5">2</data>
      <data key="d6">1537463799.0</data>
      <data key="d7">username checks out</data>
      <data key="d8">19</data>
      <data key="d9">5.667</data>
      <data key="d10">0.0</data>
      <data key="d11">0.9</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1)]</data>
    </node>
    <node id="c153">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6af9mo</data>
      <data key="d3">e6amts2</data>
      <data key="d4">SuperGameTheory</data>
      <data key="d5">7</data>
      <data key="d6">1537439234.0</data>
      <data key="d7">I like you. You use words I don’t know to describe my thoughts.

My user name, Supergame Theory, came to me as I was reading up on game theory. By that time I had already invested a bunch of time studying and investigating emergent behavior (via flocking and swarming algorithms...social behavior simulations, I called them). So, I reasoned that emergent behavior must be some sort of *super*game theory, where the simple rules of a game expand out to ever more complex rules as you expand the scope of your observation. I was wrong, I found out, as supergame theory is actually the study of multiple games over time. But I liked the way it sounded, so I stuck with it.

Anyway, I view a lot of things through the lens of emergent behavior. For instance, our cognitive abilities emerge from the relatively simple rules that neurons follow. Physical reality is no different, then, as our physical system emerges from the relatively simple rules of quantum physics. In that respect, quantum physics emerges from its own system.

I tickles my brain to think that what we see as quantum physics is probably a small portion of it’s full system - we only see the parts we can rationalize with our time/space thinking; that it’s only the little bits we can see or fathom because it’s the only parts from which our physical system emerges. I like to think that the larger portion of quantum physics out there is unapproachable because we can’t interact with it. And what of the completely unapproachable system from which quantum physics emerges? What if our language of math, in all its complexity and depth of knowledge, is fundamentally unable to describe the system that quantum physics emerges because our maths deal with things like quantity, which itself might be an emergent concept. In other words, what if quantity only exists as a function of something else?

Anyway, it’s been fun pondering here in my little downvote hole. Thanks for being the one to reply with a really thoughtful comment. You are awesome.</data>
      <data key="d8">2012</data>
      <data key="d9">8.751</data>
      <data key="d10">0.0</data>
      <data key="d11">8.9</data>
      <data key="d12">0.1739</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 3), (15, 1), (16, 1), (17, 1), (18, 1), (19, 4), (20, 1), (21, 2), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 4), (39, 1), (40, 3), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 8), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 5), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 3), (70, 1), (71, 5), (72, 1), (73, 1), (74, 1), (75, 2), (76, 5), (77, 1), (78, 6), (79, 1), (80, 2), (81, 1), (82, 5), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 3), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 4), (109, 1), (110, 1), (111, 1), (112, 2), (113, 1), (114, 1), (115, 1), (116, 4), (117, 1), (118, 2), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 2), (128, 1), (129, 1), (130, 1), (131, 1), (132, 2), (133, 3), (134, 3), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1)]</data>
    </node>
    <node id="c154">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6af9mo</data>
      <data key="d3">e6avuqw</data>
      <data key="d4">dancorbe</data>
      <data key="d5">-13</data>
      <data key="d6">1537449737.0</data>
      <data key="d7">You're wasting your energy on someone who's obviously a drug burn-out; and that's why this person is being downvoted.

</data>
      <data key="d8">119</data>
      <data key="d9">5.105</data>
      <data key="d10">0.0</data>
      <data key="d11">10.7</data>
      <data key="d12">-0.1531</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c155">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6amppf</data>
      <data key="d3">e6an7yd</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">2</data>
      <data key="d6">1537439621.0</data>
      <data key="d7">&gt;  if the simulation were identical to the machine, how would that simulation exist?

Is it not the case that two digital images could be identical, down to each and every pixel, but one image be compressed such that it occupies a smaller amount of memory than the other?

</data>
      <data key="d8">273</data>
      <data key="d9">5.658</data>
      <data key="d10">0.0</data>
      <data key="d11">11.5</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 3), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]</data>
    </node>
    <node id="c156">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ab7wr</data>
      <data key="d3">e6acquo</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-9</data>
      <data key="d6">1537429300.0</data>
      <data key="d7">*all* information is energy? also, even if it were true, exactly how does that apply here?

EDIT: Downvote if you wish but at least present a coherent argument. This *is* /r/compsci for afterall</data>
      <data key="d8">194</data>
      <data key="d9">4.656</data>
      <data key="d10">0.0</data>
      <data key="d11">5.3</data>
      <data key="d12">-0.34</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]</data>
    </node>
    <node id="c157">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6abg3m</data>
      <data key="d3">e6abxik</data>
      <data key="d4">sn0rrlax</data>
      <data key="d5">2</data>
      <data key="d6">1537428502.0</data>
      <data key="d7">Quantum computing isn’t too far out (computers that can use more than just binary 0 and 1 bits)</data>
      <data key="d8">95</data>
      <data key="d9">3.8</data>
      <data key="d10">0.0</data>
      <data key="d11">8.0</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]</data>
    </node>
    <node id="c158">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aogcn</data>
      <data key="d3">e6bypjq</data>
      <data key="d4">Anonymous</data>
      <data key="d5">1</data>
      <data key="d6">1537496802.0</data>
      <data key="d7">[deleted]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c159">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a8afs</data>
      <data key="d3">e6avm7l</data>
      <data key="d4">Sukrim</data>
      <data key="d5">-11</data>
      <data key="d6">1537449405.0</data>
      <data key="d7">Peephole optimizers exist, if you for example see a bogosort implementation you can replace it with a better algorithm if you are only interested in the result.

It is not possible to perfectly simulate a complete system on itself anyways (if you simulate something that uses all available resources on the system, the simulator still needs to fit in addition to that).</data>
      <data key="d8">369</data>
      <data key="d9">6.543</data>
      <data key="d10">0.0</data>
      <data key="d11">16.6</data>
      <data key="d12">0.3042</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]</data>
    </node>
    <node id="c160">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ai1t0</data>
      <data key="d3">e6av3yl</data>
      <data key="d4">Sukrim</data>
      <data key="d5">-4</data>
      <data key="d6">1537448709.0</data>
      <data key="d7">If you require that level of precision (all states of registers, PC etc. are accessible for every intermediate state) from your simulation, then of course I agree.

If your simulation criteria can be relaxed (you simulate "x = 1+1+1+1+1; print x" as "print 5"), then the optimizer could of course also run outside the simulator natively. If it doesn't however, there is a chance that the simulation reaches the correct end state faster than the native naive implementation for a certain class of programs. Even intermediate states (how would the machine look like after 2000 cycles?) could be computed potentially faster for some programs than running them. Thus I'm not so sure about the "always" claim as long as it is not followed by "in the general case".

Anyways, thanks for your long answer.</data>
      <data key="d8">798</data>
      <data key="d9">6.848</data>
      <data key="d10">0.0727</data>
      <data key="d11">8.6</data>
      <data key="d12">0.2563</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 2), (16, 2), (17, 3), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1)]</data>
    </node>
    <node id="c161">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6abcur</data>
      <data key="d3">e6av9la</data>
      <data key="d4">Sukrim</data>
      <data key="d5">2</data>
      <data key="d6">1537448919.0</data>
      <data key="d7">Sure, to refute an "always" claim however, you only need a single counter example.</data>
      <data key="d8">82</data>
      <data key="d9">4.571</data>
      <data key="d10">0.0854</data>
      <data key="d11">8.8</data>
      <data key="d12">0.3182</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]</data>
    </node>
    <node id="c162">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bh0qx</data>
      <data key="d3">e6bjvbs</data>
      <data key="d4">MjrK</data>
      <data key="d5">3</data>
      <data key="d6">1537484685.0</data>
      <data key="d7">Sure

&gt; You can use a light bulb to power a solar cell that powers a light bulb.

&gt; The second light bulb will never emit as much energy as the first.

The assumption of a lower output is due to transmission energy loss or imperfect capture or whatever other physical imperfections in your system design. This setup is a perpetual motion machine of the third kind - it is practically impossible, but does not violate the laws of thermodybamics.

This isn't really analogous to computational overhead because it owes to a practical limitation not a theoretical limitation.


&gt; Or you could go with a photocopier analogy - if you copy a copy of copy there will be a reduction in quality. There will always be a loss. As the other commentor suggested if there was some kind of improvement or increase within the system the consequences would be absurd. 


What do you even mean by quality in this context? An exact replication of the photo, or a faithful representation of some original / reference artifact?

If you mean exact replication, you would have to define some metric for exactness because when you get down to the level of electrons, quantum physics explicitly prohibits copying quantum states. In which case, there is a fundamental physical limit prohibiting exact copying - this is not analogous to computational overhead.

If you mean faithful representation of some reference, with machine learning it is possible to make copies of antique photos which look more faithful to a scene than the antique photo. In this case, it clearly this isn't analogous to computational overhead because it's possible to do better than the original.</data>
      <data key="d8">1644</data>
      <data key="d9">9.096</data>
      <data key="d10">0.0</data>
      <data key="d11">12.0</data>
      <data key="d12">0.1626</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 3), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 3), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 2), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 3), (44, 3), (45, 3), (46, 2), (47, 1), (48, 1), (49, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 4), (69, 1), (70, 3), (71, 2), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (78, 3), (79, 3), (80, 3), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 4), (88, 2), (89, 2), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 2), (105, 1), (106, 1), (107, 1), (108, 2), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 2), (122, 1), (123, 1), (124, 2)]</data>
    </node>
    <node id="c163">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6a9c93</data>
      <data key="d3">e6kobng</data>
      <data key="d4">ctchalk</data>
      <data key="d5">1</data>
      <data key="d6">1537854246.0</data>
      <data key="d7">I'm referring to Dustin's simplified model. There's no mention of a computer. I'm just pointing out that there is an issue with this simplified explanation.</data>
      <data key="d8">156</data>
      <data key="d9">5.609</data>
      <data key="d10">0.0</data>
      <data key="d11">6.5</data>
      <data key="d12">-0.0987</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1)]</data>
    </node>
    <node id="c164">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aglg8</data>
      <data key="d3">e6ko6p3</data>
      <data key="d4">ctchalk</data>
      <data key="d5">1</data>
      <data key="d6">1537854126.0</data>
      <data key="d7">I'm talking about the model given in this comment. There is no mention of a computer. I'm just pointing out that this simplified explanation is problematic.</data>
      <data key="d8">156</data>
      <data key="d9">5.565</data>
      <data key="d10">0.0</data>
      <data key="d11">6.7</data>
      <data key="d12">-0.2455</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2)]</data>
    </node>
    <node id="c165">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6anpq1</data>
      <data key="d3">e6ap8hy</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">4</data>
      <data key="d6">1537441672.0</data>
      <data key="d7">Yeah, it's a real problem for everyone that black holes seem to destroy information, for exactly the reasons you can imagine. We want there to be a strong conservation of information law as a direct corollary to the conservation of mass and energy... but we're not there yet.

And Hawkings' work for the most part was trying to resolve the paradox in such a way that information is conserved, while Penrose doesn't seem to mind that information can be destroyed by black holes, and thinks the universe can still be resolved even if it is the case. Still others think that the information resides as a holographic projection on the black hole itself, and isn't lost as much as it is *stored indefinitely* (essentially, black holes become some gigantic form of universal data compression), but you need a lot of string theory and untestable predictions to get there.

It's fascinating to read about, even if it requires a lot of fringe thinking and pretty unsubstantiated math. (And thinking about information being lost as being encoded as the difference between Planck time lets you postulate that time travel is possible, which is also really fun to think about.)</data>
      <data key="d8">1164</data>
      <data key="d9">7.867</data>
      <data key="d10">0.0</data>
      <data key="d11">13.1</data>
      <data key="d12">0.2021</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 4), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 5), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 5), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 2), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 2), (95, 2), (96, 1), (97, 1), (98, 1)]</data>
    </node>
    <node id="c166">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ayz38</data>
      <data key="d3">e6b0291</data>
      <data key="d4">mistahspecs</data>
      <data key="d5">1</data>
      <data key="d6">1537456886.0</data>
      <data key="d7">I get that this whole post is about time with relation to simulations, however the comment I replied to did not address time.  While I love the sentiment you posted about (especially the notion of the final tick never actually arriving), I was more so speaking with regards to matter and energy, not processing speed.

I think its possible to simulate **a** universe inside of a universe like what you spoke on, but the post I was replying to mentioned "the" universe.  I don't see any way in which the entirety of the universe and its state can be represented within itself.

For example, say we want to simulate an atom, it would take well over an atom to act as memory for that atom and its metadata if you will, right?</data>
      <data key="d8">722</data>
      <data key="d9">6.3</data>
      <data key="d10">0.0055</data>
      <data key="d11">11.2</data>
      <data key="d12">0.2561</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1), (47, 3), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1)]</data>
    </node>
    <node id="c167">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6atue3</data>
      <data key="d3">e6aytwf</data>
      <data key="d4">p_pistol</data>
      <data key="d5">1</data>
      <data key="d6">1537454638.0</data>
      <data key="d7">Well, it doesn't mean there is no God, but the good would certainly not be omniscient.

That is, if god even comes to this universe.</data>
      <data key="d8">132</data>
      <data key="d9">4.25</data>
      <data key="d10">0.0</data>
      <data key="d11">3.4</data>
      <data key="d12">0.5442</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c168">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6az68o</data>
      <data key="d3">e6bs3v1</data>
      <data key="d4">olliej</data>
      <data key="d5">1</data>
      <data key="d6">1537491378.0</data>
      <data key="d7">If its a simulation, within the bounds of the stated rule, then you do have to simulate all state, otherwise you aren't simulating the machine you say you are :)</data>
      <data key="d8">161</data>
      <data key="d9">5.16</data>
      <data key="d10">0.0</data>
      <data key="d11">13.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c169">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6btc8s</data>
      <data key="d3">e6cqwl3</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">1</data>
      <data key="d6">1537522151.0</data>
      <data key="d7">Theoretical models have utmost practical relevance i.e. they are used to gauge which problems can be efficiently solved in practice (since the computational models much describe a modern machine within polynomial factors). So the most important practical implications of doing so stems from this. Static level compiler optimisations do not change any of that, as I see it, and I think it may be misleading to state it like that and dismiss theoretical models, when the largest implications such a speedup can be easily seen. The implication would also seem to contradict all that we conjecture about complexity classes. Maybe I am missing your point?</data>
      <data key="d8">650</data>
      <data key="d9">6.209</data>
      <data key="d10">0.0</data>
      <data key="d11">11.3</data>
      <data key="d12">0.0658</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1)]</data>
    </node>
    <node id="c170">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ax1hb</data>
      <data key="d3">e6b2v4d</data>
      <data key="d4">Alaskan_Thunder</data>
      <data key="d5">4</data>
      <data key="d6">1537462811.0</data>
      <data key="d7">In order to simulate a computer counting from 0 to 10^50, the machine not only needs to count from 0 to 10^50, but it also has to simulate the computer doing the actual thing.</data>
      <data key="d8">175</data>
      <data key="d9">5.708</data>
      <data key="d10">0.0</data>
      <data key="d11">15.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1)]</data>
    </node>
    <node id="c171">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ax1hb</data>
      <data key="d3">e6b244l</data>
      <data key="d4">sheikhy_jake</data>
      <data key="d5">3</data>
      <data key="d6">1537461143.0</data>
      <data key="d7">Isn't that not a complete simulation though? You're simulating a simplified scenario in which the long computation isn't actually performed. </data>
      <data key="d8">141</data>
      <data key="d9">6.263</data>
      <data key="d10">0.0</data>
      <data key="d11">11.9</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]</data>
    </node>
    <node id="c172">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ax1hb</data>
      <data key="d3">e6bd8r7</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">3</data>
      <data key="d6">1537478807.0</data>
      <data key="d7">Your remark is highly esoteric and completely irrelevant to computational complexity though, since the problem of determining whether a part of the computation is irrelevant to the result you want is undecidable.</data>
      <data key="d8">212</data>
      <data key="d9">7.16</data>
      <data key="d10">0.0</data>
      <data key="d11">20.5</data>
      <data key="d12">-0.34</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]</data>
    </node>
    <node id="c173">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b3b29</data>
      <data key="d3">e6b3ftv</data>
      <data key="d4">voidmechanic</data>
      <data key="d5">6</data>
      <data key="d6">1537464077.0</data>
      <data key="d7">It was an admittedly stupid comment. Somehow the 40 downvotes still feel like fame. I'm not a troll. Just not funny. I apologize 😂😂</data>
      <data key="d8">131</data>
      <data key="d9">4.522</data>
      <data key="d10">0.0</data>
      <data key="d11">2.8</data>
      <data key="d12">-0.052</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c174">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6amts2</data>
      <data key="d3">e6bl0cq</data>
      <data key="d4">timshoaf</data>
      <data key="d5">2</data>
      <data key="d6">1537485627.0</data>
      <data key="d7">I have some interesting thoughts on emergent microeconometric phenomena that would be fun to discuss sometime if you'd like. My background is predominantly in ML and Stats so I, too, am captured by these thoughts regulary.

Stumbled on this article this morning you might be interested: https://arstechnica.com/science/2018/09/quantum-observers-with-knowledge-of-quantum-mechanics-break-reality/
Maybe we aren't so crazy after all.</data>
      <data key="d8">431</data>
      <data key="d9">7.729</data>
      <data key="d10">0.0</data>
      <data key="d11">12.1</data>
      <data key="d12">0.3986</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]</data>
    </node>
    <node id="c175">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6avuqw</data>
      <data key="d3">e6bkv3c</data>
      <data key="d4">timshoaf</data>
      <data key="d5">3</data>
      <data key="d6">1537485507.0</data>
      <data key="d7">Sometimes, /u/dancorbe, the most interesting of notions don't come from well thought through processes. The randomness of a drug fueled haze can--in the right hands--become a revelation. I like to view this as a social analogue to simulated annealing. Why build another wheel when the one we have works fine? Because I want to. Not because it is rational.

And that randomness provides just enough exploration in the explore exploit duality to get us out of a local minima.

Never discount the dreamers or the children, even if most dreams end up being wrong.</data>
      <data key="d8">559</data>
      <data key="d9">5.709</data>
      <data key="d10">0.0</data>
      <data key="d11">6.7</data>
      <data key="d12">0.1197</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1)]</data>
    </node>
    <node id="c176">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6an7yd</data>
      <data key="d3">e6ars1e</data>
      <data key="d4">nupogodi</data>
      <data key="d5">14</data>
      <data key="d6">1537444479.0</data>
      <data key="d7">Sure but there's a limit through the pigeonhole principle.

Theoretically your simulation could run in an environment that is cleverer than the hardware of the machine and can optimize the simulated task to be more efficient than the same task on the hardware, this is where you get into cases where JITted code can be faster than native code because runtime optimizations can optimize out dead code that is only dead at runtime, or can more intelligently prime a branch predictor or what have you ---- but you have changed the rules of the game, since it's not the same task anymore (and you can still run the optimized task on the bare metal and it will in a physical world be faster or equal than the optimized task on a simulator). </data>
      <data key="d8">736</data>
      <data key="d9">7.789</data>
      <data key="d10">0.0</data>
      <data key="d11">27.7</data>
      <data key="d12">0.5382</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 3), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1), (37, 2), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 5), (52, 4), (53, 2), (54, 1), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1)]</data>
    </node>
    <node id="c177">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6an7yd</data>
      <data key="d3">e6bcfns</data>
      <data key="d4">nemec</data>
      <data key="d5">4</data>
      <data key="d6">1537477988.0</data>
      <data key="d7">What can you do with a compressed image? Nothing, until it's decompressed. So now the smaller image requires a decompression routine which limits performance. </data>
      <data key="d8">159</data>
      <data key="d9">5.955</data>
      <data key="d10">0.0</data>
      <data key="d11">7.6</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]</data>
    </node>
    <node id="c178">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6acquo</data>
      <data key="d3">e6afc6p</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">11</data>
      <data key="d6">1537431856.0</data>
      <data key="d7">Yes, all information is energy. Think about it, how do you present any information about anything in the entire universe? Configuration of matter? EM wave? Neutrino signal? Displacement of the space time continuum? They're all different forms of energy.

How does it apply here? A computer that could simulate itself faster than it could run is better than a perpetual motion machine - it's a machine that generates more information than it started with from nothing - somehow the simulated machine would be generating information faster than the machine itself...but then the machine would be actually generating that information... but then the simulation would be faster still. It's a self-contradiction: we've proven a machine can't run faster than itself, even if it's simulating a computer.

The fastest possible 'computer in a computer' we have now is a hardware virtual machine, and despite running all the same instructions as the outer machine, even virtual machines have overhead - they have to translate memory accesses to ensure the guest machine can't violate the memory of the host machine (lest it corrupt either itself or some other process on the system). You can keep reducing that overhead, but you can't get rid of it. That overhead is essentially a physical manifestation of entropy - energy irretrievably lost to the disordering of the system.

Keep thinking about the problem and eventually you'll understand why this is a limitation of the actual universe, nothing special about computers being involved. It might help you to google [why you can't simulate the entire universe inside of the universe](http://wtamu.edu/~cbaird/sq/2014/09/15/could-scientists-perfectly-simulate-the-entire-universe-in-a-computer-down-to-the-last-atom/), e.g., it's a question that's pretty common to people new to physics.</data>
      <data key="d8">1828</data>
      <data key="d9">9.831</data>
      <data key="d10">0.0</data>
      <data key="d11">12.2</data>
      <data key="d12">0.1056</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 4), (7, 1), (8, 1), (9, 1), (10, 2), (11, 2), (12, 1), (13, 4), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 4), (26, 1), (27, 1), (28, 2), (29, 1), (30, 2), (31, 4), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 3), (38, 2), (39, 1), (40, 1), (41, 8), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 5), (56, 4), (57, 2), (58, 1), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 2), (84, 1), (85, 1), (86, 2), (87, 1), (88, 1), (89, 2), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 2), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1)]</data>
    </node>
    <node id="c179">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6acquo</data>
      <data key="d3">e6af9kz</data>
      <data key="d4">revereddesecration</data>
      <data key="d5">8</data>
      <data key="d6">1537431786.0</data>
      <data key="d7">It's pretty clear that you need to read a book or two. I know, I know, I sound like a douche, but "information is energy" is basic computer science. It takes a minuscule but well defined minimum amount of energy to flip a bit in a perfect system. Something to do with Planck's constant I think? I need to brush up on this. </data>
      <data key="d8">323</data>
      <data key="d9">5.319</data>
      <data key="d10">0.0681</data>
      <data key="d11">4.7</data>
      <data key="d12">0.3954</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c180">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6acquo</data>
      <data key="d3">e6c00vm</data>
      <data key="d4">rhorama</data>
      <data key="d5">1</data>
      <data key="d6">1537497902.0</data>
      <data key="d7">&gt;all information is energy?

Yes. Read a book. 

&gt;Downvote if you wish but at least present a coherent argument. This is /r/compsci for afterall

Oh I've definitely been downvoting your tripe.

My argument: you clearly have no knowledge on information theory or computing theory. This is evident because you aren't even grasping the basics. 

Go read a book, or perhaps take a basic course on the topics and come back when you aren't arguing against thermodynamics.</data>
      <data key="d8">465</data>
      <data key="d9">6.15</data>
      <data key="d10">0.0</data>
      <data key="d11">7.5</data>
      <data key="d12">0.0815</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1)]</data>
    </node>
    <node id="c181">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6abxik</data>
      <data key="d3">e6ad842</data>
      <data key="d4">_georgesim_</data>
      <data key="d5">8</data>
      <data key="d6">1537429779.0</data>
      <data key="d7">It’s also not a silver bullet and has very specific, concrete limitations. Not that you implied otherwise, but I thought it would be worth pointing out given the context.</data>
      <data key="d8">170</data>
      <data key="d9">4.452</data>
      <data key="d10">0.0</data>
      <data key="d11">7.8</data>
      <data key="d12">0.1646</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c182">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6abxik</data>
      <data key="d3">e6adjbr</data>
      <data key="d4">Little_Milton</data>
      <data key="d5">0</data>
      <data key="d6">1537430084.0</data>
      <data key="d7">Qbits scare me tho. Start talking about spins and I’m lost</data>
      <data key="d8">58</data>
      <data key="d9">3.615</data>
      <data key="d10">0.0</data>
      <data key="d11">-0.6</data>
      <data key="d12">-0.4939</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]</data>
    </node>
    <node id="c183">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bypjq</data>
      <data key="d3">e6bypsv</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537496808.0</data>
      <data key="d7">**P versus NP problem**

The P versus NP problem is a major unsolved problem in computer science. It asks whether every problem whose solution can be quickly verified (technically, verified in polynomial time) can also be solved quickly (again, in polynomial time).

The underlying issues were first discussed in the 1950s, in letters from John Forbes Nash Jr. to the National Security Agency, and from Kurt Gödel to John von Neumann.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">861</data>
      <data key="d9">10.515</data>
      <data key="d10">0.0</data>
      <data key="d11">15.6</data>
      <data key="d12">0.051</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 3), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]</data>
    </node>
    <node id="c184">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6av3yl</data>
      <data key="d3">e6bsueu</data>
      <data key="d4">olliej</data>
      <data key="d5">2</data>
      <data key="d6">1537491975.0</data>
      <data key="d7">But the statement is a machine *simulating itself* that means you do have to track the full machine state. If your simulator is not tracing all state of what it is executing it is fundamentally simulating a different machine.

Once your simulator is not confined to matching the machine you're running on, the statement we're talking about is no longer applicable. You open up all sorts of optimizations that can be performed on an abstraction of the machine. e.g. on machines that have them you'd get a big win if you dropped updates to the status register unless you could prove they were needed. Or you have the multiply case I mentioned.

Basically in the context of things like this "simulator" is the theoretical definition: exact match of behavior, as opposed to emulating, which would bee "observable output is the same".

and again: any optimization your simulator is doing can be done in the native machine as well, at which point it will be at minimum just as fast as the simulated code (in practice it will *always* be faster)</data>
      <data key="d8">1038</data>
      <data key="d9">7.289</data>
      <data key="d10">0.0385</data>
      <data key="d11">10.9</data>
      <data key="d12">0.0486</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 4), (8, 2), (9, 1), (10, 1), (11, 3), (12, 1), (13, 1), (14, 2), (15, 3), (16, 1), (17, 1), (18, 1), (19, 3), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2)]</data>
    </node>
    <node id="c185">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6av9la</data>
      <data key="d3">e6aximg</data>
      <data key="d4">khedoros</data>
      <data key="d5">1</data>
      <data key="d6">1537452367.0</data>
      <data key="d7">I can run an infinite number of emulations at infinite speed on a finite computer, if the only effect I'm simulating is a NOP instruction. There's the trivial counter-example to "must always run slower"...but I also take it to mean that that's not what the professor was claiming. Similarly, I think that speed-up to automatic optimization is *also* probably outside of the scope of the intended claim.

So, I'll turn to the wording of the quote. "Simulation" is used, in contrast to "emulation". And generally, simulation is taken to mean that you're modeling the internal states of the target system, while emulation means that you're modeling the external behavior of the target system. You can base an *emulator* around JIT, and produce a recreation of some computer's behavior by running equivalent faster code. But if you've got to maintain a simulation of the internal state of the system, I think it's safe to say that the simulation will run slower than the machine it's hosted on.</data>
      <data key="d8">990</data>
      <data key="d9">7.673</data>
      <data key="d10">0.0444</data>
      <data key="d11">10.5</data>
      <data key="d12">0.0971</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 5), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 2), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 3), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1)]</data>
    </node>
    <node id="c186">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ap8hy</data>
      <data key="d3">e6bi72w</data>
      <data key="d4">singham</data>
      <data key="d5">1</data>
      <data key="d6">1537483280.0</data>
      <data key="d7">Found more information here.  

https://physics.stackexchange.com/questions/305602/conservation-of-information-and-determinism</data>
      <data key="d8">126</data>
      <data key="d9">23.6</data>
      <data key="d10">0.0</data>
      <data key="d11">52.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</data>
    </node>
    <node id="c187">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b0291</data>
      <data key="d3">e6b0pdd</data>
      <data key="d4">Oriumpor</data>
      <data key="d5">1</data>
      <data key="d6">1537458172.0</data>
      <data key="d7">except that's unordered data, effectively.  Now we're talking simulation design: Compression: gaseous fields are cheap to compress (think image compression schemes.)  Any homogenous mass could then be represented using fewer particles using a compression scheme. Optimizations: clearly there are unobserved parts of the universe we don't have to actually simulate, we can use macro-simulations until micro interactions cross some macro threshold/they're observed directly etc. Moreover, we can pick what an "observer" represents in the simulation and optimize the universe itself by not simulating unobserved events that would happen in isolation from any "relevant" observer.

This isn't an easy thing to just design in a Reddit post (lulz clearly) but you can see how there are ways that within the design constraints given it's still possible to simulate a universe *in* a universe.  The beauty of the simulation(s) from a cosmological perspective is that it's a nice thought experiment for lots of different problems.</data>
      <data key="d8">1021</data>
      <data key="d9">7.425</data>
      <data key="d10">0.0176</data>
      <data key="d11">13.0</data>
      <data key="d12">0.1844</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 3), (52, 1), (53, 1), (54, 2), (55, 1), (56, 3), (57, 2), (58, 1), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1)]</data>
    </node>
    <node id="c188">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bs3v1</data>
      <data key="d3">e6glg3c</data>
      <data key="d4">Oriumpor</data>
      <data key="d5">1</data>
      <data key="d6">1537685814.0</data>
      <data key="d7">Yeah I guess I'm assuming a basic property of this system will be it will have to use compression schemes to be able to store the data in a meaningful way anyways.  Which means the speed of simulated the universe will have to be slower.  Unless you can optimize by removing unobservable calculations you will *always* have to operate slower in the inner simulation.</data>
      <data key="d8">365</data>
      <data key="d9">6.556</data>
      <data key="d10">0.0</data>
      <data key="d11">11.6</data>
      <data key="d12">0.3454</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 3), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 4)]</data>
    </node>
    <node id="c189">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6cqwl3</data>
      <data key="d3">e6csq0k</data>
      <data key="d4">loamfarer</data>
      <data key="d5">1</data>
      <data key="d6">1537523815.0</data>
      <data key="d7">I think you are missing my point, because I am not trying dismiss theoretical models, I'm acknowledging them. I'm just focusing on the limits of absolute quantification and contrasting how the granularity of the bounds and analysis differ in a non-trivial way between the theoretical and practical models. Though the bounds still share the same relative class-orderings in either case. Perhaps some skirting of details in my earliest post has lead you think I'm taking a misleading approach, I'm guilty of writing an internet post not a dissertation here. Terms of the art might not be translating well.

You bring up static compilation optimizations and say it doesn't change anything, well I didn't even discuss that myself. When considering the language-classes of automata you aren't considering higher-level concrete languages anyways. I'm not really getting the point you are trying to bring up here. But to clarify, I'm intentionally drawing a distinction between O() run times analysis and computational complexity classes, of which there is a distinction. I'm really not saying anything in regards to the ability to lower a higher level language construct down into an equivalent optimized version with a different performance characteristic. I'm not dismissing these things, I'm simply detailing other things. I hope this helps?</data>
      <data key="d8">1338</data>
      <data key="d9">8.095</data>
      <data key="d10">0.0</data>
      <data key="d11">11.2</data>
      <data key="d12">0.0244</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 2), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 2), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 2), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1)]</data>
    </node>
    <node id="c190">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b2v4d</data>
      <data key="d3">e6b37my</data>
      <data key="d4">pilotInPyjamas</data>
      <data key="d5">2</data>
      <data key="d6">1537463588.0</data>
      <data key="d7">That depends on how you define the simulation. At what granularity of time do you need to consider it properly simulated? You could simulate the state for each clock cycle of the CPU, but if you wanted to you could simulate a shorter time interval and emulate the physical properties of the silicon in the transistors. Alternatively, you could simulate the state of the CPU once per minute, or once per hour, and only try to calculate what is absolutely necessary to get those individual samples. Instead of writing about how granular we need our simulation, instead consider a program `p` which takes an input `t`, and returns the state of the computer at time `t`. For the contrived example I provided, `p` could run in O(1) time, whereas the actual program would run in O(t), making the simulation asymptotically faster.</data>
      <data key="d8">823</data>
      <data key="d9">7.371</data>
      <data key="d10">0.0</data>
      <data key="d11">12.5</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 4), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 2), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 3), (48, 1), (49, 1), (50, 1), (51, 1), (52, 3), (53, 1), (54, 1), (55, 3), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 1), (62, 1), (63, 1)]</data>
    </node>
    <node id="c191">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b2v4d</data>
      <data key="d3">e6bh4cn</data>
      <data key="d4">singham</data>
      <data key="d5">1</data>
      <data key="d6">1537482357.0</data>
      <data key="d7">Not directly related but interesting nonetheless. 

https://physics.stackexchange.com/questions/257323/if-we-had-a-perfectly-efficient-computer-and-all-the-energy-in-the-milky-way-a</data>
      <data key="d8">181</data>
      <data key="d9">24.571</data>
      <data key="d10">0.0</data>
      <data key="d11">46.1</data>
      <data key="d12">0.5499</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]</data>
    </node>
    <node id="c192">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b244l</data>
      <data key="d3">e6b2xss</data>
      <data key="d4">pilotInPyjamas</data>
      <data key="d5">-5</data>
      <data key="d6">1537462981.0</data>
      <data key="d7">That depends. If your program is supposed to output the all of the intermediary states in addition to the final result, then OP's statement is trivially true, since it will take a long time just to perform the output, regardless of the underlying computation. However, if your program takes as an input a value `t` and returns the state of the computation at time `t`, then it may not need to take `t` time to return that result. We could calculate any state of that computer in O(1) time, but to run the actual program is O(t), so it is asymptotically faster to simulate than it would be to run directly. 

Edit: this is only for the specific case of the computer counting from 0 to 10^50. For arbitrary programs, this is obviously untrue.</data>
      <data key="d8">740</data>
      <data key="d9">6.733</data>
      <data key="d10">0.0</data>
      <data key="d11">12.6</data>
      <data key="d12">0.139</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 3), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 2), (42, 2), (43, 3), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1)]</data>
    </node>
    <node id="c193">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b3ftv</data>
      <data key="d3">e6b7f4b</data>
      <data key="d4">stringParameter</data>
      <data key="d5">2</data>
      <data key="d6">1537471826.0</data>
      <data key="d7">Sometimes you just need to go full-derp on a comment. It has to be done, no matter how many downvotes come your way.

My record is only like -66 or something though and that was a sensible comment (the person was being an absolute snowflake)</data>
      <data key="d8">241</data>
      <data key="d9">4.634</data>
      <data key="d10">0.0</data>
      <data key="d11">5.6</data>
      <data key="d12">-0.1366</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]</data>
    </node>
    <node id="c194">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6afc6p</data>
      <data key="d3">e6ahu6k</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-7</data>
      <data key="d6">1537434306.0</data>
      <data key="d7">&gt; Yes, all information is energy. Think about it, **how do you *present* any information** about anything in the entire universe? Configuration of matter? EM wave? Neutrino signal? Displacement of the space time continuum? 

Do you disagree that it is possible to distinguish between information and the presentation of information/medium by which it is conveyed?</data>
      <data key="d8">363</data>
      <data key="d9">6.905</data>
      <data key="d10">0.0</data>
      <data key="d11">9.9</data>
      <data key="d12">0.0328</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c195">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6af9kz</data>
      <data key="d3">e6afy4p</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-9</data>
      <data key="d6">1537432461.0</data>
      <data key="d7">&gt; It's pretty clear that you need to read a book or two. 

It's pretty clear all you've *only* read but never tried to understand...

If the bits were randomly flipped on two hardrives, such that 1 hardrive was noise and the other was miraculously the completed works of shakespeare.

Which hard drive would contain more energy? And which hard drive would contain more information?</data>
      <data key="d8">381</data>
      <data key="d9">6.1</data>
      <data key="d10">0.0</data>
      <data key="d11">4.7</data>
      <data key="d12">0.2573</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 2), (3, 1), (4, 2), (5, 2), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 2), (29, 1), (30, 2), (31, 1), (32, 2), (33, 1), (34, 2)]</data>
    </node>
    <node id="c196">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6c00vm</data>
      <data key="d3">e6c36ps</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">1</data>
      <data key="d6">1537500520.0</data>
      <data key="d7">&gt;you clearly have no knowledge on information theory or computing theory. This is evident because you aren't even grasping the basics.

That’s a circular argument. You should read a freshman philosophy book. They cover that basic stuff in the first chapter.
</data>
      <data key="d8">258</data>
      <data key="d9">5.385</data>
      <data key="d10">0.0</data>
      <data key="d11">7.7</data>
      <data key="d12">-0.0903</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]</data>
    </node>
    <node id="c197">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ad842</data>
      <data key="d3">e6avsaa</data>
      <data key="d4">sn0rrlax</data>
      <data key="d5">2</data>
      <data key="d6">1537449639.0</data>
      <data key="d7">Of course. Was simply replying to “mind blowing way of making CPUs” idea. Why all these salty downvotes?</data>
      <data key="d8">104</data>
      <data key="d9">4.2</data>
      <data key="d10">0.0</data>
      <data key="d11">3.3</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c198">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bsueu</data>
      <data key="d3">e6bwwj3</data>
      <data key="d4">Sukrim</data>
      <data key="d5">1</data>
      <data key="d6">1537495291.0</data>
      <data key="d7">&gt; exact match of behavior

Then it is impossible to simulate a physical machine exactly, due to the Heisenberg uncertainty principle. You can only simulate an abstraction (e.g. a "CPU" that never overheats because the simulation has no concept of temperature). Then it only depends on where you draw that abstraction and this line is arbitrary at best.

I'm not arguing that it is possible in the general case to simulate something faster than itself - it is possible to be faster in some constructed cases if the simulation is imperfect or it is impossible to simulate to begin with. In both cases the initial statement "A computer can simulate itself, but that simulation must always run slower than the computer." is wrong or at least imprecise.</data>
      <data key="d8">748</data>
      <data key="d9">7.432</data>
      <data key="d10">0.131</data>
      <data key="d11">11.5</data>
      <data key="d12">0.0079</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 5), (24, 3), (25, 1), (26, 4), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 1), (55, 1)]</data>
    </node>
    <node id="c199">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aximg</data>
      <data key="d3">e6axzs7</data>
      <data key="d4">Sukrim</data>
      <data key="d5">2</data>
      <data key="d6">1537453179.0</data>
      <data key="d7">Often an idealized or abstracted system is being simulated (I have yet to see a Gameboy VM stop because its batteries were out of juice or because the cartridge had a bad contact) and if you take it to the extreme as I said actual simulation might not even be possible, since in the most extreme case you'd need to simulate quantum effects of atoms in the physical hardware which are currently assumed to be the closest thing to actual randomness we have.</data>
      <data key="d8">455</data>
      <data key="d9">5.677</data>
      <data key="d10">0.0</data>
      <data key="d11">34.5</data>
      <data key="d12">-0.4404</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]</data>
    </node>
    <node id="c200">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6csq0k</data>
      <data key="d3">e6fdu1q</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">2</data>
      <data key="d6">1537632972.0</data>
      <data key="d7">Yes, it is clear now. Sorry for the misunderstanding, I just think maybe complexity needs an honorable mention to put the two in contrast, perhaps. Thanks for elaborating :-)</data>
      <data key="d8">174</data>
      <data key="d9">5.222</data>
      <data key="d10">0.0</data>
      <data key="d11">6.9</data>
      <data key="d12">0.3756</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]</data>
    </node>
    <node id="c201">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b37my</data>
      <data key="d3">e6b3pqy</data>
      <data key="d4">Alaskan_Thunder</data>
      <data key="d5">3</data>
      <data key="d6">1537464693.0</data>
      <data key="d7">Yes, a program that returns the state of a cpu will have a different runtime than a program that counts to 10^50. </data>
      <data key="d8">114</data>
      <data key="d9">4.944</data>
      <data key="d10">0.0</data>
      <data key="d11">8.3</data>
      <data key="d12">0.4019</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1)]</data>
    </node>
    <node id="c202">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6b2xss</data>
      <data key="d3">e6bdcb4</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">4</data>
      <data key="d6">1537478907.0</data>
      <data key="d7">This is undecidable though. Such an emulator would be an oracle, and is not possible.</data>
      <data key="d8">85</data>
      <data key="d9">5.231</data>
      <data key="d10">0.0</data>
      <data key="d11">7.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]</data>
    </node>
    <node id="c203">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahu6k</data>
      <data key="d3">e6aiksf</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">11</data>
      <data key="d6">1537435022.0</data>
      <data key="d7">You can abstract information and say it's transmissible on any medium, but at the end of the day, the information is still represented in the universe by one of those mechanisms - matter, gravity, electromagnetic waves, etc.

Information is not ephemera, it's not its own field, it's not abstractable from the universe itself - it's a property of the configuration of the universe. You can think of it as the inverse of entropy - the order or disorder of the universe. These are all part of the basic definition of information.

You *really* need to read that information theory book.</data>
      <data key="d8">584</data>
      <data key="d9">7.281</data>
      <data key="d10">0.0</data>
      <data key="d11">10.9</data>
      <data key="d12">-0.0726</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 4), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]</data>
    </node>
    <node id="c204">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6afy4p</data>
      <data key="d3">e6ag691</data>
      <data key="d4">revereddesecration</data>
      <data key="d5">10</data>
      <data key="d6">1537432683.0</data>
      <data key="d7">Let's talk about compression. The best compression maximises entropy, such that highly compressed data looks near indistinguishable from noise. Does perfectly compressed data cease to contain information?</data>
      <data key="d8">204</data>
      <data key="d9">7.25</data>
      <data key="d10">0.0</data>
      <data key="d11">9.2</data>
      <data key="d12">0.4246</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]</data>
    </node>
    <node id="c205">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6afy4p</data>
      <data key="d3">e6agnjx</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">4</data>
      <data key="d6">1537433151.0</data>
      <data key="d7">&gt; Which hard drive would contain more energy? And which hard drive would contain more information?

How much energy do you think you expended to flip those bits into the new configuration, and why are you discounting that from your model of information here? If you could spontaneously order the drive, you'd essentially be implementing [Maxwell's Demon](https://en.wikipedia.org/wiki/Maxwell%27s_demon).

Here's a book on the [introduction to information theory](https://web.stanford.edu/~montanar/RESEARCH/BOOK/partA.pdf). You might find it useful.</data>
      <data key="d8">550</data>
      <data key="d9">8.088</data>
      <data key="d10">0.0</data>
      <data key="d11">11.4</data>
      <data key="d12">0.1074</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 2), (3, 1), (4, 2), (5, 1), (6, 2), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]</data>
    </node>
    <node id="c206">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bwwj3</data>
      <data key="d3">e6c2gvu</data>
      <data key="d4">olliej</data>
      <data key="d5">1</data>
      <data key="d6">1537499927.0</data>
      <data key="d7">&gt; Then it is impossible to simulate a physical machine exactly, due to the Heisenberg uncertainty principle.

Heisenberg principle only applies to very small scale interactions, but yes an "exact" physical simulation of any process rapidly becomes impossible as you scale up the size (see passage at the end).

The statement "a computer can simulate itself, but that simulation must alway run slower than the computer" relates to a theoretical model of a computer system, which is essentially a set of state transitions. So to simulate a computer in a theoretical context just means to simulate the state transitions, so no worrying about physical effects.

Generally however the requirement (time/space) of your simulation increase the closer you get progressively more significant as you get ever closer to "perfect", so eventually if you get down to simulating the atomic interactions in your computer (because you're insane? :D ) and you'd need to worry about quantum interactions. At that point though you're pretty much simulating a quantum computer and there have been numerous papers showing that simulating a quantum computer *requires* a quantum computer. I think the logical result is that no non-quantum computer could ever *exactly* simulate itself (or any other machine).
</data>
      <data key="d8">1286</data>
      <data key="d9">8.957</data>
      <data key="d10">0.0824</data>
      <data key="d11">15.4</data>
      <data key="d12">-0.0664</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 2), (4, 1), (5, 3), (6, 1), (7, 5), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 3), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 7), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 4), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 2), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 4), (83, 1), (84, 1), (85, 1), (86, 1), (87, 3), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 2), (94, 2)]</data>
    </node>
    <node id="c207">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6axzs7</data>
      <data key="d3">e6azdhd</data>
      <data key="d4">khedoros</data>
      <data key="d5">1</data>
      <data key="d6">1537455599.0</data>
      <data key="d7">&gt; I have yet to see a Gameboy VM stop because its batteries were out of juice or because the cartridge had a bad contact

You've given me ideas for new features in my emulator ;-)

&gt; since in the most extreme case you'd need to simulate quantum effects of atoms in the physical hardware which are currently assumed to be the closest thing to actual randomness we have.

Sounds like it's fair to say that there are many definitions (starting at reasonable and going all the way to extreme) of "simulation" that would require the simulation to run slower than the host. And maybe that's the key shortcoming of the question: It doesn't sufficiently define its terms.</data>
      <data key="d8">663</data>
      <data key="d9">5.989</data>
      <data key="d10">0.0166</data>
      <data key="d11">17.0</data>
      <data key="d12">-0.035</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1)]</data>
    </node>
    <node id="c208">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fdu1q</data>
      <data key="d3">e6fnesa</data>
      <data key="d4">loamfarer</data>
      <data key="d5">1</data>
      <data key="d6">1537651531.0</data>
      <data key="d7">Sure, no problem :)</data>
      <data key="d8">19</data>
      <data key="d9">3.75</data>
      <data key="d10">0.0</data>
      <data key="d11">5.6</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1)]</data>
    </node>
    <node id="c209">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bdcb4</data>
      <data key="d3">e6bdmda</data>
      <data key="d4">pilotInPyjamas</data>
      <data key="d5">1</data>
      <data key="d6">1537479182.0</data>
      <data key="d7">For the general case, you're correct. For specific cases, you can definitely tell if a certain variable is required. Optimising compilers do this. I only provided a single example of a specific program that could be optimised by static analysis. Change that example to a turing machine and all bets are off.</data>
      <data key="d8">307</data>
      <data key="d9">5.533</data>
      <data key="d10">0.0</data>
      <data key="d11">8.5</data>
      <data key="d12">0.2779</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c210">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aiksf</data>
      <data key="d3">e6aj2e8</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-2</data>
      <data key="d6">1537435505.0</data>
      <data key="d7">If the bits were randomly flipped on two hardrives, such that 1 hardrive was noise and the other was miraculously the completed works of shakespeare.

Which hard drive would contain more energy? And which hard drive would contain more information?

</data>
      <data key="d8">249</data>
      <data key="d9">6.344</data>
      <data key="d10">0.0</data>
      <data key="d11">6.1</data>
      <data key="d12">0.0486</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 2), (17, 1), (18, 2), (19, 1), (20, 2), (21, 1), (22, 2)]</data>
    </node>
    <node id="c211">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ag691</data>
      <data key="d3">e6aglkv</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-3</data>
      <data key="d6">1537433098.0</data>
      <data key="d7">&gt;Does perfectly compressed data cease to contain information?

It depends if you define information as an objective quality or as a function of it's utility 
</data>
      <data key="d8">158</data>
      <data key="d9">5.609</data>
      <data key="d10">0.0</data>
      <data key="d11">10.5</data>
      <data key="d12">0.6369</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]</data>
    </node>
    <node id="c212">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6agnjx</data>
      <data key="d3">e6ah7yf</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">0</data>
      <data key="d6">1537433704.0</data>
      <data key="d7">&gt; How much energy do you think you expended to flip those bits into the new configuration, and why are you discounting that from your model of information here?

What makes you think I am doing that???? Both drives achieved their configuration by using the same energy </data>
      <data key="d8">269</data>
      <data key="d9">5.632</data>
      <data key="d10">0.0</data>
      <data key="d11">8.1</data>
      <data key="d12">0.1366</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]</data>
    </node>
    <node id="c213">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6c2gvu</data>
      <data key="d3">e6c3a2f</data>
      <data key="d4">Sukrim</data>
      <data key="d5">1</data>
      <data key="d6">1537500595.0</data>
      <data key="d7">&gt; simulating a quantum computer requires a quantum computer

Luckily: No. :-) It will just be insanely slow.

Here's an implementation that's already over a decade in development at http://www.libquantum.de/ for example.

&gt; So to simulate a computer in a theoretical context just means to simulate the state transitions, so no worrying about physical effects.

In that case you get back into "if a tree falls over in the wood and nobody hears it, does it make a sound?" territory. Meaning: If you are able to query your simulation at arbitrary points and you get the same state as on a "real" system returned, is the simulation already correct **or** do you actually first have to simulate all states up to this point as well - even if there would be a shortcut and the extra work is demonstrably pointless?

Imagine simulating a program that runs in a 100 instructions loop. it would be trivial to write a "simulator" that can tell you exactly how the system state after 10 billion loops would look like, how the previous (and the next) state would look like as well and also querying each other thinkable state could be done in near constant time. The real system however would take longer, the further out you want to query state (in O(n)).</data>
      <data key="d8">1243</data>
      <data key="d9">7.19</data>
      <data key="d10">0.0732</data>
      <data key="d11">10.5</data>
      <data key="d12">-0.0064</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 3), (1, 2), (2, 1), (3, 2), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 3), (24, 6), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 3), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 1), (67, 5), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 2), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1)]</data>
    </node>
    <node id="c214">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aj2e8</data>
      <data key="d3">e6ajnnd</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">6</data>
      <data key="d6">1537436079.0</data>
      <data key="d7">How long would I need to flip the bits of a hard drive to represent the works of Shakespeare? How much energy would it cost?

edit: What, are you afraid to answer my question? I answered yours.</data>
      <data key="d8">193</data>
      <data key="d15">5</data>
      <data key="d10">0.0</data>
      <data key="d11">2.2</data>
      <data key="d12">0.0426</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]</data>
    </node>
    <node id="c215">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ah7yf</data>
      <data key="d3">e6ahqto</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">5</data>
      <data key="d6">1537434213.0</data>
      <data key="d7">While this is theoretically possible, it's ridiculously, absurdly, not-worth-discussingly improbable. Given all bits on the drives are equally likely to be zeros or ones, to generate Shakespeare would be similar to shaking all of the grains of sand on a beach and them spontaneously building a sandcastle the size of Buckingham Palace. You'd expend more energy than the universe has to get the drive into that state.

I'd tell you to try it and come back, but you'd likely be dead before you completed even a single book of Shakespeare's sonnets.

Seriously, go read that book on information theory. It'll revolutionize your thinking.</data>
      <data key="d8">634</data>
      <data key="d9">6.475</data>
      <data key="d10">0.0</data>
      <data key="d11">10.0</data>
      <data key="d12">-0.1908</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1)]</data>
    </node>
    <node id="c216">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6c3a2f</data>
      <data key="d3">e6c4h0s</data>
      <data key="d4">olliej</data>
      <data key="d5">1</data>
      <data key="d6">1537501573.0</data>
      <data key="d7">&gt; Luckily: No. :-) It will just be insanely slow.

The problem is the simulating a quantum computer on a classical computer requires an exponential amount of state, it's not just a time complexity, but rather you very rapidly reach the point where it is not possible for a classical computer to simulate a plausible quantum computer due to constraints along the lines of "the size of the universe" :D

&gt; In that case you get back into "if a tree falls over in the wood and nobody hears it, does it make a sound?" territory.  ... even if there would be a shortcut and the extra work is demonstrably pointless?

But the extra work isn't demonstrably pointless as by definition you must be able to halt the simulation at any state to verify it is indeed the correct state. The obvious "fix" is to optimise and if paused rollback the state, but due to one way operations that will require storing prior states, which you would then have to re-execute the correct state transitions from.

And again, if your simulator is capable of running the code faster by performing transformations on them, then the host computer is *by definition* capable of performing the same transformations itself, and you get back to the host computer and the simulator running identical code. But again the simulator can at best only perform as fast as the host.

I suspect there's also something like "on average across all programs the average per-instruction cost inside the simulator is higher than on the host" in some paper somewhere.

Alternatively the whole "recursive simulation produces infinitely fast code execution" is considered sufficiently self explanatory to avoid the need for any further proof :D</data>
      <data key="d8">1689</data>
      <data key="d9">8.432</data>
      <data key="d10">0.1646</data>
      <data key="d11">15.5</data>
      <data key="d12">0.2237</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 6), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 2), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 2), (53, 2), (54, 1), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 2), (74, 2), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 2), (87, 1), (88, 1), (89, 2), (90, 1), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 2), (99, 1), (100, 4), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 2), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1)]</data>
    </node>
    <node id="c217">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ajnnd</data>
      <data key="d3">e6ak605</data>
      <data key="d4">DerSkagg</data>
      <data key="d5">3</data>
      <data key="d6">1537436580.0</data>
      <data key="d7">Not the op, but for clarity sake they are arguing from false pretenses.

Assume drive A and drive B are similar in all mechanical aspects. 

Let's then assume that both drives are being written at the same time, 1 bit takes some energy calculation from Landauer's Principle... and at the end of the writing. 

Drive A contains noise, Drive B contains Shakespeare. 

The problem that arises is their definition of information... 

Edit: and their lack of a definition of how the drives are being written.

Edit2: Probably a reference to Maxwell's demon.</data>
      <data key="d8">552</data>
      <data key="d9">6.567</data>
      <data key="d10">0.0</data>
      <data key="d11">6.6</data>
      <data key="d12">-0.0803</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 2), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]</data>
    </node>
    <node id="c218">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ajnnd</data>
      <data key="d3">e6al8hy</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-6</data>
      <data key="d6">1537437633.0</data>
      <data key="d7">&gt; How long would I need to flip the bits of a hard drive to represent the works of Shakespeare? How much energy would it cost?

&gt; edit: What, are you afraid to answer my question? I answered yours.

You've already contradicted yourself in [a previous comment](https://www.reddit.com/r/compsci/comments/9h8t0k/i_heard_a_professor_say_a_computer_can_simulate/e6akm9e/) but since you saw it fit to try to condescend me, I'm happy to return the favor. Besides, it seems like you could use some practice forming arguments. This will come in handy when you graduate. 

So, to answer your question, the time required and the energy expended is irrelevant as long as it's the same for both drives. If you find this answer unsatisfactory, feel free to call it 1 unit of time and energy required. </data>
      <data key="d8">787</data>
      <data key="d9">7.322</data>
      <data key="d10">0.0</data>
      <data key="d11">8.0</data>
      <data key="d12">0.1484</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 3), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 1), (62, 1)]</data>
    </node>
    <node id="c219">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ahqto</data>
      <data key="d3">e6aigkr</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">0</data>
      <data key="d6">1537434907.0</data>
      <data key="d7">&gt; not-worth-discussingly improbable

Well now, this is a surprisingly anti-intellectual statement from someone whose last remark is "go read a book".

You've come this far, why are you suddenly scared to answer a simple hypothetical question that cuts to the heart of the matter and elucidates *your understanding* of the nature of information and energy???

Tell me, *which hard drive would contain more energy and which hard drive would contain more information?*</data>
      <data key="d8">465</data>
      <data key="d9">7.231</data>
      <data key="d10">0.0323</data>
      <data key="d11">12.5</data>
      <data key="d12">0.0738</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 2), (38, 1), (39, 2), (40, 1), (41, 2), (42, 1), (43, 2)]</data>
    </node>
    <node id="c220">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6c4h0s</data>
      <data key="d3">e6c5yvw</data>
      <data key="d4">Sukrim</data>
      <data key="d5">1</data>
      <data key="d6">1537502800.0</data>
      <data key="d7">&gt; But the extra work isn't demonstrably pointless as by definition you must be able to halt the simulation at any state to verify it is indeed the correct state. The obvious "fix" is to optimise and if paused rollback the state, but due to one way operations that will require storing prior states, which you would then have to re-execute the correct state transitions from.

It would be a trivial operation to get any (deterministic) state in near constant time for an endless loop or any other program where you can reduce its state to a constant time algorithm instead of just its result (if you care about state instead of just results).

Since we're probably talking about something that's close to Turing machines (modulo infinite storage), the capabilities of the system are anyways not that much of a concern - the speed of the simulation is.

&gt; Alternatively the whole "recursive simulation produces infinitely fast code execution" is considered sufficiently self explanatory to avoid the need for any further proof :D

Having a simulated program run faster than the original doesn't mean that simulating this program in a simulated simulator would give the same benefits. If the initial implementation is just slow and a simulator speeds it up to its limits, it just means that the initial program for whatever reason was inefficient - not that the simulator would recursively do magic. You don't JIT compile JIT compiled code and expect it to be faster, you can however get faster code with a JIT compiler.</data>
      <data key="d8">1517</data>
      <data key="d9">7.942</data>
      <data key="d10">0.0428</data>
      <data key="d11">17.4</data>
      <data key="d12">0.1595</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 5), (23, 1), (24, 1), (25, 1), (26, 1), (27, 5), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 4), (35, 1), (36, 2), (37, 1), (38, 1), (39, 2), (40, 1), (41, 2), (42, 4), (43, 1), (44, 1), (45, 1), (46, 1), (47, 4), (48, 1), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 3), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 2), (112, 1), (113, 3), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1)]</data>
    </node>
    <node id="c221">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ak605</data>
      <data key="d3">e6alu3s</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">0</data>
      <data key="d6">1537438230.0</data>
      <data key="d7">&gt;they are arguing from false pretenses.

Exactly what do you mean by this?

&gt;The problem that arises is their definition of information...

I've not provided definition of information. 

&gt;Edit: and their lack of a definition of how the drives are being written. 

The exact method, time, and energy required are irrelevant so long as it is the same for both drives. </data>
      <data key="d8">366</data>
      <data key="d9">5.979</data>
      <data key="d10">0.0</data>
      <data key="d11">6.1</data>
      <data key="d12">-0.0894</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 3), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c222">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6al8hy</data>
      <data key="d3">e6am84h</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">2</data>
      <data key="d6">1537438626.0</data>
      <data key="d7">&gt; If you find this answer unsatisfactory, feel free to call it 1 unit of time and energy required. 

Please represent that unit in terms we can discuss scientifically. I'll accept any SI units you find appropriate. Until you come back to science, I can't have a rational discussion with you.</data>
      <data key="d8">291</data>
      <data key="d9">5.273</data>
      <data key="d10">0.0</data>
      <data key="d11">8.2</data>
      <data key="d12">0.3399</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]</data>
    </node>
    <node id="c223">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6aigkr</data>
      <data key="d3">e6ajfc6</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">5</data>
      <data key="d6">1537435855.0</data>
      <data key="d7">If you could do it, the drive with Shakespeare contains more information since it's in a more ordered state, but both drives contain exactly the same amount of energy. Just like my sandcastle experiment - the sandcastle is a higher state of order, so it contains more information...

Unfortunately, to get there, you've burned several universes of energy... so even answering your question is yielding to absurdity. You're asking me to answer a question that's couched on a bad assumption - that you can somehow spontaneously order a drive with Shakespeare through any given random process. I've spent *several comments* now trying to explain why.

That's *why* I'm telling you to read a book - so that you can understand why *the question you're asking* is broken. You are missing the foundation of the puzzle - that order in the universe *always decreases over time*, that scrambling matter *increases entropy over time*. Infinite monkeys typing yielding a monkey that makes Shakespeare is a fun thought experiment, but once you understand information theory, you understand why it's silly to rely on it - the heat death of the universe will catch up to you long before you get there.

I'm pretty much done responding to you. I decided to check your post history and I'm not surprised by what I found there, either... Arguing with someone that doesn't understand the fundamentals of the question that's being asked is like trying to argue with a brick wall - I'm not afraid of doing it, I just realize what an absolute waste of time it is.

Read the book. Get some understanding about how the universe works and why your question is absurd. Try to find some reason.</data>
      <data key="d8">1667</data>
      <data key="d9">8.434</data>
      <data key="d10">0.0</data>
      <data key="d11">9.4</data>
      <data key="d12">-0.1144</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 3), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 2), (16, 2), (17, 3), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 4), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 5), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 6), (51, 2), (52, 2), (53, 1), (54, 2), (55, 1), (56, 1), (57, 2), (58, 1), (59, 3), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 4), (98, 3), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 2), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 2), (137, 1), (138, 1)]</data>
    </node>
    <node id="c224">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6am84h</data>
      <data key="d3">e6amhq5</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-1</data>
      <data key="d6">1537438898.0</data>
      <data key="d7">&gt;I'll accept any SI units you find appropriate.

Each drive requires *exactly* 1 second and 1 joule to achieve it's configuration. 

Commence the rational discussion!

:)</data>
      <data key="d8">170</data>
      <data key="d9">5.4</data>
      <data key="d10">0.0</data>
      <data key="d11">7.7</data>
      <data key="d12">0.1273</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c225">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6ajfc6</data>
      <data key="d3">e6akm9e</data>
      <data key="d4">Anonymous</data>
      <data key="d5">0</data>
      <data key="d6">1537437027.0</data>
      <data key="d7">[removed]</data>
      <data key="d8">9</data>
      <data key="d15">7</data>
      <data key="d10">0.0</data>
      <data key="d11">8.4</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c226">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6akm9e</data>
      <data key="d3">e6amdbq</data>
      <data key="d4">hackingdreams</data>
      <data key="d5">4</data>
      <data key="d6">1537438773.0</data>
      <data key="d7">&gt; I understand if your too embarrassed to respond. Not only that, it's probably past your bedtime, no? 

And now you're reported for harassment. I've already taken you to school tonight. The fact you don't want to learn is not my problem anymore.

You're now blocked.</data>
      <data key="d8">267</data>
      <data key="d9">5.25</data>
      <data key="d10">0.0</data>
      <data key="d11">3.9</data>
      <data key="d12">-0.2024</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]</data>
    </node>
    <node id="c227">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6amdbq</data>
      <data key="d3">e6antff</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">-1</data>
      <data key="d6">1537440218.0</data>
      <data key="d7">&gt; And now you're reported for harassment. I've already taken you to school tonight. The fact you don't want to learn is not my problem anymore.
&gt; 
&gt; You're now blocked.

Well this is all rather childish of you! Especially since you saw it fit to try to condescend me at every chance. Perhaps in the future you'll show a little caution in telling *other people* they should read more :)</data>
      <data key="d8">385</data>
      <data key="d9">5.119</data>
      <data key="d10">0.0</data>
      <data key="d11">3.5</data>
      <data key="d12">-0.0192</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)]</data>
    </node>
    <node id="c228">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6antff</data>
      <data key="d3">e6c057b</data>
      <data key="d4">rhorama</data>
      <data key="d5">1</data>
      <data key="d6">1537498000.0</data>
      <data key="d7">Your comment got removed because it was rude. You've been nothing but an ignorant condescending asshole in this entire thread. Nobody wants to even engage with you to tell you why you're wrong because it'd be like trying to explain to someone covered in shit why they smell.

Sure you might be able to do it eventually but you'd actually have to get near them and talk to them. </data>
      <data key="d8">378</data>
      <data key="d9">5.63</data>
      <data key="d10">0.0</data>
      <data key="d11">7.7</data>
      <data key="d12">-0.1035</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1)]</data>
    </node>
    <node id="c229">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6c057b</data>
      <data key="d3">e6c2giu</data>
      <data key="d4">ebolanurse</data>
      <data key="d5">1</data>
      <data key="d6">1537499919.0</data>
      <data key="d7">&gt;You've been nothing but an ignorant condescending asshole in this entire thread. 

Excuse me? Show me where I was rude to someone who didn’t start off by telling me I needed to “read a book” since my questions were apparently so uninformed. 

&gt;Nobody wants to even engage with you to tell you why you're wrong because it'd be like trying to explain to someone covered in shit why they smell.

Just admit you don’t understand the topic enough to effectively engage my argument. Why are you playing this game where you whine about how I’m too dumb to understand your superior intellect. </data>
      <data key="d8">586</data>
      <data key="d9">5.607</data>
      <data key="d10">0.0</data>
      <data key="d11">8.9</data>
      <data key="d12">0.0694</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1)]</data>
    </node>
    <node id="c230">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hpwwe</data>
      <data key="d3">e6dplwj</data>
      <data key="d4">djimbob</data>
      <data key="d5">32</data>
      <data key="d6">1537569306.0</data>
      <data key="d7">Worth pointing out that graph isomorphism (are two graphs isomorphic -- can you relabel vertices of two graphs so they contain all the same connections) is distinct from subgraph isomorphism (does graph G1 contain a subgraph that is isomorphic to graph G2).  

We know subgraph isomorphism is NP-complete.  There hasn't been a well-accepted complete proof that graph isomorphism is in P or is NP-complete. (Graph-isomorphism is known to be in NP; given a valid mapping between isomorphic graphs you can show in polynomial time that they are isomorphic).  

Note if P != NP, there must be NP-intermediate problems (those that aren't P or NP-complete) and problems like integer factorization and graph isomorphism typically are listed as potential problems in the class.</data>
      <data key="d8">768</data>
      <data key="d9">8.761</data>
      <data key="d10">0.0</data>
      <data key="d11">11.0</data>
      <data key="d12">0.1241</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 5), (9, 3), (10, 3), (11, 5), (12, 1), (13, 1), (14, 1), (15, 3), (16, 5), (17, 2), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 3), (50, 1), (51, 1)]</data>
    </node>
    <node id="c231">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6dplwj</data>
      <data key="d3">e6dqrmg</data>
      <data key="d4">scorpio312</data>
      <data key="d5">7</data>
      <data key="d6">1537570311.0</data>
      <data key="d7">Is there known the status of Babai's claim of quasi-polynomial algorithm for graph isomorphism? Wikipedia says it is still under review - since January 2017: https://en.wikipedia.org/wiki/Graph_isomorphism_problem#State_of_the_art</data>
      <data key="d8">230</data>
      <data key="d9">8.417</data>
      <data key="d10">0.0</data>
      <data key="d11">12.9</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]</data>
    </node>
    <node id="c232">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hpwwe</data>
      <data key="d3">e6dy9bk</data>
      <data key="d4">m--w</data>
      <data key="d5">8</data>
      <data key="d6">1537576417.0</data>
      <data key="d7">That is not at all what is going on here. </data>
      <data key="d8">42</data>
      <data key="d9">3.444</data>
      <data key="d10">0.0</data>
      <data key="d11">2.5</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c233">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6dy9bk</data>
      <data key="d3">e6e6p6d</data>
      <data key="d4">daermonn</data>
      <data key="d5">5</data>
      <data key="d6">1537583314.0</data>
      <data key="d7">Can you elaborate please?</data>
      <data key="d8">25</data>
      <data key="d9">5.25</data>
      <data key="d10">0.0</data>
      <data key="d11">3.7</data>
      <data key="d12">0.3182</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1)]</data>
    </node>
    <node id="c234">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hpwwe</data>
      <data key="d3">e6fd9ub</data>
      <data key="d4">TKAAZ</data>
      <data key="d5">1</data>
      <data key="d6">1537631767.0</data>
      <data key="d7">Why is this so upvoted? The title is so misleading.</data>
      <data key="d8">51</data>
      <data key="d15">5</data>
      <data key="d10">0.0</data>
      <data key="d11">4.1</data>
      <data key="d12">-0.2705</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c235">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fd9ub</data>
      <data key="d3">e6fylf9</data>
      <data key="d4">exorxor</data>
      <data key="d5">0</data>
      <data key="d6">1537663140.0</data>
      <data key="d7">The answer is that Reddit is full of idiots. Allow me to help you to down vote it, but really we are outnumbered.</data>
      <data key="d8">113</data>
      <data key="d9">4.19</data>
      <data key="d10">0.0</data>
      <data key="d11">4.2</data>
      <data key="d12">0.1591</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c236">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6dqrmg</data>
      <data key="d3">e6e1mqx</data>
      <data key="d4">crystal__math</data>
      <data key="d5">7</data>
      <data key="d6">1537579160.0</data>
      <data key="d7">I'm fairly certain it's commonly accepted as correct (there was a minor error that was fixed a while ago), but he's taking his time revising it for publication. </data>
      <data key="d8">161</data>
      <data key="d9">4.962</data>
      <data key="d10">0.0</data>
      <data key="d11">14.2</data>
      <data key="d12">0.0644</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]</data>
    </node>
    <node id="c237">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6e6p6d</data>
      <data key="d3">e6ejp13</data>
      <data key="d4">twbmsp</data>
      <data key="d5">11</data>
      <data key="d6">1537594656.0</data>
      <data key="d7">I guess it is because the title, as often, is click-baity, there is no proof there, he doesn't "show" anything nor does he claims to. Although I would admit to find these comments addressing the bad title rather than the (IMHO) interesting  content almost equally annoying. Grumpy end-of-week me.

Edit: typos </data>
      <data key="d8">310</data>
      <data key="d9">5.833</data>
      <data key="d10">0.0161</data>
      <data key="d11">8.7</data>
      <data key="d12">-0.2135</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]</data>
    </node>
    <node id="c238">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i26ov</data>
      <data key="d3">e6gdqnp</data>
      <data key="d4">AsymptoticPerplexity</data>
      <data key="d5">3</data>
      <data key="d6">1537677911.0</data>
      <data key="d7">This is really interesting! It could be useful for extracting important features from an image before applying other processing. I imagine you could make an analogue of this for video where you highlight the regions of the video with the greatest information change over time.</data>
      <data key="d8">276</data>
      <data key="d9">6.189</data>
      <data key="d10">0.0</data>
      <data key="d11">9.1</data>
      <data key="d12">0.615</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1)]</data>
    </node>
    <node id="c239">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6gdqnp</data>
      <data key="d3">e6geeb9</data>
      <data key="d4">Feynmanfan85</data>
      <data key="d5">1</data>
      <data key="d6">1537678579.0</data>
      <data key="d7">Thanks! I was actually thinking the same thing re video.</data>
      <data key="d8">56</data>
      <data key="d9">4.5</data>
      <data key="d10">0.0</data>
      <data key="d11">4.8</data>
      <data key="d12">0.2463</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]</data>
    </node>
    <node id="c240">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i0awa</data>
      <data key="d3">e6fttls</data>
      <data key="d4">TomvdZ</data>
      <data key="d5">2</data>
      <data key="d6">1537658509.0</data>
      <data key="d7">There's no relation between CPU register size and the width of the address bus. They're completely orthogonal concepts. For example, many 8-bit processors can access more than 256 bytes of RAM.</data>
      <data key="d8">193</data>
      <data key="d9">5.267</data>
      <data key="d10">0.0</data>
      <data key="d11">6.1</data>
      <data key="d12">-0.0987</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]</data>
    </node>
    <node id="c241">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fttls</data>
      <data key="d3">e6gfuza</data>
      <data key="d4">manoj549t</data>
      <data key="d5">2</data>
      <data key="d6">1537680059.0</data>
      <data key="d7">I am a bit curios. How does your 8-bit processor reference more than 256 bytes of RAM? Don’t you need to store the address in a register to fetch its data?</data>
      <data key="d8">155</data>
      <data key="d9">3.903</data>
      <data key="d10">0.0</data>
      <data key="d11">3.8</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c242">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6gfuza</data>
      <data key="d3">e6glh5e</data>
      <data key="d4">everyonelovespenis</data>
      <data key="d5">3</data>
      <data key="d6">1537685846.0</data>
      <data key="d7">https://en.wikipedia.org/wiki/MOS_Technology_6502#Registers
</data>
      <data key="d8">60</data>
      <data key="d15">59</data>
      <data key="d10">0.0</data>
      <data key="d11">102.8</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1)]</data>
    </node>
    <node id="c243">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6glh5e</data>
      <data key="d3">e6glyka</data>
      <data key="d4">manoj549t</data>
      <data key="d5">1</data>
      <data key="d6">1537686351.0</data>
      <data key="d7">Ah, 16-bit program counter. Thanks for the link! 
I assumed it had a 8-bit PC.</data>
      <data key="d8">78</data>
      <data key="d9">3.562</data>
      <data key="d10">0.0</data>
      <data key="d11">-0.8</data>
      <data key="d12">0.1642</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]</data>
    </node>
    <node id="c244">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hu5v1</data>
      <data key="d3">e6hrap1</data>
      <data key="d4">IcebergLattice</data>
      <data key="d5">2</data>
      <data key="d6">1537745144.0</data>
      <data key="d7">You represent a relation R ⊂ S×T (with finite S and T) as a matrix M indexed by S and T, where M\_{s,t} = 1 if (s,t) ∈ R and 0 otherwise. I'm not sure how one would write an entire book about that.</data>
      <data key="d8">197</data>
      <data key="d9">3.784</data>
      <data key="d10">0.0</data>
      <data key="d11">8.1</data>
      <data key="d12">-0.1206</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]</data>
    </node>
    <node id="c245">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6hrap1</data>
      <data key="d3">e6hweh4</data>
      <data key="d4">dragontamer5788</data>
      <data key="d5">1</data>
      <data key="d6">1537749806.0</data>
      <data key="d7">Oh yeah, I'm not necessarily looking for a whole book on the subject. But a book that covers this format. Ideally, the book would be in the greater context of Constraint Programming... but it does seem like the 0-1 matrix form may be applicable to other subjects? I wouldn't be surprised if the 0-1 matrix came in handy during 3-SAT problems.

But optimal use of the 0-1 matrix form seems incredibly complicated, especially when you consider modern hardware capabilities. For example, I've noticed that the [PEXT](https://www.felixcloutier.com/x86/PEXT.html) and [PDEP](https://www.felixcloutier.com/x86/PDEP.html) instructions on the x86 Intel system can perform a "select" on a 64-bit bitmask in just 1 clock-tick on Intel Skylake systems (i7-8700k). !

I'd use the PEXT as a "parallel bitwise select" statement, and use that as the basis for other algorithms, such as "join". But I'm not quite sure if my algorithm is optimal.

Ex: if R1 and R2 are both 4-domain, 2-column relations (therefore 16-bits each, since they are a 4x4 0-1 bit matrix), then you can perform a join as follows:


    // NOT DEBUGGED!! FOR conceptual discussion purposes only!!

    // If x0, x1, x2,  are the variables in the relations by R1 and R2, assume
    // that R1 represents {x0, x1} and R2 represents {x0, x2}.
    // Output a int64_t 3-column relation with columns ordered {x0, x1, x2}.
    // In SQL, this join could be written as:
    // SELECT x0, x1, x2 FROM R1 JOIN R2 on R1.x0 == R2.x0

    int64_t joinCol0_with_Col0(int16_t R1, int16_t R2){
        // int4_t is for clarity. With 4-value domains, you only need 4-bits to store
        // the results of these selects on 2-columns. 
        // "selectCol0(R1, 0)" means "select x0 from R1 where x0 == R1.x0"
        // PEXT instruction easily works, but a "backup" solution needs to be made in case someone's processor
        // doesn't implement PEXT, since it is a relatively recent instruction added to x86.
        int4_t R1SelectResults[4] = {selectCol0(R1, 0), selectCol0(R1, 1), selectCol0(R1, 2), selectCol0(R1, 3)};
        int4_t R2SelectResults[4] = {selectCol0(R2, 0), selectCol0(R2, 1), selectCol0(R2, 2), selectCol0(R2, 3)};

        // Extend the 16-bit R1 {x0, x1} into the 64-bit R1Mask {x0, x1, x2}
        // Extend the 16-bit R2 {x0, x2} into the 64-bit R2Mask {x0, x1, x2}
        int64_t R2Mask = 0; 
        int64_t R1Mask = 0; 
        for(int i=0; i&lt;4; i++){
            // x2 is the least-significant variable in the ordering {x0, x1, x2}. Join is therefore
            // implemented with copy/pasting the {x0, x2} array.
            R2Mask |= R2SelectResults[i] &lt;&lt; (4*i);
            R2Mask |= R2SelectResults[i] &lt;&lt; (4*i+16);
            R2Mask |= R2SelectResults[i] &lt;&lt; (4*i+32);
            R2Mask |= R2SelectResults[i] &lt;&lt; (4*i+48);

            // x1 is in the middle of the output {x0, x1, x2}, so "smear" the results of R1.
            // R1 will have a "smear" step later, just prepare the holes for now
            // pext_smear_prepare turns a binary number such as 0101 (in hex: 0x5) into
            // the hex number 0x0101.
            // When combined with the smear, binary-0101 turns into 0x0F0F.
            int16_t submask = pext_smear_prepare(R1SelectResults[i]);
            submask  = submask | (submask &lt;&lt;2);
            submask  = submask | (submask &lt;&lt; 1); 
            R1Mask |= submask &lt;&lt; (i*16);
        }

        return R1Mask &amp; R2Mask;
    }

The implementation of selectCol0(int16_t 2-colRelation, 0) is as simple as:

    // int4_t is typedef int8_t, but 4-bit for clarity.
    int4_t selectCol0 (int16_t relation2column, int value){
        switch(value){
            case 0: return _pext_u64(relation2column, 0x000F);
            case 1: return _pext_u64(relation2column, 0x00F0); 
            case 2: return _pext_u64(relation2column, 0x0F00); 
            case 3: return _pext_u64(relation2column, 0xF000); 
        }
    }

[See here for a description of the _pext_u64](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=10,4073,4072&amp;text=pext) intrinsic. Column0 is the easy case where things can be done with purely an AND mask. But Column1 would be harder, and would need to be implemented _pext_u64(relation2column, 0x8888); instead, for the column1 and value=3 case.

I've simplified the problem down to the simplest case. But in the general case, where the number of columns grow... sorting issues come into hand. Ex, if R1 and R2 were 3-column relations instead over x0, x1, x2, x3, and x4... then the R1 {x0, x1, x4} and R2 {x0, x2, x3} case is a bit weird with regards to which columns to "smear" and which columns to copy/paste. In this case, the 5-column output is 1024-bits / 128 bytes, which is still seems efficient IMO (and would cover the worst-case scenario for Path-consistency in Constraint programming)

There are also the case of two-shared variables, such as R1 {x0, x1, x2} join R2{x0, x2, x3}, which turns into a 4-column relation (256-bits) instead (output of {x0, x1, x2, x3}). The x0 / x1 shared variables changes how smears and copy/pastes work in the above algorithm, but the concept seems sound to me.

There are other topics of note that are useful. For example, a great data-structure for this is the [lower triangle-matrix](https://en.wikipedia.org/wiki/Triangular_matrix). You need O(n^2/2) space to hold the 2-column case, and O(n^3/6) space to hold the complete 3-column case, where n is the number of variables. It seems to be the most efficient data-structure for small-n, small-domains, and small-columns (as is typical when going for Arc-consistency or Path-consistency).

&gt; I'm not sure how one would write an entire book about that.

It **seems** like the binary relation representation is very similar to the [Binary Decision Diagram](http://www.cs.utsa.edu/~wagner/knuth/fasc1b.pdf) representation. Which Knuth has written 153 pages on, and is quite comprehensive.

I really do think this 0-1 matrix representation is super-useful, especially now that the PEXT and PDEP instructions are widespread. The "obvious" application is the 4-coloring problem solved through constraint programming... but any other constraint-programming problem with small-domain sizes will surely use the 0-1 matrix representation. Especially because Arc-Consistency / Path-consistency hammers the 1-column and 2-column cases particularly hard.</data>
      <data key="d8">6390</data>
      <data key="d9">12.623</data>
      <data key="d10">0.0192</data>
      <data key="d11">16.3</data>
      <data key="d12">0.1199</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 4), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 5), (18, 1), (19, 4), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 6), (26, 5), (27, 1), (28, 5), (29, 1), (30, 1), (31, 1), (32, 1), (33, 3), (34, 2), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 2), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 1), (52, 1), (53, 2), (54, 4), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 3), (70, 2), (71, 1), (72, 1), (73, 3), (74, 1), (75, 1), (76, 1), (77, 1), (78, 3), (79, 1), (80, 3), (81, 2), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 2), (91, 2), (92, 3), (93, 14), (94, 3), (95, 1), (96, 4), (97, 4), (98, 1), (99, 3), (100, 6), (101, 1), (102, 1), (103, 2), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 2), (111, 1), (112, 1), (113, 1), (114, 1), (115, 2), (116, 1), (117, 5), (118, 3), (119, 1), (120, 1), (121, 1), (122, 2), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 4), (131, 1), (132, 8), (133, 1), (134, 2), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 2), (149, 1), (150, 3), (151, 1), (152, 1), (153, 3), (154, 1), (155, 2), (156, 2), (157, 4), (158, 6), (159, 6), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 2), (172, 1), (173, 4), (174, 1), (175, 1), (176, 1), (177, 3), (178, 1), (179, 2), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 2), (187, 1), (188, 1), (189, 2), (190, 1), (191, 4), (192, 1), (193, 3), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 6), (202, 2), (203, 1), (204, 1), (205, 1), (206, 5), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 5), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 2), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 2), (246, 1), (247, 4), (248, 1), (249, 1), (250, 1), (251, 1), (252, 2), (253, 1), (254, 1), (255, 1), (256, 2), (257, 1), (258, 1), (259, 3), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 4), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 2), (277, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 2), (298, 1), (299, 1), (300, 2), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 2), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 1), (321, 1), (322, 1), (323, 1), (324, 2), (325, 2), (326, 1), (327, 1), (328, 1), (329, 1), (330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (349, 1), (350, 1), (351, 1)]</data>
    </node>
    <node id="c246">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hyw1m</data>
      <data key="d3">e6fk1ei</data>
      <data key="d4">PetrosPapapa</data>
      <data key="d5">13</data>
      <data key="d6">1537646565.0</data>
      <data key="d7">My problem back in high school had more to do with motivation rather than the level of knowledge. As far as I know this is still the case, as even undergrads (in Reddit) keep asking for ideas for projects. 

Simply put, as much or as little as I would learn, I did not know what to do with it. I wanted to build something fun and meaningful that I could show off. There were 2 problems with that:

First, I was only ever given toy examples, and I could never extrapolate how any of it would be useful in "real" software. Give them better examples, solving actual problems! Give them better problems to work on, little games, or small fun apps they can actually use! This is why Logo used to be such a good language for learning, because you have an immediate practical reward.

Second, I was never taught enough to make anything useful. It was like some subjects (like pointers, or I/O, or simple interfaces) were taboo because "oh that is too advanced". There is always a huge gap between students who are natural and learn quickly and students who aren't and struggle. This leads teachers to underestimate how much the former can actually understand and learn. Myself and my other geeky friends learned to build Visual Basic interfaces, pixelated game graphics, even sounds and game mechanics all on our own. I remember reading tutorials on a PC magazine on how to do simple drawing and keyboard controller movement in BASIC. I learned so much from that alone!</data>
      <data key="d8">1462</data>
      <data key="d9">6.946</data>
      <data key="d10">0.0198</data>
      <data key="d11">7.7</data>
      <data key="d12">0.2461</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 2), (24, 2), (25, 2), (26, 1), (27, 2), (28, 1), (29, 3), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 3), (36, 1), (37, 1), (38, 2), (39, 1), (40, 2), (41, 1), (42, 1), (43, 2), (44, 1), (45, 2), (46, 1), (47, 2), (48, 1), (49, 2), (50, 2), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 2), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 2), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1)]</data>
    </node>
    <node id="c247">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fk1ei</data>
      <data key="d3">e6fnilx</data>
      <data key="d4">napalmlipbalm</data>
      <data key="d5">5</data>
      <data key="d6">1537651665.0</data>
      <data key="d7">I feel your pain! The projects teachers are given to teach from are dull as anything - I paid a fortune for new ones because we just don't have the time to put them together. I'm thinking skills combined with a program that can be added to as they go along would help to at least give a reason for the skills learned? We're not even told to teach UI programming and Python will only take them so far before they start losing the will to live. Students join the courses thinking they'll have a pretty GUI based system and they end up in bumbling through print statements and sadness. 

I hate that things are considered too advanced so we fly through them to make them go away again without adding them to the practical projects being developed. I need to work something out to make them seem less daunting because we have so many non-CS graduates currently teaching at A level. They don't stand a chance. 

I was lucky to grow up with logo and moved over to NXT robots pretty quickly. I pushed them at school but then they breakdown and getting funding to buy new tech was a nuisance. The software we needed to demonstrate was either expensive or not deemed as secure enough by the network techies. 

I started in visual basic. It at least gave me something to understand because I could see it happening. Until I developed a robotic simulator at undergrad, I don't think I'd ever combined all of the abstract skills I'd picked up.

Thanks for answering. You've definitely given me a couple of things to look at! </data>
      <data key="d8">1513</data>
      <data key="d9">6.966</data>
      <data key="d10">0.0</data>
      <data key="d11">6.5</data>
      <data key="d12">0.012</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 3), (8, 1), (9, 1), (10, 2), (11, 1), (12, 3), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 3), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 3), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 2), (47, 7), (48, 4), (49, 1), (50, 2), (51, 2), (52, 1), (53, 1), (54, 1), (55, 2), (56, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 2), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 1), (82, 1), (83, 2), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1)]</data>
    </node>
    <node id="c248">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hyw1m</data>
      <data key="d3">e6fivd7</data>
      <data key="d4">s0ft3ng</data>
      <data key="d5">6</data>
      <data key="d6">1537644452.0</data>
      <data key="d7">I didn't do computer science in high school, but just the self-taught programming stuff.

I actively chose *not* to do the offered ICT class because I was too advanced for it. I like the option that my first-year CS course took: teach functional programming.

It'd be brand-new to both "advanced" students and those who've never programmed before. It distills programming to it's core algorithmic parts, and shows *explicitly* concepts like state &amp; abstractions. I never really understood what people meant by "state" until my first function programming class, where it all clicked for me.

It's also very easy to test (QuickCheck has a super simple interface) and debug. When writing assignments, you can just specify the type, and let the student go wild.

I'd honestly stay away from object orientation, although it might be useful in their undergrad. In the real world, I avoid inheritance wherever I can, and use composition instead.</data>
      <data key="d8">938</data>
      <data key="d9">6.491</data>
      <data key="d10">0.016</data>
      <data key="d11">8.0</data>
      <data key="d12">0.2443</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 3), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1)]</data>
    </node>
    <node id="c249">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fivd7</data>
      <data key="d3">e6fn2wy</data>
      <data key="d4">napalmlipbalm</data>
      <data key="d5">3</data>
      <data key="d6">1537651107.0</data>
      <data key="d7">Thank you so much for this! I hadn't thought of functional programming being a good base skill but I can definitely see what you're saying. I still have a functional hangover from undergraduate level that I need to shake off. Even with a degree it was a subject I really hated teaching because I don't feel grounded enough in it. Goodness knows what teachers without compsci at degree level are thinking about it. It's definitely one thing understanding it and another teaching it. 

Unfortunately I'm constrained by the exam boards and they're pushing OOP. The issue being it's turning into one big pile of mush when students don't have the foundations in more complex areas in procedural languages. Everything just felt abstract to students; they know things but they don't understand why they know it or what it can be used for. State transitions taught through game design was my finest moment of teaching - I just need to find those links for the rest of our curriculum! </data>
      <data key="d8">976</data>
      <data key="d9">6.729</data>
      <data key="d10">0.0</data>
      <data key="d11">8.6</data>
      <data key="d12">0.0682</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 2), (11, 2), (12, 3), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 2), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 3), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 3), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 2), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 3), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1)]</data>
    </node>
    <node id="c250">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6fnilx</data>
      <data key="d3">e6fpwjr</data>
      <data key="d4">PetrosPapapa</data>
      <data key="d5">1</data>
      <data key="d6">1537654502.0</data>
      <data key="d7">I agree completely. I'm glad this was helpful. Getting teaching resources right is very hard, so good luck! </data>
      <data key="d8">108</data>
      <data key="d9">4.778</data>
      <data key="d10">0.0</data>
      <data key="d11">3.3</data>
      <data key="d12">0.6163</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c251">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9ij2vq</data>
      <data key="d3">e6k7qlr</data>
      <data key="d4">ACoderGirl</data>
      <data key="d5">1</data>
      <data key="d6">1537840621.0</data>
      <data key="d7">HTTP is pretty low level. Something like a callback arguably should and sometimes *does* take place at a higher level.

/u/dabombnl points out a good reason that this can't happen simply. To elaborate and use an example, WebRTC is a technology for real time communications in a peer to peer fashion. The nature of it requires that a peer can connect to your computer and that requires a predictable public IP.

NATs can make it such that a computer doesn't actually know its public IP (as the NAT transforms it). [STUN](https://en.wikipedia.org/wiki/STUN) is a technology that WebRTC uses to thus determine the public IP and *if it's usable* (some forms of NATs make it *impossible* to have true peer to peer communications). WebRTC does actually have a way around that, which is using "TURN" servers to act as middle men to relay the streams to (but then you need a high bandwidth server). If you're using a TURN server, you're basically just connecting to a regular public server (like any old website). [Here's an article that goes into more depth on the issues that WebRTC has due to NATs and how they are resolved](https://webrtchacks.com/an-intro-to-webrtcs-natfirewall-problem/).

At any rate, as I'm sure you can imagine, if you don't have a publicly predictable IP for the port that would receive your communications, what is the server going to connect to? Now, a callback as you describe would totally work fine between two computers not behind NATs, as is the case for publicly accessible servers. So you could have two servers communicate this way. But "regular users" are usually behind NATs and thus it doesn't make sense for the bulk of HTTP traffic. As the links show, there are ways to resolve this issue, but not for all possible NATs and it's so complicated.

As an aside, you can have push-like behavior via using things like long polling or websockets. Websockets requires that you make a connection, then just leave it open. Every now and then you send a tiny "keep alive" request so that it won't get automatically closed by the NAT. Long polling is similar except it's a "regular" request that just stays open for a long time. When the server has something to say, it immediately returns a response. If it never has anything to say, it sends a response that says "nothing happened" and then you make another long polling request to keep waiting for a real response (or to keep a connection for constant receiving of data).</data>
      <data key="d8">2447</data>
      <data key="d9">9.226</data>
      <data key="d10">0.0225</data>
      <data key="d11">9.9</data>
      <data key="d12">0.1097</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 2), (2, 1), (3, 1), (4, 2), (5, 1), (6, 2), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 1), (17, 2), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 5), (26, 1), (27, 2), (28, 4), (29, 2), (30, 1), (31, 3), (32, 1), (33, 2), (34, 12), (35, 3), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 5), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (60, 5), (61, 1), (62, 1), (63, 1), (64, 3), (65, 1), (66, 3), (67, 1), (68, 5), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 3), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 4), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 3), (90, 1), (91, 1), (92, 2), (93, 1), (94, 1), (95, 1), (96, 1), (97, 2), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 2), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 2), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 2), (156, 1), (157, 3), (158, 1), (159, 1), (160, 1), (161, 3), (162, 1), (163, 1), (164, 3), (165, 2), (166, 1), (167, 1), (168, 2), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1)]</data>
    </node>
    <node id="c252">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k7qlr</data>
      <data key="d3">e6k7r4i</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537840633.0</data>
      <data key="d7">**STUN**

Session Traversal Utilities for NAT (STUN) is a standardized set of methods, including a network protocol, for traversal of network address translator (NAT) gateways in applications of real-time voice, video, messaging, and other interactive communications.

STUN is a tool used by other protocols, such as Interactive Connectivity Establishment (ICE), the Session Initiation Protocol (SIP), or WebRTC. It provides a tool for hosts to discover the presence of a network address translator, and to discover the mapped, usually public, Internet Protocol (IP) address and port number that the NAT has allocated for the application's User Datagram Protocol (UDP) flows to remote hosts. The protocol requires assistance from a third-party network server (STUN server) located on the opposing (public) side of the NAT, usually the public Internet.

Originally, STUN was an acronym for Simple Traversal of User Datagram Protocol (UDP) through Network Address Translators, but this title was changed in a specification of an updated set of methods published as RFC 5389, retaining the same acronym.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1527</data>
      <data key="d9">10.965</data>
      <data key="d10">0.0</data>
      <data key="d11">16.9</data>
      <data key="d12">-0.0136</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 2), (4, 2), (5, 1), (6, 3), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 4), (38, 2), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1)]</data>
    </node>
    <node id="c253">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i6dl2</data>
      <data key="d3">e6h8nuw</data>
      <data key="d4">orangejake</data>
      <data key="d5">16</data>
      <data key="d6">1537714801.0</data>
      <data key="d7">It looks like they use a (forked) version of [MathQuill](https://github.com/mathquill/mathquill), so looking there is a good first step.</data>
      <data key="d8">136</data>
      <data key="d9">6.167</data>
      <data key="d10">0.0</data>
      <data key="d11">6.8</data>
      <data key="d12">0.3612</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]</data>
    </node>
    <node id="c254">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h8nuw</data>
      <data key="d3">e6hrp5e</data>
      <data key="d4">jpsky</data>
      <data key="d5">2</data>
      <data key="d6">1537745523.0</data>
      <data key="d7">Thanks! That's super helpful</data>
      <data key="d8">28</data>
      <data key="d15">6</data>
      <data key="d10">0.0</data>
      <data key="d11">3.7</data>
      <data key="d12">0.4926</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c255">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i6dl2</data>
      <data key="d3">e6h8o8i</data>
      <data key="d4">minno</data>
      <data key="d5">15</data>
      <data key="d6">1537714824.0</data>
      <data key="d7">That's fascinating. It looks like it's doing everything client-side, but the source code is minified so I can't make much sense of it. It's [here](https://www.desmos.com/assets/build/calculator_desktop-721a7d41e28db4feef812af859b17bd2a82ef541.js) if you want to take a look at it.

What it appears to be doing is setting an event handler on the text box that runs every time you type something in. When the handler recognizes a special input like "sqrt", "^" or "/", it changes the elements in the box by adding new HTML elements with the proper CSS to put things like the square root symbol, superscript text, or horizontal line in, along with new text boxes for things like the interior of the sqrt symbol and the numerator and denominator of the fraction.

For example, the expression (x+3)/2 looks like this:

      &lt;span class="dcg-mq-fraction dcg-mq-non-leaf" aria-hidden="true"&gt;
        &lt;span class="dcg-mq-numerator" aria-hidden="true"&gt;
          &lt;span class="dcg-mq-non-leaf" aria-hidden="true"&gt;
            &lt;span class="dcg-mq-scaled dcg-mq-paren" style="transform: scale(0.997621, 1.18573);"&gt;
              (
            &lt;/span&gt;
            &lt;span class="dcg-mq-non-leaf" aria-hidden="true"&gt;
              &lt;var aria-hidden="true" class=""&gt;
                x
              &lt;/var&gt;
              &lt;span aria-hidden="true" class=""&gt;
                &amp;nbsp;
              &lt;/span&gt;
              &lt;span aria-hidden="true" class="dcg-mq-binary-operator"&gt;
                +
              &lt;/span&gt;
              &lt;span aria-hidden="true" class=""&gt;
                &amp;nbsp;
              &lt;/span&gt;
              &lt;span aria-hidden="true" class=""&gt;
                3
              &lt;/span&gt;
            &lt;/span&gt;
            &lt;span class="dcg-mq-scaled dcg-mq-paren" style="transform: scale(0.997621, 1.18573);"&gt;
              )
            &lt;/span&gt;
          &lt;/span&gt;
        &lt;/span&gt;
        &lt;span class="dcg-mq-denominator" aria-hidden="true"&gt;
          &lt;span aria-hidden="true"&gt;
            2
          &lt;/span&gt;
        &lt;/span&gt;
        &lt;span style="display:inline-block;width:0"&gt;​
        &lt;/span&gt;
      &lt;/span&gt;

So when I typed "(x+3)/2" it created all of those elements in response. They all have CSS classes (and some inline styles) that dictate how they are arranged on the screen, along with those "aria" attributes that are meant to be used by screen readers to help people with vision problems navigate the site.</data>
      <data key="d8">2401</data>
      <data key="d9">10.708</data>
      <data key="d10">0.1504</data>
      <data key="d11">35.4</data>
      <data key="d12">0.3052</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 5), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 3), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 1), (55, 3), (56, 2), (57, 1), (58, 1), (59, 4), (60, 1), (61, 1), (62, 1), (63, 1), (64, 13), (65, 6), (66, 1), (67, 1), (68, 1), (69, 2), (70, 2), (71, 2), (72, 2), (73, 2), (74, 2), (75, 13), (76, 1), (77, 5), (78, 4), (79, 1), (80, 2), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 2), (109, 1), (110, 1), (111, 1), (112, 1)]</data>
    </node>
    <node id="c256">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h8o8i</data>
      <data key="d3">e6hre30</data>
      <data key="d4">jpsky</data>
      <data key="d5">1</data>
      <data key="d6">1537745235.0</data>
      <data key="d7">thanks for the response, it makes sense -- somebody else mentioned potential use of an event trigger like javascript's keyUp function, so maybe it's calling a renderer every time the user changes the input string by adding or deleting a character</data>
      <data key="d8">246</data>
      <data key="d9">5.459</data>
      <data key="d10">0.0</data>
      <data key="d11">16.5</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]</data>
    </node>
    <node id="c257">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h8o8i</data>
      <data key="d3">e6huc8o</data>
      <data key="d4">hendawg98</data>
      <data key="d5">1</data>
      <data key="d6">1537747946.0</data>
      <data key="d7">Can you not just un-minify code right in chrome console or just by googling and finding a site that does that?</data>
      <data key="d8">110</data>
      <data key="d9">4.684</data>
      <data key="d10">0.0</data>
      <data key="d11">6.8</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]</data>
    </node>
    <node id="c258">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i6dl2</data>
      <data key="d3">e6h7vt2</data>
      <data key="d4">pgn674</data>
      <data key="d5">8</data>
      <data key="d6">1537713262.0</data>
      <data key="d7">Well, this is actually kind of interesting. I typed in a test equation: [https://imgur.com/a/ZFQQFcc](https://imgur.com/a/ZFQQFcc)

And looking through the web page's source code, I found this:

    &lt;textarea aria-label="aria-label="Expression 1:  "y" equals StartRoot, "x" plus 3 , EndRoot minus left parenthesis, 2 plus StartFraction, 6 Over left parenthesis, 4 , right parenthesis , EndFraction , right parenthesis  Has graph. To audio trace, press ALT+T.""&gt;&lt;/textarea&gt;

Looks like that's for accessibility, so a screen reader can read it out loud. But that's all I've got. I imagine the scripts taking the input and creating the pretty equations are loaded by the page and run locally, but I don't know any web analysis and decomposer tools to go further.</data>
      <data key="d8">759</data>
      <data key="d9">6.362</data>
      <data key="d10">0.0224</data>
      <data key="d11">10.6</data>
      <data key="d12">0.1633</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 2), (30, 2), (31, 2), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1)]</data>
    </node>
    <node id="c259">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h7vt2</data>
      <data key="d3">e6h8ian</data>
      <data key="d4">umop_aplsdn</data>
      <data key="d5">5</data>
      <data key="d6">1537714491.0</data>
      <data key="d7">It's using some custom JavaScript and HTML divs to create the layout. I'm not sure if the code is proprietary or not. There might be some open source versions here: https://github.com/mathjax/MathJax-docs/wiki/List-of-web-based-math-editors

[MathQuill](http://mathquill.com/) on that page seems good, and it looks like its development is supported by desmos, so that might be what they're using.</data>
      <data key="d8">396</data>
      <data key="d9">7.217</data>
      <data key="d10">0.0</data>
      <data key="d11">8.6</data>
      <data key="d12">0.008</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1)]</data>
    </node>
    <node id="c260">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h7vt2</data>
      <data key="d3">e6h7vv3</data>
      <data key="d4">imguralbumbot</data>
      <data key="d5">0</data>
      <data key="d6">1537713265.0</data>
      <data key="d7">^(Hi, I'm a bot for linking direct images of albums with only 1 image)

**https://i.imgur.com/eXRK6YF.png**

^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e6h7vv3) </data>
      <data key="d8">533</data>
      <data key="d9">18.32</data>
      <data key="d10">0.0</data>
      <data key="d11">50.0</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]</data>
    </node>
    <node id="c261">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i6dl2</data>
      <data key="d3">e6h97jx</data>
      <data key="d4">straught</data>
      <data key="d5">4</data>
      <data key="d6">1537715907.0</data>
      <data key="d7">If I understand your question correctly, they probably do it with a [lexer](https://en.wikipedia.org/wiki/Lexical_analysis). Using regular expressions you can easily determine what the user means to type, and convert it to the appropriate symbols. For example, if you write 'sqrt' on desmos, it turns it into the square root symbol, right?

Well, with a lexer, you would need to consider 'sqrt' in your regular expression. Then your lexer would produce a token, which you would use to do anything you want, either construct an abstract syntax tree, or use it in a program.

If you really want to have an idea of how to do this, look into learning compilers, it will teach you all you need to know on this subject, and even more.

&amp;#x200B;

EDIT: Looking at some other responses, this is not the answer you might have been looking for, but I'm still gonna leave it here in case someone has a use for it.</data>
      <data key="d8">902</data>
      <data key="d9">6.769</data>
      <data key="d10">0.0</data>
      <data key="d11">9.7</data>
      <data key="d12">0.0956</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 3), (49, 1), (50, 1), (51, 2), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1)]</data>
    </node>
    <node id="c262">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6h97jx</data>
      <data key="d3">e6h97n9</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">1</data>
      <data key="d6">1537715913.0</data>
      <data key="d7">**Lexical analysis**

In computer science, lexical analysis, lexing or tokenization is the process of converting a sequence of characters (such as in a computer program or web page) into a sequence of tokens (strings with an assigned and thus identified meaning). A program that performs lexical analysis may be termed a lexer, tokenizer, or scanner, though scanner is also a term for the first stage of a lexer. A lexer is generally combined with a parser, which together analyze the syntax of programming languages, web pages, and so forth.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">969</data>
      <data key="d9">10.026</data>
      <data key="d10">0.0</data>
      <data key="d11">16.1</data>
      <data key="d12">-0.0251</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1)]</data>
    </node>
    <node id="c263">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6huc8o</data>
      <data key="d3">e6hz5go</data>
      <data key="d4">minno</data>
      <data key="d5">3</data>
      <data key="d6">1537752201.0</data>
      <data key="d7">You can undo the formatting changes, but there's no recovering the names, and it's much harder to navigate the code without them.</data>
      <data key="d8">129</data>
      <data key="d9">5.25</data>
      <data key="d10">0.0</data>
      <data key="d11">10.7</data>
      <data key="d12">-0.4215</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c264">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9il297</data>
      <data key="d3">e6khhnn</data>
      <data key="d4">wtallis</data>
      <data key="d5">2</data>
      <data key="d6">1537848527.0</data>
      <data key="d7">It depends on what you mean by buffers. If you're referring generally to memory spaces allocated for short-term storage, then there's not much room for alternatives. If you're referring to specific data structures, algorithms and access patterns, then there's almost always an alternative if you're creative enough. For example, Van Jacobson has recently proposed replacing FIFO packet queues in network drivers and NICs with [timing wheels](https://www.files.netdevconf.org/d/46def75c2ef345809bbe/files/?p=/Evolving%20from%20AFAP%20%E2%80%93%20Teaching%20NICs%20about%20time.pdf), but packets waiting to be sent still have to be stored somewhere that could reasonably be called a buffer. </data>
      <data key="d8">689</data>
      <data key="d9">8.096</data>
      <data key="d10">0.0</data>
      <data key="d11">12.3</data>
      <data key="d12">0.0881</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 3)]</data>
    </node>
    <node id="c265">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6khhnn</data>
      <data key="d3">e6kif4h</data>
      <data key="d4">mavavilj</data>
      <data key="d5">-1</data>
      <data key="d6">1537849266.0</data>
      <data key="d7">But there's also an interesting difference between electronic buffers and programming language constructs. While they might use different "topology", they may foundationally use the same kind of memory structures. Thus the concept of buffer is variable as well, perhaps? That is, it doesn't matter much whether the underlying structure is that which it is now, it still allows a lot of other constructs. Except for maybe something that's non-deterministic for example.</data>
      <data key="d8">468</data>
      <data key="d9">6.672</data>
      <data key="d10">0.0192</data>
      <data key="d11">10.0</data>
      <data key="d12">0.1312</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]</data>
    </node>
    <node id="c266">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6khhnn</data>
      <data key="d3">e6kik66</data>
      <data key="d4">mavavilj</data>
      <data key="d5">-1</data>
      <data key="d6">1537849383.0</data>
      <data key="d7">Then again in hardware design and manufacturing one ends up with a lot of other constraints, costs, materials, expertise... Thus the idea of using a common hardware base for multiple abstractions done in software is quite efficient I think.</data>
      <data key="d8">240</data>
      <data key="d9">5.5</data>
      <data key="d10">0.0</data>
      <data key="d11">10.9</data>
      <data key="d12">0.2377</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c267">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i7p4c</data>
      <data key="d3">e6hj2is</data>
      <data key="d4">ArthurTMurray</data>
      <data key="d5">-1</data>
      <data key="d6">1537735962.0</data>
      <data key="d7">Modern JavaScript also includes **[Artificial Intelligence](http://ai.neocities.org/FirstWorkingAGI.html)**.</data>
      <data key="d8">108</data>
      <data key="d9">13.429</data>
      <data key="d10">0.0</data>
      <data key="d11">28.1</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]</data>
    </node>
    <node id="c268">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6hj2is</data>
      <data key="d3">e6hvpub</data>
      <data key="d4">Neker</data>
      <data key="d5">1</data>
      <data key="d6">1537749183.0</data>
      <data key="d7">What is that ? Looks interesting. Is there an introduction somewhere ?</data>
      <data key="d8">70</data>
      <data key="d9">5.6</data>
      <data key="d10">0.0</data>
      <data key="d11">8.8</data>
      <data key="d12">0.134</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]</data>
    </node>
    <node id="c269">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hf9ch</data>
      <data key="d3">e6bfezm</data>
      <data key="d4">theblacklounge</data>
      <data key="d5">2</data>
      <data key="d6">1537480859.0</data>
      <data key="d7">You can't do that. You can use a topic models to check whether the content of the article still matches, but that's about it. You can't check whether they say the same thing. 

But this is not just an NLP task, it's heuristics. Fake news comes from similar sources, and uses similar language. It's also not spin, spin isn't fake and most fake news doesn't even try to spin. It's completely made up often, or based on old and unrelated articles. Look for keywords on the site, not just the article. Check the category titles. Check the site's ranking on Google, check the ranking of the links inside. Check the date of the sources. Check the ads on the news sites...</data>
      <data key="d8">665</data>
      <data key="d9">6.562</data>
      <data key="d10">0.0</data>
      <data key="d11">3.7</data>
      <data key="d12">0.0124</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 2), (3, 3), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 4), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 3), (43, 1), (44, 2), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)]</data>
    </node>
    <node id="c270">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bfezm</data>
      <data key="d3">e6bfl03</data>
      <data key="d4">GhostFoxGod</data>
      <data key="d5">1</data>
      <data key="d6">1537481011.0</data>
      <data key="d7">Ok so instead of matching whole article, is there any way to compare only title of the article? For example : 'Trump will support China' and 'China will get some help from Trump' so these two headings are same. So is there any way to check if they both are same?</data>
      <data key="d8">262</data>
      <data key="d9">5.486</data>
      <data key="d10">0.0</data>
      <data key="d11">6.3</data>
      <data key="d12">0.3186</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2)]</data>
    </node>
    <node id="c271">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hf9ch</data>
      <data key="d3">e6bz8in</data>
      <data key="d4">WhackAMoleE</data>
      <data key="d5">1</data>
      <data key="d6">1537497241.0</data>
      <data key="d7">Here's the classic case to test your design on.

During the run up to the Iraq war in 2002, the New York Times ran a series of articles by Judith Miller claiming that Saddam had yellowcake uranium and aluminum tubes to build WMDs. Turned out this was a neocon lie, 100% fake news to start a war. 

But hey, it's the New York Times, right? So your algorithm or method should be able to identify fake news not only in the National Enquirer, but in the "paper of record," the New York Times, which is the world's greatest purveyor of fake news. How many wars has the National Enquirer lied us into?</data>
      <data key="d8">595</data>
      <data key="d9">5.886</data>
      <data key="d10">0.0286</data>
      <data key="d11">7.0</data>
      <data key="d12">-0.3287</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 3), (17, 1), (18, 1), (19, 1), (20, 1), (21, 3), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1)]</data>
    </node>
    <node id="c272">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bz8in</data>
      <data key="d3">e6c2w4j</data>
      <data key="d4">theblacklounge</data>
      <data key="d5">2</data>
      <data key="d6">1537500277.0</data>
      <data key="d7">That was real news about lies. The reporting was sincere, without any real way to disprove it, and no real reason for more distrust than any other news coming from US intelligence at the time. Now, real news might not always be sincere, but fake news never is. </data>
      <data key="d8">261</data>
      <data key="d9">5.282</data>
      <data key="d10">0.0</data>
      <data key="d11">7.2</data>
      <data key="d12">-0.33</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 4), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1)]</data>
    </node>
    <node id="c273">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6bfl03</data>
      <data key="d3">e6bg0jp</data>
      <data key="d4">theblacklounge</data>
      <data key="d5">1</data>
      <data key="d6">1537481393.0</data>
      <data key="d7">I edited with more concrete ideas. 

Yes you can match those with a topic model. You can find pretrained ones, and libraries build around those. They will find similarity between "support" and "help". However, it would also just match "China will support Trump" and "Trump won't support China". Topic models can help you match topics, not messages. </data>
      <data key="d8">349</data>
      <data key="d9">6.659</data>
      <data key="d10">0.1834</data>
      <data key="d11">4.6</data>
      <data key="d12">0.2439</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 3), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1)]</data>
    </node>
    <node id="c274">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9hksvv</data>
      <data key="d3">e6gqw4t</data>
      <data key="d4">tulip_bro</data>
      <data key="d5">1</data>
      <data key="d6">1537691576.0</data>
      <data key="d7">Is operational semantics used in industry? I am in a compilers course where we are learning a _static_ semantic formalism: attribute grammars. My conjecture is we are learning it due to it's relative easy translation to an implementable algorithm.

I find it less elegant than the dynamic variant of operational semantics, but cannot seem to find many uses of it in compiler design.</data>
      <data key="d8">382</data>
      <data key="d9">6.521</data>
      <data key="d10">0.0</data>
      <data key="d11">10.6</data>
      <data key="d12">0.2107</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]</data>
    </node>
    <node id="c275">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6gqw4t</data>
      <data key="d3">e6jssh7</data>
      <data key="d4">east_lisp_junk</data>
      <data key="d5">1</data>
      <data key="d6">1537827973.0</data>
      <data key="d7">Languages that people actually use often aren't specified at that level of detail, and those that are don't seem to use that format. Someone might develop an operational semantics describing an existing language to enable formal analysis (e.g., developing LambdaJS to model an existing ECMAScript standard), but operational semantics as a specification technique doesn't seem to have become very widespread outside PL academia.

I have not heard of anyone using attribute grammars outside of the Dragon Book.</data>
      <data key="d8">508</data>
      <data key="d9">6.902</data>
      <data key="d10">0.0</data>
      <data key="d11">13.2</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 2), (28, 1), (29, 2), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 4), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]</data>
    </node>
    <node id="c276">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i7nib</data>
      <data key="d3">e6i6tqw</data>
      <data key="d4">Cocomorph</data>
      <data key="d5">3</data>
      <data key="d6">1537758211.0</data>
      <data key="d7">Learnability from positive examples has long been of interest to linguists (cf., e.g., https://en.wikipedia.org/wiki/Negative_evidence_in_language_acquisition for some context). Needless to say, linguistics and formal language theory have influenced each other (see, for example, Gold's theorem), but the perspectives (and respective literatures, for the most part) are different.  </data>
      <data key="d8">382</data>
      <data key="d9">7.548</data>
      <data key="d10">0.0</data>
      <data key="d11">14.0</data>
      <data key="d12">0.4456</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c277">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6i6tqw</data>
      <data key="d3">e6jcfvk</data>
      <data key="d4">TaXxER</data>
      <data key="d5">1</data>
      <data key="d6">1537801363.0</data>
      <data key="d7">Thanks! Yeah, very relevant indeed. Especially Gold's proof that not every arbitrary regular language can always be inferred from positive examples, while it is possible for certain subclasses of regular langauges, is very insightful. I doubt for example that people working on process mining are aware of this finding, even though it has quite serious implications for the field. I'll have some reading to do to get more familiar with this research field.</data>
      <data key="d8">456</data>
      <data key="d9">6.048</data>
      <data key="d10">0.0</data>
      <data key="d11">10.4</data>
      <data key="d12">0.2008</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 2), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1)]</data>
    </node>
    <node id="c278">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i7nib</data>
      <data key="d3">e6i8bad</data>
      <data key="d4">tangled_zans</data>
      <data key="d5">2</data>
      <data key="d6">1537759363.0</data>
      <data key="d7">There's a new trick for working with positive-only datasets that I've learned from Richard Evans: assume that all possible datapoints that are **not** in your example-data-set are **negative** examples. 

https://www.youtube.com/watch?v=yD02DlZnHJw</data>
      <data key="d8">248</data>
      <data key="d9">7.667</data>
      <data key="d10">0.0</data>
      <data key="d11">16.2</data>
      <data key="d12">-0.0516</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)]</data>
    </node>
    <node id="c279">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6i8bad</data>
      <data key="d3">e6jcijq</data>
      <data key="d4">TaXxER</data>
      <data key="d5">1</data>
      <data key="d6">1537801518.0</data>
      <data key="d7">Treating everything that is not observed as negative examples is not really a new trick, is it? I know that this perspective on the matter has been used since the 1950s by the Petri net synthesis guys.</data>
      <data key="d8">201</data>
      <data key="d9">5.226</data>
      <data key="d10">0.0</data>
      <data key="d11">8.1</data>
      <data key="d12">0.2725</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 1)]</data>
    </node>
    <node id="c280">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9i7nib</data>
      <data key="d3">e6idjv2</data>
      <data key="d4">PM_Me_Bayes_Theorem</data>
      <data key="d5">1</data>
      <data key="d6">1537763333.0</data>
      <data key="d7">Something like this?  
[http://karpathy.github.io/2015/05/21/rnn-effectiveness/](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)</data>
      <data key="d8">137</data>
      <data key="d9">31.75</data>
      <data key="d10">0.0</data>
      <data key="d11">50.9</data>
      <data key="d12">0.3612</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1)]</data>
    </node>
    <node id="c281">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6idjv2</data>
      <data key="d3">e6jcmvq</data>
      <data key="d4">TaXxER</data>
      <data key="d5">1</data>
      <data key="d6">1537801765.0</data>
      <data key="d7">You just mean RNNs? Or is there something specific that you are referring to? The article just seems to be about (character-level) RNNs. Yeah sure, those can be used. In my original post I even mentioned them as very first when listing the existing techniques that I am aware of.</data>
      <data key="d8">279</data>
      <data key="d9">5.045</data>
      <data key="d10">0.0</data>
      <data key="d11">4.8</data>
      <data key="d12">0.1721</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]</data>
    </node>
    <node id="c282">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6jcijq</data>
      <data key="d3">e6k6ico</data>
      <data key="d4">tangled_zans</data>
      <data key="d5">1</data>
      <data key="d6">1537839616.0</data>
      <data key="d7">I guess that's exactly as you've said, different subfields need more communication with each other. xD</data>
      <data key="d8">102</data>
      <data key="d9">5.312</data>
      <data key="d10">0.0</data>
      <data key="d11">10.7</data>
      <data key="d12">0.0</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]</data>
    </node>
    <node id="c283">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9ijf4o</data>
      <data key="d3">e6k3c4i</data>
      <data key="d4">ryani</data>
      <data key="d5">17</data>
      <data key="d6">1537837014.0</data>
      <data key="d7">The video glosses over this, but there are (surprisingly small) Turing Machines that are "Universal", in that they can be used to simulate any other Turing Machine by starting with an appropriate encoding of that machine on the memory tape.

What this allows is that you don't need to build a custom machine for every program -- you can build one machine and encode the program into its memory dynamically.

This has extremely far-reaching consequences, and forms the basis for how we know that certain values are *not* computable.  A fun example is the [Busy Beaver](https://en.wikipedia.org/wiki/Busy_beaver) function, which grows faster than any computable function.  Here are the first few values for a 2-symbol turing machine:

N | BB(N)
--: | --:
2 | 4
3 | 6
4 | 13
5 | &gt;= 4098
6 | &gt;= 3.5 x 10^18267
7 | &gt;= 10^10^10^10^18705353

Nobody has been able to find the value of even BB(5), and the value of BB(8000) [cannot be found by modern set theory](https://www.scottaaronson.com/blog/?p=2725) because an 8000-state turing machine can encode rules for generating every possible proof in ZFC.  The actual bound where it becomes unprovable is probably much lower, but it's amazing to me that there is such a simple problem that we know mathematics literally cannot solve.</data>
      <data key="d8">1273</data>
      <data key="d9">7.151</data>
      <data key="d10">0.0079</data>
      <data key="d11">11.9</data>
      <data key="d12">0.2764</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 4), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 7), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 2), (30, 2), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 2), (59, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1)]</data>
    </node>
    <node id="c284">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k3c4i</data>
      <data key="d3">e6kdgqa</data>
      <data key="d4">sturmhauke</data>
      <data key="d5">7</data>
      <data key="d6">1537845325.0</data>
      <data key="d7">This is all [Gödel's fault.](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems)</data>
      <data key="d8">98</data>
      <data key="d9">14.833</data>
      <data key="d10">0.0</data>
      <data key="d11">21.8</data>
      <data key="d12">-0.4019</data>
      <data key="d13">Negative</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1)]</data>
    </node>
    <node id="c285">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9ijf4o</data>
      <data key="d3">e6k23gz</data>
      <data key="d4">But_Mooooom</data>
      <data key="d5">6</data>
      <data key="d6">1537835996.0</data>
      <data key="d7">The elementary place to start for you seems like "logic gates". These are the building blocks for implementing "instruction sets" of a given processor.

Logisim is a common simulation software for introductions to these concepts via hand-on learning.


Sorry if I completely missed the premise of your question, but it seems to be the direction you're looking for...</data>
      <data key="d8">366</data>
      <data key="d9">6.082</data>
      <data key="d10">0.0792</data>
      <data key="d11">8.9</data>
      <data key="d12">-0.0226</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]</data>
    </node>
    <node id="c286">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k23gz</data>
      <data key="d3">e6k2nvo</data>
      <data key="d4">Gavcradd</data>
      <data key="d5">3</data>
      <data key="d6">1537836464.0</data>
      <data key="d7">Yes - the full adder I mentioned previously is built from logic gates. If you want to go even deeper, each logic gate is built from transistors (effectively an electronic switch). Computers are just banks of millions (billions) of switches at heart.</data>
      <data key="d8">249</data>
      <data key="d9">5.528</data>
      <data key="d10">0.0</data>
      <data key="d11">7.5</data>
      <data key="d12">0.1597</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]</data>
    </node>
    <node id="c287">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9ijf4o</data>
      <data key="d3">e6k2apw</data>
      <data key="d4">Gavcradd</data>
      <data key="d5">2</data>
      <data key="d6">1537836160.0</data>
      <data key="d7">The instructions are just that - instructions to perform an operation. The underlying hardware deals with actually performing those operations. So for example, adding two numbers up can be done using hardware called a full adder (or more accurately, a series of these). Look it up.  Multiplication can be done (somewhat) using shifts, where binary values are shuffled up a register. OTher more complex instructions will have their own hardware, or use combinations of existing hardware.

Have you had a look at the Little Man Computer? Google it, I use it with my Y10 students in the UK (14 year olds). It's a cut-down simulation of a processor in Von Neumann architecture. Each of the instructions in this would be a separate "chunk" of hardware.</data>
      <data key="d8">747</data>
      <data key="d9">6.784</data>
      <data key="d10">0.008</data>
      <data key="d11">8.1</data>
      <data key="d12">0.0402</data>
      <data key="d13">Neutral</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 2), (20, 1), (21, 4), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1)]</data>
    </node>
    <node id="c288">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k2apw</data>
      <data key="d3">e6k4gpg</data>
      <data key="d4">KDLGates</data>
      <data key="d5">2</data>
      <data key="d6">1537837945.0</data>
      <data key="d7">&gt; Little Man Computer

This is awesome. I didn't know this was a thing. :D Thanks for sharing.</data>
      <data key="d8">94</data>
      <data key="d9">4.235</data>
      <data key="d10">0.0</data>
      <data key="d11">3.2</data>
      <data key="d12">0.4386</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]</data>
    </node>
    <node id="c289">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6kdgqa</data>
      <data key="d3">e6kdh32</data>
      <data key="d4">WikiTextBot</data>
      <data key="d5">4</data>
      <data key="d6">1537845333.0</data>
      <data key="d7">**Gödel's incompleteness theorems**

Gödel's incompleteness theorems are two theorems of mathematical logic that demonstrate the inherent limitations of every formal axiomatic system capable of modelling basic arithmetic.  These results, published by Kurt Gödel in 1931, are important both in mathematical logic and in the philosophy of mathematics. The theorems are widely, but not universally, interpreted as showing that Hilbert's program to find a complete and consistent set of axioms for all mathematics is impossible.

The first incompleteness theorem states that no consistent system of axioms whose theorems can be listed by an effective procedure (i.e., an algorithm) is capable of proving all truths about the arithmetic of the natural numbers.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/compsci/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28</data>
      <data key="d8">1182</data>
      <data key="d9">10.703</data>
      <data key="d10">0.0</data>
      <data key="d11">16.9</data>
      <data key="d12">0.0584</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 3), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 2), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 3), (38, 4), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1)]</data>
    </node>
    <node id="c290">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e6k2nvo</data>
      <data key="d3">e6k423w</data>
      <data key="d4">KDLGates</data>
      <data key="d5">1</data>
      <data key="d6">1537837610.0</data>
      <data key="d7">There were a few hardware electives that were "expected" (not mandatory but a good idea) for Computer Engineering degrees at my University, like electrical systems (to study things like the physicality of transistors and how to read a DRAM memory diagram) and VLSI design.

Do these courses also normally factor into an Electrical Engineering degree program? Or do they not cover implementation of logic design beyond logic gates and symbolic design work like done in LogiSim / Logic Friday, reducing truth tables to KMaps and such?</data>
      <data key="d8">532</data>
      <data key="d9">6.29</data>
      <data key="d10">0.0169</data>
      <data key="d11">15.5</data>
      <data key="d12">0.4915</data>
      <data key="d13">Positive</data>
      <data key="d14">[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 3), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]</data>
    </node>
    <node id="ar291">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i0l65</data>
      <data key="d16">Help visualizing algorithms</data>
      <data key="d17">0</data>
      <data key="d6">1537630759.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.6</data>
    </node>
    <node id="c292" />
    <node id="c293" />
    <node id="c294" />
    <node id="c295" />
    <node id="c296" />
    <node id="c297" />
    <node id="c298" />
    <node id="ar299">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">97s8dl</data>
      <data key="d16">On natural selection of the laws of nature, Artificial life and Open-ended evolution, Universal Darwinism, Occam's razor</data>
      <data key="d17">0</data>
      <data key="d6">1534425736.0</data>
      <data key="d21">1537684626.0</data>
      <data key="d19">False</data>
      <data key="d20">0.79</data>
    </node>
    <node id="c300" />
    <node id="c301" />
    <node id="c302" />
    <node id="c303" />
    <node id="c304" />
    <node id="c305" />
    <node id="c306" />
    <node id="ar307">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hyvs3</data>
      <data key="d16">Fetching the readable text from a document</data>
      <data key="d17">0</data>
      <data key="d6">1537614217.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.59</data>
    </node>
    <node id="c308" />
    <node id="c309" />
    <node id="c310" />
    <node id="c311" />
    <node id="ar312">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9h8t0k</data>
      <data key="d16">I heard a professor say "A computer can simulate itself, but that simulation must always run slower than the computer." but what does that mean? Is this a law?</data>
      <data key="d17">0</data>
      <data key="d6">1537389288.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.87</data>
    </node>
    <node id="c313" />
    <node id="c314" />
    <node id="c315" />
    <node id="c316" />
    <node id="c317" />
    <node id="c318" />
    <node id="c319" />
    <node id="c320" />
    <node id="c321" />
    <node id="c322" />
    <node id="c323" />
    <node id="c324" />
    <node id="c325" />
    <node id="c326" />
    <node id="c327" />
    <node id="c328" />
    <node id="c329" />
    <node id="c330" />
    <node id="c331" />
    <node id="c332" />
    <node id="c333" />
    <node id="c334" />
    <node id="c335" />
    <node id="c336" />
    <node id="c337" />
    <node id="c338" />
    <node id="c339" />
    <node id="c340" />
    <node id="ar341">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hj8yu</data>
      <data key="d16">A Gift of Fire Fourth edition Sara Baase - ppt download</data>
      <data key="d17">0</data>
      <data key="d6">1537479411.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.25</data>
    </node>
    <node id="c342" />
    <node id="ar343">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hpwwe</data>
      <data key="d16">Jarek Duda shows polynomial algorithm handling hardest cases of graph isomorphism problem</data>
      <data key="d17">0</data>
      <data key="d6">1537536785.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.71</data>
    </node>
    <node id="c344" />
    <node id="ar345">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i26ov</data>
      <data key="d16">Using Information Theory to Identify Image Features</data>
      <data key="d17">0</data>
      <data key="d6">1537643181.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.72</data>
    </node>
    <node id="c346" />
    <node id="c347" />
    <node id="ar348">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9imazo</data>
      <data key="d16">Machine Learning -- Research Scientist vs Research Engineer?</data>
      <data key="d17">0</data>
      <data key="d6">1537826426.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">1.0</data>
    </node>
    <node id="c349" />
    <node id="ar350">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i0awa</data>
      <data key="d16">CPU Register Vs RAM . - 32bit vs 64bit</data>
      <data key="d17">0</data>
      <data key="d6">1537628457.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.5</data>
    </node>
    <node id="c351" />
    <node id="c352" />
    <node id="c353" />
    <node id="c354" />
    <node id="c355" />
    <node id="ar356">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hu5v1</data>
      <data key="d16">Any good books discussing the 0-1 matrix (aka: binary) representation of relations?</data>
      <data key="d17">0</data>
      <data key="d6">1537564885.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.67</data>
    </node>
    <node id="ar357">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hyw1m</data>
      <data key="d16">Briding gaps in programming resources</data>
      <data key="d17">0</data>
      <data key="d6">1537614301.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.81</data>
    </node>
    <node id="c358" />
    <node id="c359" />
    <node id="c360" />
    <node id="ar361">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9ij2vq</data>
      <data key="d16">Standard callback for HTTP?</data>
      <data key="d17">0</data>
      <data key="d6">1537804279.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.67</data>
    </node>
    <node id="c362" />
    <node id="ar363">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i6dl2</data>
      <data key="d16">How do sites like Desmos automatically convert text input into symbols?</data>
      <data key="d17">0</data>
      <data key="d6">1537683227.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.9</data>
    </node>
    <node id="c364" />
    <node id="c365" />
    <node id="ar366">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9il297</data>
      <data key="d16">Are buffers "fundamental constructs" or are there alternatives to buffers?</data>
      <data key="d17">0</data>
      <data key="d6">1537817691.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">1.0</data>
    </node>
    <node id="c367" />
    <node id="ar368">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i7p4c</data>
      <data key="d16">The Complete Guide to Modern JavaScript 2018</data>
      <data key="d17">0</data>
      <data key="d6">1537701893.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.17</data>
    </node>
    <node id="ar369">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i1eta</data>
      <data key="d16">Hi! Question about Computer generated Data Driven Models/ Time Series Models Research</data>
      <data key="d17">0</data>
      <data key="d6">1537637176.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.67</data>
    </node>
    <node id="c370" />
    <node id="c371" />
    <node id="ar372">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hf9ch</data>
      <data key="d16">How would you approach the problem of fake news detection in real time?</data>
      <data key="d17">0</data>
      <data key="d6">1537449793.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.3</data>
    </node>
    <node id="c373" />
    <node id="c374" />
    <node id="c375" />
    <node id="c376" />
    <node id="c377" />
    <node id="c378" />
    <node id="c379" />
    <node id="ar380">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9hksvv</data>
      <data key="d16">CompSci Weekend SuperThread (September 21, 2018)</data>
      <data key="d17">0</data>
      <data key="d6">1537491970.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.69</data>
    </node>
    <node id="ar381">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9i7nib</data>
      <data key="d16">Learning a language from positive examples</data>
      <data key="d17">0</data>
      <data key="d6">1537701278.0</data>
      <data key="d21">1537721276.0</data>
      <data key="d19">False</data>
      <data key="d20">0.87</data>
    </node>
    <node id="ar382">
      <data key="d0" />
      <data key="d1" />
      <data key="d3">9ijf4o</data>
      <data key="d16">Confused about on how instructions would be passed to Turing Machine</data>
      <data key="d17">0</data>
      <data key="d6">1537806615.0</data>
      <data key="d18">False</data>
      <data key="d19">False</data>
      <data key="d20">0.82</data>
    </node>
    <node id="c383" />
    <node id="c384" />
    <node id="c385" />
    <node id="c386" />
    <node id="c387" />
    <node id="c388" />
    <node id="c389" />
    <node id="Positive">
      <data key="d0">Positive</data>
      <data key="d1" />
    </node>
    <node id="Negative">
      <data key="d0">Negative</data>
      <data key="d1" />
    </node>
    <node id="Neutral">
      <data key="d0">Neutral</data>
      <data key="d1" />
    </node>
    <node id="-smiley--" />
    <node id="Jaxan0" />
    <node id="thbb" />
    <node id="eshyDerBerserk" />
    <node id="SteeleDynamics" />
    <node id="wellnhoferia" />
    <node id="future_security" />
    <node id="CelestialZippyZap" />
    <node id="bastywright" />
    <node id="sagaciux" />
    <node id="WeirdEidolon" />
    <node id="Rococoon" />
    <node id="pdxdabel" />
    <node id="UnderTruth" />
    <node id="noam_compsci" />
    <node id="Anonymous" />
    <node id="GayMakeAndModel" />
    <node id="Anonymous" />
    <node id="Meguli" />
    <node id="quiteamess" />
    <node id="zergling_Lester" />
    <node id="criticalcontext" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="SnowceanJay" />
    <node id="kiwi0fruit" />
    <node id="HelperBot_" />
    <node id="WikiTextBot" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="Anonymous" />
    <node id="Anonymous" />
    <node id="kiwi0fruit" />
    <node id="WikiTextBot" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="WikiTextBot" />
    <node id="kiwi0fruit" />
    <node id="sagaciux" />
    <node id="noam_compsci" />
    <node id="daermonn" />
    <node id="Anonymous" />
    <node id="WikiTextBot" />
    <node id="Anonymous" />
    <node id="Meguli" />
    <node id="sagaciux" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="sagaciux" />
    <node id="sagaciux" />
    <node id="daermonn" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="sagaciux" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="sagaciux" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="kiwi0fruit" />
    <node id="NowImAllSet" />
    <node id="stalefries" />
    <node id="rgb786684" />
    <node id="crimson117" />
    <node id="pudu0" />
    <node id="edeph" />
    <node id="webkenth" />
    <node id="GhostFoxGod" />
    <node id="ProgramTheWorld" />
    <node id="GhostFoxGod" />
    <node id="NowImAllSet" />
    <node id="crimson117" />
    <node id="WikiTextBot" />
    <node id="clownshoesrock" />
    <node id="TheMasterBaker01" />
    <node id="hypermog" />
    <node id="nanodano" />
    <node id="Dev__" />
    <node id="olliej" />
    <node id="p_pistol" />
    <node id="alvahrow" />
    <node id="Dustin-" />
    <node id="ralphredosoprano" />
    <node id="spacemoses" />
    <node id="Reddit1990" />
    <node id="SteeleDynamics" />
    <node id="almostinvisible" />
    <node id="macnlz" />
    <node id="wannagetbaked" />
    <node id="teawreckshero" />
    <node id="tsvk" />
    <node id="brett_riverboat" />
    <node id="agumonkey" />
    <node id="Laafheid" />
    <node id="superjimmyplus" />
    <node id="MjrK" />
    <node id="taratoni" />
    <node id="I_edit_comments_bad" />
    <node id="pandasashu" />
    <node id="ocean07" />
    <node id="Kulhu" />
    <node id="fourdebt" />
    <node id="generic12345689" />
    <node id="Causative" />
    <node id="roscoe_e_roscoe" />
    <node id="voneger" />
    <node id="znegva" />
    <node id="TheoreticalFunk" />
    <node id="djimbob" />
    <node id="Veedrac" />
    <node id="NowImAllSet" />
    <node id="CowboyFromSmell" />
    <node id="loamfarer" />
    <node id="t_bptm" />
    <node id="bloatedfrog" />
    <node id="bo0mb0om" />
    <node id="ThePeskyWabbit" />
    <node id="SuperGameTheory" />
    <node id="c3534l" />
    <node id="zck" />
    <node id="hnerixh" />
    <node id="wasimwesley" />
    <node id="CowboyFromSmell" />
    <node id="Sukrim" />
    <node id="mulletlaw" />
    <node id="agumonkey" />
    <node id="daviegravee" />
    <node id="sheikhy_jake" />
    <node id="MjrK" />
    <node id="singham" />
    <node id="ctchalk" />
    <node id="hackingdreams" />
    <node id="mistahspecs" />
    <node id="olliej" />
    <node id="znegva" />
    <node id="Putnam3145" />
    <node id="TKAAZ" />
    <node id="sheikhy_jake" />
    <node id="clownshoesrock" />
    <node id="SirClueless" />
    <node id="MjrK" />
    <node id="voidmechanic" />
    <node id="timshoaf" />
    <node id="knot_hk" />
    <node id="hackingdreams" />
    <node id="trex-eaterofcadrs" />
    <node id="Little_Milton" />
    <node id="olliej" />
    <node id="hackingdreams" />
    <node id="barsoap" />
    <node id="krimin_killr21" />
    <node id="olliej" />
    <node id="khedoros" />
    <node id="technocapital" />
    <node id="Dev__" />
    <node id="EldritchSundae" />
    <node id="Kaon_Particle" />
    <node id="Reddit1990" />
    <node id="WikiTextBot" />
    <node id="Oriumpor" />
    <node id="richardathome" />
    <node id="Oriumpor" />
    <node id="CowboyFromSmell" />
    <node id="loamfarer" />
    <node id="umpc" />
    <node id="pilotInPyjamas" />
    <node id="t_bptm" />
    <node id="stringParameter" />
    <node id="SuperGameTheory" />
    <node id="dancorbe" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="sn0rrlax" />
    <node id="Anonymous" />
    <node id="Sukrim" />
    <node id="Sukrim" />
    <node id="Sukrim" />
    <node id="MjrK" />
    <node id="ctchalk" />
    <node id="ctchalk" />
    <node id="hackingdreams" />
    <node id="mistahspecs" />
    <node id="p_pistol" />
    <node id="olliej" />
    <node id="TKAAZ" />
    <node id="Alaskan_Thunder" />
    <node id="sheikhy_jake" />
    <node id="TKAAZ" />
    <node id="voidmechanic" />
    <node id="timshoaf" />
    <node id="timshoaf" />
    <node id="nupogodi" />
    <node id="nemec" />
    <node id="hackingdreams" />
    <node id="revereddesecration" />
    <node id="rhorama" />
    <node id="_georgesim_" />
    <node id="Little_Milton" />
    <node id="WikiTextBot" />
    <node id="olliej" />
    <node id="khedoros" />
    <node id="singham" />
    <node id="Oriumpor" />
    <node id="Oriumpor" />
    <node id="loamfarer" />
    <node id="pilotInPyjamas" />
    <node id="singham" />
    <node id="pilotInPyjamas" />
    <node id="stringParameter" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="sn0rrlax" />
    <node id="Sukrim" />
    <node id="Sukrim" />
    <node id="TKAAZ" />
    <node id="Alaskan_Thunder" />
    <node id="TKAAZ" />
    <node id="hackingdreams" />
    <node id="revereddesecration" />
    <node id="hackingdreams" />
    <node id="olliej" />
    <node id="khedoros" />
    <node id="loamfarer" />
    <node id="pilotInPyjamas" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="Sukrim" />
    <node id="hackingdreams" />
    <node id="hackingdreams" />
    <node id="olliej" />
    <node id="DerSkagg" />
    <node id="ebolanurse" />
    <node id="ebolanurse" />
    <node id="Sukrim" />
    <node id="ebolanurse" />
    <node id="hackingdreams" />
    <node id="hackingdreams" />
    <node id="ebolanurse" />
    <node id="Anonymous" />
    <node id="hackingdreams" />
    <node id="ebolanurse" />
    <node id="rhorama" />
    <node id="ebolanurse" />
    <node id="noam_compsci" />
    <node id="djimbob" />
    <node id="m--w" />
    <node id="DrSweetscent" />
    <node id="TKAAZ" />
    <node id="scorpio312" />
    <node id="daermonn" />
    <node id="exorxor" />
    <node id="crystal__math" />
    <node id="twbmsp" />
    <node id="alkasm" />
    <node id="AsymptoticPerplexity" />
    <node id="TotesMessenger" />
    <node id="Feynmanfan85" />
    <node id="NotSureIfImMe" />
    <node id="szienze" />
    <node id="skeeto" />
    <node id="TomvdZ" />
    <node id="patsluth" />
    <node id="makeshiftquilt" />
    <node id="feedayeen" />
    <node id="manoj549t" />
    <node id="everyonelovespenis" />
    <node id="manoj549t" />
    <node id="IcebergLattice" />
    <node id="dragontamer5788" />
    <node id="PetrosPapapa" />
    <node id="s0ft3ng" />
    <node id="AManIsBusy" />
    <node id="turtle_13" />
    <node id="surface_book" />
    <node id="napalmlipbalm" />
    <node id="napalmlipbalm" />
    <node id="PetrosPapapa" />
    <node id="dabombnl" />
    <node id="ACoderGirl" />
    <node id="WikiTextBot" />
    <node id="orangejake" />
    <node id="minno" />
    <node id="pgn674" />
    <node id="straught" />
    <node id="Carpetfizz" />
    <node id="48151_62342" />
    <node id="jpsky" />
    <node id="jpsky" />
    <node id="hendawg98" />
    <node id="umop_aplsdn" />
    <node id="imguralbumbot" />
    <node id="WikiTextBot" />
    <node id="minno" />
    <node id="wtallis" />
    <node id="Jaxan0" />
    <node id="mavavilj" />
    <node id="mavavilj" />
    <node id="ArthurTMurray" />
    <node id="Neker" />
    <node id="covertfunction" />
    <node id="TaXxER" />
    <node id="eternusvia" />
    <node id="wakka54" />
    <node id="theblacklounge" />
    <node id="flexibeast" />
    <node id="almostinvisible" />
    <node id="bradcroteau" />
    <node id="Andy_Reds" />
    <node id="WhackAMoleE" />
    <node id="exorxor" />
    <node id="GhostFoxGod" />
    <node id="theblacklounge" />
    <node id="theblacklounge" />
    <node id="tulip_bro" />
    <node id="east_lisp_junk" />
    <node id="Cocomorph" />
    <node id="tangled_zans" />
    <node id="PM_Me_Bayes_Theorem" />
    <node id="TaXxER" />
    <node id="TaXxER" />
    <node id="TaXxER" />
    <node id="tangled_zans" />
    <node id="ryani" />
    <node id="But_Mooooom" />
    <node id="Gavcradd" />
    <node id="theblacklounge" />
    <node id="remy_porter" />
    <node id="KDLGates" />
    <node id="holden_nelson" />
    <node id="sturmhauke" />
    <node id="euzinkazoo" />
    <node id="jhp2000" />
    <node id="sturmhauke" />
    <node id="Gavcradd" />
    <node id="KDLGates" />
    <node id="WikiTextBot" />
    <node id="KDLGates" />
    <edge source="c0" target="c1">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c0" target="ar291">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c0" target="Positive">
      <data key="d23">0.4391</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c1" target="ar291">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c1" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c2" target="c3">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c2" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c2" target="Positive">
      <data key="d23">0.0535</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c3" target="c36">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c3" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c3" target="Positive">
      <data key="d23">0.0547</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c4" target="c5">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c4" target="c6">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c4" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c4" target="Positive">
      <data key="d23">0.5766</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c5" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c5" target="Positive">
      <data key="d23">0.0795</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c6" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c6" target="Neutral">
      <data key="d23">0.0468</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c7" target="c8">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c7" target="c9">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c7" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c7" target="Positive">
      <data key="d23">0.4731</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c8" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c8" target="Positive">
      <data key="d23">0.4997</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c9" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c9" target="Positive">
      <data key="d23">0.134</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c10" target="c11">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c10" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c10" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c11" target="c37">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c11" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c11" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c12" target="c13">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c12" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c12" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c13" target="c38">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c13" target="c39">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c13" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c13" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c14" target="c15">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c14" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c14" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c15" target="c40">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c15" target="c41">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c15" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c15" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c16" target="c17">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c16" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c16" target="Positive">
      <data key="d23">0.5719</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c17" target="c42">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c17" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c17" target="Positive">
      <data key="d23">0.4036</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c18" target="c19">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c18" target="c20">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c18" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c18" target="Positive">
      <data key="d23">0.2138</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c19" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c19" target="Neutral">
      <data key="d23">0.0397</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c20" target="c43">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c20" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c20" target="Positive">
      <data key="d23">0.2287</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c21" target="c22">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c23">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c24">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c25">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c26">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c27">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c28">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c29">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="c30">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c21" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c21" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c22" target="c44">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c22" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c22" target="Positive">
      <data key="d23">0.3502</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c23" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c23" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c24" target="c45">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c24" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c24" target="Positive">
      <data key="d23">0.2124</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c25" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c25" target="Positive">
      <data key="d23">0.289</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c26" target="c46">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c26" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c26" target="Negative">
      <data key="d23">-0.0918</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c27" target="c47">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c27" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c27" target="Neutral">
      <data key="d23">0.0474</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c28" target="c48">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c28" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c28" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c29" target="c49">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c29" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c29" target="Positive">
      <data key="d23">0.2107</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c30" target="c50">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c30" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c30" target="Neutral">
      <data key="d23">0.0412</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c31" target="c32">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c31" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c31" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c32" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c32" target="Positive">
      <data key="d23">0.2103</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c33" target="c34">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c33" target="c35">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c33" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c33" target="Positive">
      <data key="d23">0.0569</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c34" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c34" target="Negative">
      <data key="d23">-0.1641</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c35" target="c51">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c35" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c35" target="Positive">
      <data key="d23">0.2279</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c36" target="c52">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c36" target="c53">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c36" target="c54">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c36" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c36" target="Positive">
      <data key="d23">0.1436</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c37" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c37" target="Positive">
      <data key="d23">0.2463</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c38" target="c55">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c38" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c38" target="Positive">
      <data key="d23">0.2442</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c39" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c39" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c40" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c40" target="Negative">
      <data key="d23">-0.1545</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c41" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c41" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c42" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c42" target="Neutral">
      <data key="d23">0.0184</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c43" target="c56">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c43" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c43" target="Positive">
      <data key="d23">0.2419</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c44" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c44" target="Positive">
      <data key="d23">0.2803</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c45" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c45" target="Positive">
      <data key="d23">0.1557</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c46" target="c57">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c46" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c46" target="Positive">
      <data key="d23">0.2004</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c47" target="c58">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c47" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c47" target="Positive">
      <data key="d23">0.1272</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c48" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c48" target="Positive">
      <data key="d23">0.1668</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c49" target="c59">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c49" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c49" target="Positive">
      <data key="d23">0.4885</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c50" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c50" target="Negative">
      <data key="d23">-0.1369</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c51" target="c60">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c51" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c51" target="Neutral">
      <data key="d23">0.0365</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c52" target="c61">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c52" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c52" target="Positive">
      <data key="d23">0.3963</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c53" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c53" target="Positive">
      <data key="d23">0.052</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c54" target="c62">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c54" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c54" target="Positive">
      <data key="d23">0.1893</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c55" target="c63">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c55" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c55" target="Positive">
      <data key="d23">0.3535</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c56" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c56" target="Positive">
      <data key="d23">0.2302</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c57" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c57" target="Positive">
      <data key="d23">0.117</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c58" target="c64">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c58" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c58" target="Positive">
      <data key="d23">0.2154</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c59" target="c65">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c59" target="c66">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c59" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c59" target="Neutral">
      <data key="d23">0.0075</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c60" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c60" target="Positive">
      <data key="d23">0.3266</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c61" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c61" target="Negative">
      <data key="d23">-0.0825</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c62" target="c67">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c62" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c62" target="Negative">
      <data key="d23">-0.169</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c63" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c63" target="Positive">
      <data key="d23">0.7041</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c64" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c64" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c65" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c65" target="Negative">
      <data key="d23">-0.25</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c66" target="c68">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c66" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c66" target="Negative">
      <data key="d23">-0.0513</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c67" target="c69">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c67" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c67" target="Negative">
      <data key="d23">-0.075</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c68" target="c70">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c68" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c68" target="Neutral">
      <data key="d23">-0.008</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c69" target="c71">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c69" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c69" target="Positive">
      <data key="d23">0.081</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c70" target="c72">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c70" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c70" target="Positive">
      <data key="d23">0.0521</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c71" target="c73">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c71" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c71" target="Positive">
      <data key="d23">0.1626</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c72" target="c74">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c72" target="c75">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c72" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c72" target="Neutral">
      <data key="d23">-0.0118</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c73" target="c76">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c73" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c73" target="Negative">
      <data key="d23">-0.1618</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c74" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c74" target="Negative">
      <data key="d23">-0.0841</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c75" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c75" target="Negative">
      <data key="d23">-0.212</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c76" target="ar299">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c76" target="Positive">
      <data key="d23">0.2953</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c77" target="c78">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c77" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c77" target="Positive">
      <data key="d23">0.3147</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c78" target="c83">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c78" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c78" target="Positive">
      <data key="d23">0.3968</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c79" target="c80">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c79" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c79" target="Positive">
      <data key="d23">0.1699</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c80" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c80" target="Positive">
      <data key="d23">0.0911</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c81" target="c82">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c81" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c81" target="Negative">
      <data key="d23">-0.3612</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c82" target="c84">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c82" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c82" target="Negative">
      <data key="d23">-0.0674</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c83" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c83" target="Positive">
      <data key="d23">0.1096</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c84" target="c85">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c84" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c84" target="Neutral">
      <data key="d23">-0.0018</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c85" target="ar307">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c85" target="Neutral">
      <data key="d23">-0.0226</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c86" target="c87">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c88">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c89">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c90">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c91">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c92">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c93">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c94">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c95">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c96">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="c97">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c86" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c86" target="Neutral">
      <data key="d23">0.0475</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c87" target="c121">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c87" target="c122">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c87" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c87" target="Positive">
      <data key="d23">0.1794</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c88" target="c123">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c88" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c88" target="Positive">
      <data key="d23">0.4119</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c89" target="c124">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c89" target="c125">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c89" target="c126">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c89" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c89" target="Positive">
      <data key="d23">0.6908</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c90" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c90" target="Positive">
      <data key="d23">0.6686</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c91" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c91" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c92" target="c127">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c92" target="c128">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c92" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c92" target="Positive">
      <data key="d23">0.0694</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c93" target="c129">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c93" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c93" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c94" target="c130">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c94" target="c131">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c94" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c94" target="Positive">
      <data key="d23">0.1764</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c95" target="c132">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c95" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c95" target="Positive">
      <data key="d23">0.1277</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c96" target="c133">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c96" target="c134">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c96" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c96" target="Positive">
      <data key="d23">0.0906</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c97" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c97" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c98" target="c99">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c98" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c98" target="Positive">
      <data key="d23">0.1717</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c99" target="c135">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c99" target="c136">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c99" target="c137">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c99" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c99" target="Positive">
      <data key="d23">0.1806</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c100" target="c101">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c100" target="c102">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c100" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c100" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c101" target="c138">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c101" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c101" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c102" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c102" target="Positive">
      <data key="d23">0.4019</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c103" target="c104">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c103" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c103" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c104" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c104" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c105" target="c106">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c105" target="c107">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c105" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c105" target="Positive">
      <data key="d23">0.1137</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c106" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c106" target="Positive">
      <data key="d23">0.4201</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c107" target="c139">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c107" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c107" target="Negative">
      <data key="d23">-0.4576</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c108" target="c109">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c108" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c108" target="Positive">
      <data key="d23">0.2816</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c109" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c109" target="Positive">
      <data key="d23">0.144</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c110" target="c111">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c110" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c110" target="Positive">
      <data key="d23">0.3506</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c111" target="c140">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c111" target="c141">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c111" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c111" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c112" target="c113">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c112" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c112" target="Positive">
      <data key="d23">0.1699</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c113" target="c142">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c113" target="c143">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c113" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c113" target="Negative">
      <data key="d23">-0.2248</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c114" target="c115">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c114" target="c116">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c114" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c114" target="Negative">
      <data key="d23">-0.3412</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c115" target="c144">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c115" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c115" target="Neutral">
      <data key="d23">-0.0095</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c116" target="c145">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c116" target="c146">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c116" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c116" target="Negative">
      <data key="d23">-0.247</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c117" target="c118">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c117" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c117" target="Neutral">
      <data key="d23">0.018</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c118" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c118" target="Negative">
      <data key="d23">-0.2263</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c119" target="c120">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c119" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c119" target="Positive">
      <data key="d23">0.0709</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c120" target="c147">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c120" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c120" target="Positive">
      <data key="d23">0.1399</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c121" target="c148">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c121" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c121" target="Negative">
      <data key="d23">-0.1033</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c122" target="c149">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c122" target="c150">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c122" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c122" target="Neutral">
      <data key="d23">0.0399</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c123" target="c151">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c123" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c123" target="Positive">
      <data key="d23">0.3919</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c124" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c124" target="Positive">
      <data key="d23">0.0773</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c125" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c125" target="Negative">
      <data key="d23">-0.1396</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c126" target="c152">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c126" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c126" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c127" target="c153">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c127" target="c154">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c127" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c127" target="Positive">
      <data key="d23">0.067</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c128" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c128" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c129" target="c155">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c129" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c129" target="Positive">
      <data key="d23">0.2144</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c130" target="c156">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c130" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c130" target="Positive">
      <data key="d23">0.2732</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c131" target="c157">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c131" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c131" target="Positive">
      <data key="d23">0.1815</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c132" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c132" target="Positive">
      <data key="d23">0.2722</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c133" target="c158">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c133" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c133" target="Positive">
      <data key="d23">0.134</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c134" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c134" target="Positive">
      <data key="d23">0.2771</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c135" target="c159">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c135" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c135" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c136" target="c160">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c136" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c136" target="Positive">
      <data key="d23">0.4581</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c137" target="c161">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c137" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c137" target="Positive">
      <data key="d23">0.4586</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c138" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c138" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c139" target="c162">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c139" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c139" target="Positive">
      <data key="d23">0.5574</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c140" target="c163">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c140" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c140" target="Neutral">
      <data key="d23">0.0051</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c141" target="c164">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c141" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c141" target="Positive">
      <data key="d23">0.4404</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c142" target="c165">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c142" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c142" target="Positive">
      <data key="d23">0.0999</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c143" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c143" target="Negative">
      <data key="d23">-0.0929</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c144" target="c166">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c144" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c144" target="Positive">
      <data key="d23">0.1875</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c145" target="c167">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c145" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c145" target="Positive">
      <data key="d23">0.125</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c146" target="c168">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c146" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c146" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c147" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c147" target="Neutral">
      <data key="d23">-0.0388</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c148" target="c169">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c148" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c148" target="Positive">
      <data key="d23">0.0682</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c149" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c149" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c150" target="c170">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c150" target="c171">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c150" target="c172">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c150" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c150" target="Positive">
      <data key="d23">0.068</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c151" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c151" target="Positive">
      <data key="d23">0.128</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c152" target="c173">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c152" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c152" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c153" target="c174">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c153" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c153" target="Positive">
      <data key="d23">0.1739</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c154" target="c175">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c154" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c154" target="Negative">
      <data key="d23">-0.1531</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c155" target="c176">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c155" target="c177">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c155" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c155" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c156" target="c178">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c156" target="c179">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c156" target="c180">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c156" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c156" target="Negative">
      <data key="d23">-0.34</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c157" target="c181">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c157" target="c182">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c157" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c157" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c158" target="c183">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c158" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c158" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c159" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c159" target="Positive">
      <data key="d23">0.3042</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c160" target="c184">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c160" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c160" target="Positive">
      <data key="d23">0.2563</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c161" target="c185">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c161" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c161" target="Positive">
      <data key="d23">0.3182</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c162" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c162" target="Positive">
      <data key="d23">0.1626</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c163" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c163" target="Negative">
      <data key="d23">-0.0987</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c164" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c164" target="Negative">
      <data key="d23">-0.2455</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c165" target="c186">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c165" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c165" target="Positive">
      <data key="d23">0.2021</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c166" target="c187">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c166" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c166" target="Positive">
      <data key="d23">0.2561</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c167" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c167" target="Positive">
      <data key="d23">0.5442</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c168" target="c188">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c168" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c168" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c169" target="c189">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c169" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c169" target="Positive">
      <data key="d23">0.0658</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c170" target="c190">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c170" target="c191">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c170" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c170" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c171" target="c192">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c171" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c171" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c172" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c172" target="Negative">
      <data key="d23">-0.34</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c173" target="c193">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c173" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c173" target="Negative">
      <data key="d23">-0.052</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c174" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c174" target="Positive">
      <data key="d23">0.3986</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c175" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c175" target="Positive">
      <data key="d23">0.1197</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c176" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c176" target="Positive">
      <data key="d23">0.5382</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c177" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c177" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c178" target="c194">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c178" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c178" target="Positive">
      <data key="d23">0.1056</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c179" target="c195">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c179" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c179" target="Positive">
      <data key="d23">0.3954</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c180" target="c196">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c180" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c180" target="Positive">
      <data key="d23">0.0815</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c181" target="c197">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c181" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c181" target="Positive">
      <data key="d23">0.1646</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c182" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c182" target="Negative">
      <data key="d23">-0.4939</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c183" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c183" target="Positive">
      <data key="d23">0.051</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c184" target="c198">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c184" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c184" target="Neutral">
      <data key="d23">0.0486</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c185" target="c199">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c185" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c185" target="Positive">
      <data key="d23">0.0971</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c186" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c186" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c187" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c187" target="Positive">
      <data key="d23">0.1844</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c188" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c188" target="Positive">
      <data key="d23">0.3454</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c189" target="c200">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c189" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c189" target="Neutral">
      <data key="d23">0.0244</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c190" target="c201">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c190" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c190" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c191" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c191" target="Positive">
      <data key="d23">0.5499</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c192" target="c202">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c192" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c192" target="Positive">
      <data key="d23">0.139</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c193" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c193" target="Negative">
      <data key="d23">-0.1366</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c194" target="c203">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c194" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c194" target="Neutral">
      <data key="d23">0.0328</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c195" target="c204">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c195" target="c205">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c195" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c195" target="Positive">
      <data key="d23">0.2573</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c196" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c196" target="Negative">
      <data key="d23">-0.0903</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c197" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c197" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c198" target="c206">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c198" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c198" target="Neutral">
      <data key="d23">0.0079</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c199" target="c207">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c199" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c199" target="Negative">
      <data key="d23">-0.4404</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c200" target="c208">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c200" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c200" target="Positive">
      <data key="d23">0.3756</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c201" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c201" target="Positive">
      <data key="d23">0.4019</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c202" target="c209">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c202" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c202" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c203" target="c210">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c203" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c203" target="Negative">
      <data key="d23">-0.0726</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c204" target="c211">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c204" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c204" target="Positive">
      <data key="d23">0.4246</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c205" target="c212">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c205" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c205" target="Positive">
      <data key="d23">0.1074</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c206" target="c213">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c206" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c206" target="Negative">
      <data key="d23">-0.0664</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c207" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c207" target="Neutral">
      <data key="d23">-0.035</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c208" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c208" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c209" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c209" target="Positive">
      <data key="d23">0.2779</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c210" target="c214">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c210" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c210" target="Neutral">
      <data key="d23">0.0486</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c211" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c211" target="Positive">
      <data key="d23">0.6369</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c212" target="c215">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c212" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c212" target="Positive">
      <data key="d23">0.1366</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c213" target="c216">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c213" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c213" target="Neutral">
      <data key="d23">-0.0064</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c214" target="c217">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c214" target="c218">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c214" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c214" target="Neutral">
      <data key="d23">0.0426</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c215" target="c219">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c215" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c215" target="Negative">
      <data key="d23">-0.1908</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c216" target="c220">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c216" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c216" target="Positive">
      <data key="d23">0.2237</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c217" target="c221">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c217" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c217" target="Negative">
      <data key="d23">-0.0803</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c218" target="c222">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c218" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c218" target="Positive">
      <data key="d23">0.1484</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c219" target="c223">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c219" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c219" target="Positive">
      <data key="d23">0.0738</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c220" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c220" target="Positive">
      <data key="d23">0.1595</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c221" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c221" target="Negative">
      <data key="d23">-0.0894</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c222" target="c224">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c222" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c222" target="Positive">
      <data key="d23">0.3399</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c223" target="c225">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c223" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c223" target="Negative">
      <data key="d23">-0.1144</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c224" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c224" target="Positive">
      <data key="d23">0.1273</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c225" target="c226">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c225" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c225" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c226" target="c227">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c226" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c226" target="Negative">
      <data key="d23">-0.2024</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c227" target="c228">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c227" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c227" target="Neutral">
      <data key="d23">-0.0192</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c228" target="c229">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c228" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c228" target="Negative">
      <data key="d23">-0.1035</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c229" target="ar312">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c229" target="Positive">
      <data key="d23">0.0694</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c230" target="c231">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c230" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c230" target="Positive">
      <data key="d23">0.1241</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c231" target="c236">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c231" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c231" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c232" target="c233">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c232" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c232" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c233" target="c237">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c233" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c233" target="Positive">
      <data key="d23">0.3182</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c234" target="c235">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c234" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c234" target="Negative">
      <data key="d23">-0.2705</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c235" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c235" target="Positive">
      <data key="d23">0.1591</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c236" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c236" target="Positive">
      <data key="d23">0.0644</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c237" target="ar343">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c237" target="Negative">
      <data key="d23">-0.2135</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c238" target="c239">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c238" target="ar345">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c238" target="Positive">
      <data key="d23">0.615</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c239" target="ar345">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c239" target="Positive">
      <data key="d23">0.2463</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c240" target="c241">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c240" target="ar350">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c240" target="Negative">
      <data key="d23">-0.0987</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c241" target="c242">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c241" target="ar350">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c241" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c242" target="c243">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c242" target="ar350">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c242" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c243" target="ar350">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c243" target="Positive">
      <data key="d23">0.1642</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c244" target="c245">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c244" target="ar356">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c244" target="Negative">
      <data key="d23">-0.1206</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c245" target="ar356">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c245" target="Positive">
      <data key="d23">0.1199</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c246" target="c247">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c246" target="ar357">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c246" target="Positive">
      <data key="d23">0.2461</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c247" target="c250">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c247" target="ar357">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c247" target="Neutral">
      <data key="d23">0.012</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c248" target="c249">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c248" target="ar357">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c248" target="Positive">
      <data key="d23">0.2443</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c249" target="ar357">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c249" target="Positive">
      <data key="d23">0.0682</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c250" target="ar357">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c250" target="Positive">
      <data key="d23">0.6163</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c251" target="c252">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c251" target="ar361">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c251" target="Positive">
      <data key="d23">0.1097</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c252" target="ar361">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c252" target="Neutral">
      <data key="d23">-0.0136</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c253" target="c254">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c253" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c253" target="Positive">
      <data key="d23">0.3612</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c254" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c254" target="Positive">
      <data key="d23">0.4926</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c255" target="c256">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c255" target="c257">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c255" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c255" target="Positive">
      <data key="d23">0.3052</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c256" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c256" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c257" target="c263">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c257" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c257" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c258" target="c259">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c258" target="c260">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c258" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c258" target="Positive">
      <data key="d23">0.1633</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c259" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c259" target="Neutral">
      <data key="d23">0.008</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c260" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c260" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c261" target="c262">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c261" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c261" target="Positive">
      <data key="d23">0.0956</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c262" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c262" target="Neutral">
      <data key="d23">-0.0251</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c263" target="ar363">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c263" target="Negative">
      <data key="d23">-0.4215</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c264" target="c265">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c264" target="c266">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c264" target="ar366">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c264" target="Positive">
      <data key="d23">0.0881</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c265" target="ar366">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c265" target="Positive">
      <data key="d23">0.1312</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c266" target="ar366">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c266" target="Positive">
      <data key="d23">0.2377</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c267" target="c268">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c267" target="ar368">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c267" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c268" target="ar368">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c268" target="Positive">
      <data key="d23">0.134</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c269" target="c270">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c269" target="ar372">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c269" target="Neutral">
      <data key="d23">0.0124</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c270" target="c273">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c270" target="ar372">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c270" target="Positive">
      <data key="d23">0.3186</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c271" target="c272">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c271" target="ar372">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c271" target="Negative">
      <data key="d23">-0.3287</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c272" target="ar372">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c272" target="Negative">
      <data key="d23">-0.33</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c273" target="ar372">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c273" target="Positive">
      <data key="d23">0.2439</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c274" target="c275">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c274" target="ar380">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c274" target="Positive">
      <data key="d23">0.2107</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c275" target="ar380">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c275" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c276" target="c277">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c276" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c276" target="Positive">
      <data key="d23">0.4456</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c277" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c277" target="Positive">
      <data key="d23">0.2008</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c278" target="c279">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c278" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c278" target="Negative">
      <data key="d23">-0.0516</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c279" target="c282">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c279" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c279" target="Positive">
      <data key="d23">0.2725</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c280" target="c281">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c280" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c280" target="Positive">
      <data key="d23">0.3612</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c281" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c281" target="Positive">
      <data key="d23">0.1721</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c282" target="ar381">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c282" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c283" target="c284">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c283" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c283" target="Positive">
      <data key="d23">0.2764</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c284" target="c289">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c284" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c284" target="Negative">
      <data key="d23">-0.4019</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c285" target="c286">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c285" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c285" target="Neutral">
      <data key="d23">-0.0226</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c286" target="c290">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c286" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c286" target="Positive">
      <data key="d23">0.1597</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c287" target="c288">
      <data key="d22">parent-child</data>
    </edge>
    <edge source="c287" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c287" target="Neutral">
      <data key="d23">0.0402</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c288" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c288" target="Positive">
      <data key="d23">0.4386</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c289" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c289" target="Positive">
      <data key="d23">0.0584</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c290" target="ar382">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c290" target="Positive">
      <data key="d23">0.4915</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar291" target="c292">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c293">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c294">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c295">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c296">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c297">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar291" target="c298">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c292" target="Positive">
      <data key="d23">0.1098</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c293" target="Positive">
      <data key="d23">0.2906</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c294" target="Positive">
      <data key="d23">0.8074</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c295" target="Positive">
      <data key="d23">0.3025</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c296" target="Negative">
      <data key="d23">-0.1459</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c297" target="Positive">
      <data key="d23">0.0702</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c298" target="Positive">
      <data key="d23">0.6808</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar299" target="c300">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c301">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c302">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c303">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c304">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c305">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar299" target="c306">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c300" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c301" target="Positive">
      <data key="d23">0.3612</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c302" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c303" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c304" target="Positive">
      <data key="d23">0.4286</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c305" target="Positive">
      <data key="d23">0.2787</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c306" target="Neutral">
      <data key="d23">0.0394</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar307" target="c308">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar307" target="c309">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar307" target="c310">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar307" target="c311">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c308" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c309" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c310" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c311" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar312" target="c313">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c314">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c315">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c316">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c317">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c318">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c319">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c320">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c321">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c322">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c323">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c324">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c325">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c326">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c327">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c328">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c329">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c330">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c331">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c332">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c333">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c334">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c335">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c336">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c337">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c338">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c339">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar312" target="c340">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c313" target="Neutral">
      <data key="d23">0.0377</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c314" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c315" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c316" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c317" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c318" target="Positive">
      <data key="d23">0.1591</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c319" target="Positive">
      <data key="d23">0.2139</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c320" target="Positive">
      <data key="d23">0.6124</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c321" target="Negative">
      <data key="d23">-0.09</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c322" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c323" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c324" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c325" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c326" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c327" target="Positive">
      <data key="d23">0.0881</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c328" target="Positive">
      <data key="d23">0.4215</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c329" target="Positive">
      <data key="d23">0.2202</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c330" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c331" target="Negative">
      <data key="d23">-0.4391</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c332" target="Neutral">
      <data key="d23">0.0455</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c333" target="Negative">
      <data key="d23">-0.1274</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c334" target="Positive">
      <data key="d23">0.1063</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c335" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c336" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c337" target="Negative">
      <data key="d23">-0.1746</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c338" target="Neutral">
      <data key="d23">-0.0253</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c339" target="Neutral">
      <data key="d23">-0.0011</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c340" target="Positive">
      <data key="d23">0.142</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar341" target="c342">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c342" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar343" target="c344">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c344" target="Negative">
      <data key="d23">-0.296</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar345" target="c346">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar345" target="c347">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c346" target="Positive">
      <data key="d23">0.4404</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c347" target="Positive">
      <data key="d23">0.1649</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar348" target="c349">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c349" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar350" target="c351">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar350" target="c352">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar350" target="c353">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar350" target="c354">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar350" target="c355">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c351" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c352" target="Neutral">
      <data key="d23">-0.0465</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c353" target="Neutral">
      <data key="d23">0.0257</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c354" target="Positive">
      <data key="d23">0.0648</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c355" target="Positive">
      <data key="d23">0.0843</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar357" target="c358">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar357" target="c359">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar357" target="c360">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c358" target="Neutral">
      <data key="d23">0.0391</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c359" target="Positive">
      <data key="d23">0.3094</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c360" target="Positive">
      <data key="d23">0.7269</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar361" target="c362">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c362" target="Negative">
      <data key="d23">-0.0874</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar363" target="c364">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar363" target="c365">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c364" target="Positive">
      <data key="d23">0.3612</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c365" target="Positive">
      <data key="d23">0.3818</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar366" target="c367">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c367" target="Negative">
      <data key="d23">-0.3255</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar369" target="c370">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar369" target="c371">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c370" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c371" target="Positive">
      <data key="d23">0.2123</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar372" target="c373">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c374">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c375">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c376">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c377">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c378">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar372" target="c379">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c373" target="Negative">
      <data key="d23">-0.128</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c374" target="Negative">
      <data key="d23">-0.1337</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c375" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c376" target="Negative">
      <data key="d23">-0.0953</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c377" target="Positive">
      <data key="d23">0.3224</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c378" target="Positive">
      <data key="d23">0.1624</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c379" target="Neutral">
      <data key="d23">0.0</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="ar382" target="c383">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c384">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c385">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c386">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c387">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c388">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="ar382" target="c389">
      <data key="d22">article-comment</data>
    </edge>
    <edge source="c383" target="Neutral">
      <data key="d23">0.038</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c384" target="Positive">
      <data key="d23">0.0916</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c385" target="Positive">
      <data key="d23">0.4915</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c386" target="Positive">
      <data key="d23">0.4767</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c387" target="Neutral">
      <data key="d23">0.0114</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c388" target="Positive">
      <data key="d23">0.0986</data>
      <data key="d22">sentiment-comment</data>
    </edge>
    <edge source="c389" target="Neutral">
      <data key="d23">0.0213</data>
      <data key="d22">sentiment-comment</data>
    </edge>
  </graph>
</graphml>
